{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NENROZ0T0m9D",
        "outputId": "51c467aa-c5f8-46ec-97de-16ef8940ce87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! cp '/content/drive/MyDrive/data' '/' -r"
      ],
      "metadata": {
        "id": "PSHfppoAE7Bj"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir /model"
      ],
      "metadata": {
        "id": "OssqkfxpGApJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "k4paDiag0lNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torchtext\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "BIhi0eyZq9HY"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileNn = '/content/drive/MyDrive/APS360_project_group_12-main'"
      ],
      "metadata": {
        "id": "jDZFsrDrtNe6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def skipFromHere(index):\n",
        "\n",
        "    if index > 50:\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "metadata": {
        "id": "7lz_LlH58PLv"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YWA4tXeB0lNh"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import torchtext\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "def data_loader(batch_size=128):\n",
        "    # load data from csv file\n",
        "    fields = ['news_article', 'news_category']\n",
        "\n",
        "    train_data = pd.read_csv(fileNn + '/content/inshort_news_data-train.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    val_data = pd.read_csv(fileNn +'/content/inshort_news_data-val.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    test_data = pd.read_csv(fileNn +'/content/inshort_news_data-test.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    new_data = pd.read_csv(fileNn +'/content/new_news_articles.csv',header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True, skiprows=lambda x: skipFromHere(x))\n",
        "    # read_csv seems have bugs for skip_blank_lines accoring to return value of what i tried for \n",
        "    # new_data before and online forum, so i use skirows instead of skip_blank_lines\n",
        "\n",
        "\n",
        "    # Creating training and testing data\n",
        "    X_train = train_data['news_article']\n",
        "    Y_train = train_data['news_category']\n",
        "\n",
        "    X_test = test_data['news_article']\n",
        "    Y_test = test_data['news_category']\n",
        "\n",
        "    X_val = val_data['news_article']\n",
        "    Y_val = val_data['news_category']\n",
        "    \n",
        "    X_new = new_data['news_article']\n",
        "    Y_new = new_data['news_category']\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      X_train[i] = X_train[i].split()\n",
        "\n",
        "    for j in range(X_val.shape[0]):\n",
        "      X_val[j] = X_val[j].split()\n",
        "\n",
        "    for k in range(X_test.shape[0]):\n",
        "      X_test[k] = X_test[k].split()\n",
        "\n",
        "    for m in range(X_new.shape[0]):\n",
        "      X_new[m] = X_new[m].split()\n",
        "    # fixing bugs for interating out of range in above loop about new data\n",
        "\n",
        "\n",
        "    Y_train = pd.get_dummies(Y_train).to_numpy()\n",
        "    Y_val = pd.get_dummies(Y_val).to_numpy()\n",
        "    Y_test = pd.get_dummies(Y_test).to_numpy()\n",
        "    Y_new = pd.get_dummies(Y_new).to_numpy()\n",
        "\n",
        "    # stopwords to eliminate useless words\n",
        "    stopwords = []\n",
        "    stop = open(fileNn + '/content/stopwords.txt', encoding=\"utf-8\")\n",
        "    for line in stop:\n",
        "      stopwords.append(line.strip())\n",
        "    stop.close()\n",
        "\n",
        "    # choose first 61 words\n",
        "    for ix in X_train:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_val:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_test:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      if (len(X_new[i]) > 61):\n",
        "        X_new[i] = X_new[i][0:61]\n",
        "    # somehow above loops don't change len of each entry, now they are fine\n",
        "\n",
        "    # utilize Glove6B for embedding\n",
        "    glove = torchtext.vocab.GloVe(name='6B', dim=50)\n",
        "\n",
        "    # Filling the embedding matrix\n",
        "    embedding_matrix_train = np.zeros((X_train.shape[0], 61, 50))\n",
        "    embedding_matrix_val = np.zeros((X_val.shape[0], 61, 50))\n",
        "    embedding_matrix_test = np.zeros((X_test.shape[0], 61, 50))\n",
        "    embedding_matrix_new = np.zeros((X_new.shape[0], 61, 50))\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      for j in range(len(X_train[i])):\n",
        "        if not (X_train[i][j].lower() in stopwords):\n",
        "          embedding_matrix_train[i][j] = glove[X_train[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_val.shape[0]):\n",
        "      for j in range(len(X_val[i])):\n",
        "        if not (X_val[i][j].lower() in stopwords):\n",
        "          embedding_matrix_val[i][j] = glove[X_val[i][j].lower()]\n",
        "\n",
        "    for i in range(X_test.shape[0]):\n",
        "      for j in range(len(X_test[i])):\n",
        "        if not (X_test[i][j].lower() in stopwords):\n",
        "          embedding_matrix_test[i][j] = glove[X_test[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      for j in range(len(X_new[i])):\n",
        "        if not (X_new[i][j].lower() in stopwords):\n",
        "          embedding_matrix_new[i][j] = glove[X_new[i][j].lower()]\n",
        "\n",
        "    X_train_t = torch.from_numpy(embedding_matrix_train).to(torch.float32)\n",
        "    Y_train_t = torch.from_numpy(Y_train).to(torch.float32)\n",
        "    X_val_t = torch.from_numpy(embedding_matrix_val).to(torch.float32)\n",
        "    Y_val_t = torch.from_numpy(Y_val).to(torch.float32)\n",
        "    X_test_t = torch.from_numpy(embedding_matrix_test).to(torch.float32)\n",
        "    Y_test_t = torch.from_numpy(Y_test).to(torch.float32)\n",
        "    X_new_t = torch.from_numpy(embedding_matrix_new).to(torch.float32)\n",
        "    Y_new_t = torch.from_numpy(Y_new).to(torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
        "    val_dataset = TensorDataset(X_val_t, Y_val_t)\n",
        "    test_dataset = TensorDataset(X_test_t, Y_test_t)\n",
        "    new_dataset = TensorDataset(X_new_t, Y_new_t)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "    new_dataloader = DataLoader(new_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader, new_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader, new_loader = data_loader()"
      ],
      "metadata": {
        "id": "6RmVocW5sOcT"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num training articles:',len(train_loader.dataset))\n",
        "print('Num validation articles:',len(val_loader.dataset))\n",
        "print('Num test articles:',len(test_loader.dataset))\n",
        "print('Num new articles:',len(new_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Qt_1IlP7Lu",
        "outputId": "9d05438b-175d-4bab-8cdd-4ceabe2a7208"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training articles: 6380\n",
            "Num validation articles: 1560\n",
            "Num test articles: 1560\n",
            "Num new articles: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NBx-LLzS0lNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "use_cuda = True\n",
        "\n",
        "# I made this a bidirectional LSTM.\n",
        "class LSTM_news_classifier_3(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_3, self).__init__()\n",
        "        self.name = \"LSTM_3\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(out[:,-1,:])\n",
        "\n",
        "\n",
        "# LSTM model\n",
        "class LSTM_news_classifier_4(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_4, self).__init__()\n",
        "        self.name = \"LSTM_4\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True, num_layers=4)\n",
        "        self.fc = nn.Linear(4 * 2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(8, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(8, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(h_n.view(-1, self.hidden_size * 4 * 2))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r97Hm3-x0lNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing Code"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JgVHyyl30lNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_model_path(name, batch_size, learning_rate, epoch, exercise_code):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}_exercise_{4}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_csv_path(name, batch_size, learning_rate, exercise_code):\n",
        "    \"\"\" Generate a name for the csv file consisting of all training and validation data\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"data_{0}_bs{1}_lr{2}_exercise_{3}.csv\".format(name,batch_size, learning_rate, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_fig_path(name1, name2, batch_size, learning_rate, exercise_code):\n",
        "    path = \"fig_{0}_bs{1}_lr{2}_exercise_{3}_{4}.png\".format(name1, batch_size, learning_rate, exercise_code, name2)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "def find_the_best_model(val_acc):\n",
        "    \"\"\" Find the model with the best validation accuracy\n",
        "\n",
        "    Args:\n",
        "        validation accuracy list\n",
        "    Returns:\n",
        "        The epoch with the greatest accuracy and its accuracy\n",
        "    \"\"\"\n",
        "    cur_largest = -1\n",
        "    cur_largest_epoch = -1\n",
        "    for epoch in range(len(val_acc)):\n",
        "        if(val_acc[epoch] > cur_largest):\n",
        "            cur_largest = val_acc[epoch]\n",
        "            cur_largest_epoch = epoch\n",
        "    return cur_largest_epoch, cur_largest\n",
        "\n",
        "\n",
        "def save_to_csv(path, epochs, train_losses, train_acc, val_losses, val_acc, header):\n",
        "    organized_data = []\n",
        "    organized_data.append(header)\n",
        "    for i in range(len(epochs)):\n",
        "        organized_data.append([epochs[i], train_losses[i], train_acc[i], val_losses[i], val_acc[i]])\n",
        "    f = open(path,'w+')\n",
        "    write_csv = csv.writer(f)\n",
        "    write_csv.writerows(organized_data)\n",
        "\n",
        "\n",
        "def train_net(net, batch_size, learning_rate, num_epochs, train_loader, val_loader, exercise_code):\n",
        "    assert num_epochs > 0, \"num_epochs must be an integer that is greater than 0\"\n",
        "    assert learning_rate > 0, \"learning_rate must be greater than 0\"\n",
        "    torch.manual_seed(1000)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(),\n",
        "                                 lr=learning_rate,\n",
        "                                 weight_decay=1e-5)\n",
        "    epochs, train_losses, train_acc, val_losses, val_acc = [], [], [], [], []\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        epochs.append(epoch)\n",
        "        total, correct = 0, 0\n",
        "        total_loss = 0\n",
        "        for articles, labels in train_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                articles = articles.cuda()\n",
        "                labels = labels.cuda()\n",
        "            out = net(articles)\n",
        "            loss = criterion(out, labels)\n",
        "            total_loss = total_loss + loss.item() * articles.shape[0]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # print(out.shape)\n",
        "            pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "            # print(pred)\n",
        "            # print(torch.argmax(labels, dim=1))\n",
        "            correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "            total = total + articles.shape[0]\n",
        "            # print(correct, total)\n",
        "        train_acc.append(correct/total)\n",
        "        train_losses.append(total_loss/total)\n",
        "\n",
        "        val_correct = 0\n",
        "        val_total_loss = 0\n",
        "        val_total = 0\n",
        "        for val_articles, val_labels in val_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                val_articles = val_articles.cuda()\n",
        "                val_labels = val_labels.cuda()\n",
        "            val_out = net(val_articles)\n",
        "            # print(val_imgs)\n",
        "            val_pred = torch.squeeze(val_out.max(1, keepdim=True)[1], 1)\n",
        "            val_correct = val_correct + val_pred.eq(torch.argmax(val_labels, dim=1)).sum().item()\n",
        "            val_total = val_total + val_articles.shape[0]\n",
        "            val_total_loss = val_total_loss + (criterion(val_out, val_labels)).item() * val_articles.shape[0]\n",
        "        val_losses.append(val_total_loss/val_total) # Append the average loss\n",
        "        val_acc.append(val_correct/val_total)\n",
        "\n",
        "        print(\"Epoch {0}:\\ntraining accuracy: {1}\\ttraining loss: {2}\\tvalidation accuracy: {3}\\tvalidation loss:{4}\".format(epoch, train_acc[epoch], train_losses[epoch], val_acc[epoch], val_losses[epoch]))\n",
        "        print(\"Correct number of outputs in validation: {0}\\tTotal number of outputs in validation: {1}\\tTotal validation loss {2}\".format(val_correct, val_total, val_total_loss))\n",
        "        model_path = get_model_path(net.name, batch_size, learning_rate, epoch, exercise_code)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "    end_time = time.time()\n",
        "    print(\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % (\n",
        "    (end_time - start_time), ((end_time - start_time) / num_epochs)))\n",
        "\n",
        "    best_epoch, best_epoch_acc = find_the_best_model(val_acc)\n",
        "    print(\"The best epoch: {0}\\tAccuracy:{1}\".format(best_epoch, best_epoch_acc))\n",
        "\n",
        "    csv_path = get_csv_path(net.name, batch_size, learning_rate, exercise_code)\n",
        "    header = [\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Validation Loss\", \"Validation Accuracy\"]\n",
        "    save_to_csv(csv_path, epochs, train_losses, train_acc, val_losses, val_acc, header)\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.plot(epochs, train_losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Accuracy Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Training\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Loss Curve\")\n",
        "    plt.plot(epochs, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Accuracy Curve\")\n",
        "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Validation Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def test_model(net_type, parameters, use_cuda, model_path, data_loader, criterion):\n",
        "    state = torch.load(model_path)\n",
        "    net = net_type(parameters[0], parameters[1], parameters[2])\n",
        "    net.load_state_dict(state)\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        net.cuda()\n",
        "        print('CUDA is available!  Training on GPU ...')\n",
        "    else:\n",
        "        print('CUDA is not available.  Training on CPU ...')\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    for articles, labels in data_loader:\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            articles = articles.cuda()\n",
        "            labels = labels.cuda()\n",
        "        out = net(articles)\n",
        "        pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "        correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "        total = total + articles.shape[0]\n",
        "        total_loss = total_loss + (criterion(out, labels)).item() * articles.shape[0]\n",
        "    return correct, total, correct / total, total_loss / total"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G3SQ8YIm0lNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test your model here"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XHaSVNYM0lNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "News_model = LSTM_news_classifier_4(50, 256, 7)\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  News_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')"
      ],
      "metadata": {
        "id": "e5qO3oIjFmFN",
        "outputId": "a684e890-a722-4e1b-d934-22b7af917560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train = True\n",
        "if Train:\n",
        "    train_net(News_model, 256, 0.01, 200, train_loader, val_loader, 'Aug_6_22_47_hidden_size_256')\n",
        "else:\n",
        "    parameters = (50, 128, 7) # (input size, hidden size, number of classes)\n",
        "    model_path = get_model_path(\"LSTM_3\", 128, 1, 17, \"Aug_4_4_30\")\n",
        "    test_result = test_model(LSTM_news_classifier_4, parameters, False, model_path, test_loader, nn.MSELoss())\n",
        "    print(\"Correct: {0}\\tTotal: {1}\\tAccuracy: {2}\\tLoss: {3}\".format(test_result[0], test_result[1], test_result[2], test_result[3]))\n"
      ],
      "metadata": {
        "id": "Yov5VrVvJOWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = (50, 256, 7) # (input size, hidden size, number of classes)\n",
        "model_path = get_model_path(\"LSTM_3\", 256, 0.01, 16, \"Aug_6_22_40_hidden_size_256\")\n",
        "test_result = test_model(LSTM_news_classifier_3, parameters, True, model_path, test_loader, nn.MSELoss())\n",
        "print(\"Correct: {0}\\tTotal: {1}\\tAccuracy: {2}\\tLoss: {3}\".format(test_result[0], test_result[1], test_result[2], test_result[3]))"
      ],
      "metadata": {
        "id": "gEeaAPkuKYEL",
        "outputId": "06783c37-e86f-4bd3-c710-3fdcc8d31822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Correct: 1378\tTotal: 1560\tAccuracy: 0.8833333333333333\tLoss: 0.028052796652683846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /model /content/drive/MyDrive/ -r"
      ],
      "metadata": {
        "id": "7BTvmlw9MO6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "all_code.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchtext\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def data_loader(batch_size=128):\n",
    "    # load data from csv file\n",
    "    fields = ['news_article', 'news_category']\n",
    "\n",
    "    train_data = pd.read_csv('./content/inshort_news_data-train.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
    "    val_data = pd.read_csv('./content/inshort_news_data-val.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
    "    test_data = pd.read_csv('./content/inshort_news_data-test.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
    "\n",
    "    # Creating training and testing data\n",
    "    X_train = train_data['news_article']\n",
    "    Y_train = train_data['news_category']\n",
    "\n",
    "    X_test = test_data['news_article']\n",
    "    Y_test = test_data['news_category']\n",
    "\n",
    "    X_val = val_data['news_article']\n",
    "    Y_val = val_data['news_category']\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "      X_train[i] = X_train[i].split()\n",
    "\n",
    "    for j in range(X_val.shape[0]):\n",
    "      X_val[j] = X_val[j].split()\n",
    "\n",
    "    for k in range(X_test.shape[0]):\n",
    "      X_test[k] = X_test[k].split()\n",
    "\n",
    "    Y_train = pd.get_dummies(Y_train).to_numpy()\n",
    "    Y_val = pd.get_dummies(Y_val).to_numpy()\n",
    "    Y_test = pd.get_dummies(Y_test).to_numpy()\n",
    "\n",
    "    # stopwords to eliminate useless words\n",
    "    stopwords = []\n",
    "    stop = open('./content/stopwords.txt', encoding=\"utf-8\")\n",
    "    for line in stop:\n",
    "      stopwords.append(line.strip())\n",
    "    stop.close()\n",
    "\n",
    "    # utilize Glove6B for embedding\n",
    "    glove = torchtext.vocab.GloVe(name='6B', dim=50)\n",
    "\n",
    "    # Filling the embedding matrix\n",
    "    embedding_matrix_train = np.zeros((X_train.shape[0], 61, 50))\n",
    "    embedding_matrix_val = np.zeros((X_val.shape[0], 61, 50))\n",
    "    embedding_matrix_test = np.zeros((X_test.shape[0], 61, 50))\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "      for j in range(len(X_train[i])):\n",
    "        if not (X_train[i][j].lower() in stopwords):\n",
    "          embedding_matrix_train[i][j] = glove[X_train[i][j].lower()]\n",
    "\n",
    "    for i in range(X_val.shape[0]):\n",
    "      for j in range(len(X_val[i])):\n",
    "        if not (X_val[i][j].lower() in stopwords):\n",
    "          embedding_matrix_val[i][j] = glove[X_val[i][j].lower()]\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "      for j in range(len(X_test[i])):\n",
    "        if not (X_test[i][j].lower() in stopwords):\n",
    "          embedding_matrix_test[i][j] = glove[X_test[i][j].lower()]\n",
    "\n",
    "    X_train_t = torch.from_numpy(embedding_matrix_train).to(torch.float32)\n",
    "    Y_train_t = torch.from_numpy(Y_train).to(torch.float32)\n",
    "    X_val_t = torch.from_numpy(embedding_matrix_val).to(torch.float32)\n",
    "    Y_val_t = torch.from_numpy(Y_val).to(torch.float32)\n",
    "    X_test_t = torch.from_numpy(embedding_matrix_test).to(torch.float32)\n",
    "    Y_test_t = torch.from_numpy(Y_test).to(torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
    "    val_dataset = TensorDataset(X_val_t, Y_val_t)\n",
    "    test_dataset = TensorDataset(X_test_t, Y_test_t)\n",
    "\n",
    "    print('Num training articles: ', len(train_dataset))\n",
    "    print('Num validation articles: ', len(val_dataset))\n",
    "    print('Num test articles: ', len(test_dataset))\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = data_loader()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# LSTM model\n",
    "class LSTM_news_classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class):\n",
    "        super(LSTM_news_classifier, self).__init__()\n",
    "        self.name = \"LSTM_1\"\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
    "        return self.fc(out[:,-1,:])\n",
    "\n",
    "# LSTM model number 2. I add a sigmoid function\n",
    "class LSTM_news_classifier_2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class):\n",
    "        super(LSTM_news_classifier_2, self).__init__()\n",
    "        self.name = \"LSTM_2\"\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_class)\n",
    "        self.af = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
    "        return self.af(self.fc(out[:,-1,:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "News_LSTM = LSTM_news_classifier(50, 64, 7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training and Testing Code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_model_path(name, batch_size, learning_rate, epoch, exercise_code):\n",
    "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}_exercise_{4}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch, exercise_code)\n",
    "    path = \"./model/\" + path\n",
    "    return path\n",
    "\n",
    "\n",
    "def get_csv_path(name, batch_size, learning_rate, exercise_code):\n",
    "    \"\"\" Generate a name for the csv file consisting of all training and validation data\n",
    "\n",
    "    Args:\n",
    "        config: Configuration object containing the hyperparameters\n",
    "    Returns:\n",
    "        path: A string with the hyperparameter name and value concatenated\n",
    "    \"\"\"\n",
    "    path = \"data_{0}_bs{1}_lr{2}_exercise_{3}.csv\".format(name,batch_size, learning_rate, exercise_code)\n",
    "    path = \"./model/\" + path\n",
    "    return path\n",
    "\n",
    "\n",
    "def get_fig_path(name1, name2, batch_size, learning_rate, exercise_code):\n",
    "    path = \"fig_{0}_bs{1}_lr{2}_exercise_{3}_{4}.png\".format(name1, batch_size, learning_rate, exercise_code, name2)\n",
    "    path = \"./model/\" + path\n",
    "    return path\n",
    "\n",
    "def find_the_best_model(val_acc):\n",
    "    \"\"\" Find the model with the best validation accuracy\n",
    "\n",
    "    Args:\n",
    "        validation accuracy list\n",
    "    Returns:\n",
    "        The epoch with the greatest accuracy and its accuracy\n",
    "    \"\"\"\n",
    "    cur_largest = -1\n",
    "    cur_largest_epoch = -1\n",
    "    for epoch in range(len(val_acc)):\n",
    "        if(val_acc[epoch] > cur_largest):\n",
    "            cur_largest = val_acc[epoch]\n",
    "            cur_largest_epoch = epoch\n",
    "    return cur_largest_epoch, cur_largest\n",
    "\n",
    "\n",
    "def save_to_csv(path, epochs, train_losses, train_acc, val_losses, val_acc, header):\n",
    "    organized_data = []\n",
    "    organized_data.append(header)\n",
    "    for i in range(len(epochs)):\n",
    "        organized_data.append([epochs[i], train_losses[i], train_acc[i], val_losses[i], val_acc[i]])\n",
    "    f = open(path,'w+')\n",
    "    write_csv = csv.writer(f)\n",
    "    write_csv.writerows(organized_data)\n",
    "\n",
    "\n",
    "def train_net(net, batch_size, learning_rate, num_epochs, train_loader, val_loader, exercise_code):\n",
    "    assert num_epochs > 0, \"num_epochs must be an integer that is greater than 0\"\n",
    "    assert learning_rate > 0, \"learning_rate must be greater than 0\"\n",
    "    torch.manual_seed(1000)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr=learning_rate,\n",
    "                                 weight_decay=1e-5)\n",
    "    epochs, train_losses, train_acc, val_losses, val_acc = [], [], [], [], []\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        epochs.append(epoch)\n",
    "        total, correct = 0, 0\n",
    "        total_loss = 0\n",
    "        for articles, labels in train_loader:\n",
    "            #############################################\n",
    "            #To Enable GPU Usage\n",
    "            # if use_cuda and torch.cuda.is_available():\n",
    "              # imgs = imgs.cuda()\n",
    "              # labels = labels.cuda()\n",
    "            #############################################\n",
    "            #print(imgs)\n",
    "            #print(labels)\n",
    "            out = net(articles)\n",
    "            loss = criterion(out, labels)\n",
    "            total_loss = total_loss + loss.item() * articles.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # print(out.shape)\n",
    "            pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
    "            # print(pred)\n",
    "            # print(torch.argmax(labels, dim=1))\n",
    "            correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "            total = total + articles.shape[0]\n",
    "            # print(correct, total)\n",
    "        train_acc.append(correct/total)\n",
    "        train_losses.append(total_loss/total)\n",
    "\n",
    "        val_correct = 0\n",
    "        val_total_loss = 0\n",
    "        val_total = 0\n",
    "        for val_articles, val_labels in val_loader:\n",
    "            # if use_cuda and torch.cuda.is_available():\n",
    "                # val_imgs = val_imgs.cuda()\n",
    "                # val_labels = val_labels.cuda()\n",
    "            val_out = net(val_articles)\n",
    "            # print(val_imgs)\n",
    "            val_pred = torch.squeeze(val_out.max(1, keepdim=True)[1], 1)\n",
    "            val_correct = val_correct + val_pred.eq(torch.argmax(val_labels, dim=1)).sum().item()\n",
    "            val_total = val_total + val_articles.shape[0]\n",
    "            val_total_loss = val_total_loss + (criterion(val_out, val_labels)).item() * val_articles.shape[0]\n",
    "        val_losses.append(val_total_loss/val_total) # Append the average loss\n",
    "        val_acc.append(val_correct/val_total)\n",
    "\n",
    "        print(\"Epoch {0}:\\ntraining accuracy: {1}\\ttraining loss: {2}\\tvalidation accuracy: {3}\\tvalidation loss:{4}\".format(epoch, train_acc[epoch], train_losses[epoch], val_acc[epoch], val_losses[epoch]))\n",
    "        print(\"Correct number of outputs in validation: {0}\\tTotal number of outputs in validation: {1}\\tTotal validation loss {2}\".format(val_correct, val_total, val_total_loss))\n",
    "        model_path = get_model_path(net.name, batch_size, learning_rate, epoch, exercise_code)\n",
    "        torch.save(net.state_dict(), model_path)\n",
    "    end_time = time.time()\n",
    "    print(\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % (\n",
    "    (end_time - start_time), ((end_time - start_time) / num_epochs)))\n",
    "\n",
    "    best_epoch, best_epoch_acc = find_the_best_model(val_acc)\n",
    "    print(\"The best epoch: {0}\\tAccuracy:{1}\".format(best_epoch, best_epoch_acc))\n",
    "\n",
    "    csv_path = get_csv_path(net.name, batch_size, learning_rate, exercise_code)\n",
    "    header = [\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Validation Loss\", \"Validation Accuracy\"]\n",
    "    save_to_csv(csv_path, epochs, train_losses, train_acc, val_losses, val_acc, header)\n",
    "\n",
    "    # plotting\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.plot(epochs, train_losses, label=\"Train\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Train Loss\")\n",
    "    plt.savefig(get_fig_path(net.name, \"Training_Loss\", batch_size, learning_rate, exercise_code))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Accuracy Curve\")\n",
    "    plt.plot(epochs, train_acc, label=\"Training\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.savefig(get_fig_path(net.name, \"Training_Acc\", batch_size, learning_rate, exercise_code))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Validation Loss Curve\")\n",
    "    plt.plot(epochs, val_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Train Loss\")\n",
    "    plt.savefig(get_fig_path(net.name, \"Val_Loss\", batch_size, learning_rate, exercise_code))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Validation Accuracy Curve\")\n",
    "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.savefig(get_fig_path(net.name, \"Val_Acc\", batch_size, learning_rate, exercise_code))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_model(net_type, parameters, use_cuda, model_path, data_loader, criterion):\n",
    "    state = torch.load(model_path)\n",
    "    net = net_type(parameters[0], parameters[1], parameters[2])\n",
    "    net.load_state_dict(state)\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "    else:\n",
    "        print('CUDA is not available.  Training on CPU ...')\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    for articles, labels in data_loader:\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            articles = articles.cuda()\n",
    "            labels = labels.cuda()\n",
    "        out = net(articles)\n",
    "        pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
    "        correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
    "        total = total + articles.shape[0]\n",
    "        total_loss = total_loss + (criterion(out, labels)).item() * articles.shape[0]\n",
    "    return correct, total, correct / total, total_loss / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and test your model here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters = (50, 64, 7)\n",
    "model_path = get_model_path(\"LSTM_1\", 128, 0.01, 16, \"July_8_8_33\")\n",
    "test_result = test_model(LSTM_news_classifier, parameters, False, model_path, test_loader, nn.MSELoss())\n",
    "print(\"Correct: {0}\\tTotal: {1}\\tAccuracy: {2}\\tLoss: {3}\".format(test_result[0], test_result[1], test_result[2], test_result[3]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
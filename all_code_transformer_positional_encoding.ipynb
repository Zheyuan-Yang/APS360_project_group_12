{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NENROZ0T0m9D",
        "outputId": "fbc6758c-3285-42d3-ef0e-6df224d72f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp '/content/drive/MyDrive/data' '/' -r"
      ],
      "metadata": {
        "id": "PSHfppoAE7Bj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm /model -r\n",
        "! mkdir /model"
      ],
      "metadata": {
        "id": "OssqkfxpGApJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "k4paDiag0lNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torchtext\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "BIhi0eyZq9HY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileNn = ''"
      ],
      "metadata": {
        "id": "jDZFsrDrtNe6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def skipFromHere(index):\n",
        "\n",
        "    if index > 50:\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "metadata": {
        "id": "7lz_LlH58PLv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YWA4tXeB0lNh"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import torchtext\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "def data_loader(batch_size=128):\n",
        "    # load data from csv file\n",
        "    fields = ['news_article', 'news_category']\n",
        "\n",
        "    train_data = pd.read_csv(fileNn + '/data/inshort_news_data-train.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    val_data = pd.read_csv(fileNn +'/data/inshort_news_data-val.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    test_data = pd.read_csv(fileNn +'/data/inshort_news_data-test.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    new_data = pd.read_csv(fileNn +'/data/new_news_articles.csv',header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True, skiprows=lambda x: skipFromHere(x))\n",
        "    # read_csv seems have bugs for skip_blank_lines accoring to return value of what i tried for \n",
        "    # new_data before and online forum, so i use skirows instead of skip_blank_lines\n",
        "\n",
        "\n",
        "    # Creating training and testing data\n",
        "    X_train = train_data['news_article']\n",
        "    Y_train = train_data['news_category']\n",
        "\n",
        "    X_test = test_data['news_article']\n",
        "    Y_test = test_data['news_category']\n",
        "\n",
        "    X_val = val_data['news_article']\n",
        "    Y_val = val_data['news_category']\n",
        "    \n",
        "    X_new = new_data['news_article']\n",
        "    Y_new = new_data['news_category']\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      X_train[i] = X_train[i].split()\n",
        "\n",
        "    for j in range(X_val.shape[0]):\n",
        "      X_val[j] = X_val[j].split()\n",
        "\n",
        "    for k in range(X_test.shape[0]):\n",
        "      X_test[k] = X_test[k].split()\n",
        "\n",
        "    for m in range(X_new.shape[0]):\n",
        "      X_new[m] = X_new[m].split()\n",
        "    # fixing bugs for interating out of range in above loop about new data\n",
        "\n",
        "\n",
        "    Y_train = pd.get_dummies(Y_train).to_numpy()\n",
        "    Y_val = pd.get_dummies(Y_val).to_numpy()\n",
        "    Y_test = pd.get_dummies(Y_test).to_numpy()\n",
        "    Y_new = pd.get_dummies(Y_new).to_numpy()\n",
        "\n",
        "    # stopwords to eliminate useless words\n",
        "    stopwords = []\n",
        "    stop = open(fileNn + '/data/stopwords.txt', encoding=\"utf-8\")\n",
        "    for line in stop:\n",
        "      stopwords.append(line.strip())\n",
        "    stop.close()\n",
        "\n",
        "    # choose first 61 words\n",
        "    for ix in X_train:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_val:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_test:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      if (len(X_new[i]) > 61):\n",
        "        X_new[i] = X_new[i][0:61]\n",
        "    # somehow above loops don't change len of each entry, now they are fine\n",
        "\n",
        "    # utilize Glove6B for embedding\n",
        "    glove = torchtext.vocab.GloVe(name='6B', dim=50)\n",
        "\n",
        "    # Filling the embedding matrix\n",
        "    embedding_matrix_train = np.zeros((X_train.shape[0], 61, 50))\n",
        "    embedding_matrix_val = np.zeros((X_val.shape[0], 61, 50))\n",
        "    embedding_matrix_test = np.zeros((X_test.shape[0], 61, 50))\n",
        "    embedding_matrix_new = np.zeros((X_new.shape[0], 61, 50))\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      for j in range(len(X_train[i])):\n",
        "        if not (X_train[i][j].lower() in stopwords):\n",
        "          embedding_matrix_train[i][j] = glove[X_train[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_val.shape[0]):\n",
        "      for j in range(len(X_val[i])):\n",
        "        if not (X_val[i][j].lower() in stopwords):\n",
        "          embedding_matrix_val[i][j] = glove[X_val[i][j].lower()]\n",
        "\n",
        "    for i in range(X_test.shape[0]):\n",
        "      for j in range(len(X_test[i])):\n",
        "        if not (X_test[i][j].lower() in stopwords):\n",
        "          embedding_matrix_test[i][j] = glove[X_test[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      for j in range(len(X_new[i])):\n",
        "        if not (X_new[i][j].lower() in stopwords):\n",
        "          embedding_matrix_new[i][j] = glove[X_new[i][j].lower()]\n",
        "\n",
        "    X_train_t = torch.from_numpy(embedding_matrix_train).to(torch.float32)\n",
        "    Y_train_t = torch.from_numpy(Y_train).to(torch.float32)\n",
        "    X_val_t = torch.from_numpy(embedding_matrix_val).to(torch.float32)\n",
        "    Y_val_t = torch.from_numpy(Y_val).to(torch.float32)\n",
        "    X_test_t = torch.from_numpy(embedding_matrix_test).to(torch.float32)\n",
        "    Y_test_t = torch.from_numpy(Y_test).to(torch.float32)\n",
        "    X_new_t = torch.from_numpy(embedding_matrix_new).to(torch.float32)\n",
        "    Y_new_t = torch.from_numpy(Y_new).to(torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
        "    val_dataset = TensorDataset(X_val_t, Y_val_t)\n",
        "    test_dataset = TensorDataset(X_test_t, Y_test_t)\n",
        "    new_dataset = TensorDataset(X_new_t, Y_new_t)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "    new_dataloader = DataLoader(new_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader, new_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader, new_loader = data_loader()"
      ],
      "metadata": {
        "id": "6RmVocW5sOcT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num training articles:',len(train_loader.dataset))\n",
        "print('Num validation articles:',len(val_loader.dataset))\n",
        "print('Num test articles:',len(test_loader.dataset))\n",
        "print('Num new articles:',len(new_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Qt_1IlP7Lu",
        "outputId": "6c65dfa2-5cf0-4da8-fe9e-a779bc8d9575"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training articles: 6380\n",
            "Num validation articles: 1560\n",
            "Num test articles: 1560\n",
            "Num new articles: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NBx-LLzS0lNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from math import sin, cos\n",
        "use_cuda = True\n",
        "\n",
        "# I made this a bidirectional LSTM.\n",
        "class LSTM_news_classifier_3(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_3, self).__init__()\n",
        "        self.name = \"LSTM_3\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(out[:,-1,:])\n",
        "\n",
        "\n",
        "# LSTM model\n",
        "class LSTM_news_classifier_4(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_4, self).__init__()\n",
        "        self.name = \"LSTM_4\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, num_layers=2, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(4, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(4, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(out[:,-1,:])\n",
        "\n",
        "class positional_encoding(nn.Module):\n",
        "    def __init__(self, max_length, embedding_size):\n",
        "        super(positional_encoding, self).__init__()\n",
        "        self.pe_tensor = torch.zeros(max_length, embedding_size)\n",
        "        for pos in range(max_length):\n",
        "            for i in range(embedding_size):\n",
        "                if i % 2 == 0:\n",
        "                    pe = sin(pos / pow(10000, (i / max_length)))\n",
        "                else:\n",
        "                    pe = cos(pos / pow(10000, ((i - 1) / max_length)))\n",
        "                self.pe_tensor[pos][i] = pe\n",
        "\n",
        "    def forward(self, x):\n",
        "        pe_input = self.pe_tensor[:x.shape[1], :]\n",
        "        pe_input = pe_input.repeat(x.shape[0], 1, 1)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            pe_input = pe_input.cuda()\n",
        "        x = x + pe_input\n",
        "        return x\n",
        "\n",
        "\n",
        "class Transformer_news_classifier_2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(Transformer_news_classifier_2, self).__init__()\n",
        "        self.pos_encoding = positional_encoding(1000, input_size)\n",
        "        self.name = \"Transformer_news_classifier_2\"\n",
        "        self.linear_q = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_k = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_v = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_x = nn.Linear(input_size, hidden_size)\n",
        "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=4, batch_first=True)\n",
        "        self.fc1 = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size))\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = x + self.pos_encoding(x)\n",
        "        q, k, v = self.linear_q(x), self.linear_k(x), self.linear_v(x)\n",
        "        x = self.norm(self.linear_x(x) + self.attention(q, k, v)[0])\n",
        "        x = self.norm(x + self.fc1(x))\n",
        "        x = torch.sum(x, 1)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r97Hm3-x0lNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing Code"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JgVHyyl30lNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_model_path(name, batch_size, learning_rate, epoch, exercise_code):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}_exercise_{4}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_csv_path(name, batch_size, learning_rate, exercise_code):\n",
        "    \"\"\" Generate a name for the csv file consisting of all training and validation data\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"data_{0}_bs{1}_lr{2}_exercise_{3}.csv\".format(name,batch_size, learning_rate, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_fig_path(name1, name2, batch_size, learning_rate, exercise_code):\n",
        "    path = \"fig_{0}_bs{1}_lr{2}_exercise_{3}_{4}.png\".format(name1, batch_size, learning_rate, exercise_code, name2)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "def find_the_best_model(val_acc):\n",
        "    \"\"\" Find the model with the best validation accuracy\n",
        "\n",
        "    Args:\n",
        "        validation accuracy list\n",
        "    Returns:\n",
        "        The epoch with the greatest accuracy and its accuracy\n",
        "    \"\"\"\n",
        "    cur_largest = -1\n",
        "    cur_largest_epoch = -1\n",
        "    for epoch in range(len(val_acc)):\n",
        "        if(val_acc[epoch] > cur_largest):\n",
        "            cur_largest = val_acc[epoch]\n",
        "            cur_largest_epoch = epoch\n",
        "    return cur_largest_epoch, cur_largest\n",
        "\n",
        "\n",
        "def save_to_csv(path, epochs, train_losses, train_acc, val_losses, val_acc, header):\n",
        "    organized_data = []\n",
        "    organized_data.append(header)\n",
        "    for i in range(len(epochs)):\n",
        "        organized_data.append([epochs[i], train_losses[i], train_acc[i], val_losses[i], val_acc[i]])\n",
        "    f = open(path,'w+')\n",
        "    write_csv = csv.writer(f)\n",
        "    write_csv.writerows(organized_data)\n",
        "\n",
        "\n",
        "def train_net(net, batch_size, learning_rate, num_epochs, train_loader, val_loader, exercise_code):\n",
        "    assert num_epochs > 0, \"num_epochs must be an integer that is greater than 0\"\n",
        "    assert learning_rate > 0, \"learning_rate must be greater than 0\"\n",
        "    torch.manual_seed(1000)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(),\n",
        "                                 lr=learning_rate,\n",
        "                                 weight_decay=1e-5)\n",
        "    epochs, train_losses, train_acc, val_losses, val_acc = [], [], [], [], []\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        epochs.append(epoch)\n",
        "        total, correct = 0, 0\n",
        "        total_loss = 0\n",
        "        for articles, labels in train_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                articles = articles.cuda()\n",
        "                labels = labels.cuda()\n",
        "            out = net(articles)\n",
        "            loss = criterion(out, labels)\n",
        "            total_loss = total_loss + loss.item() * articles.shape[0]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # print(out.shape)\n",
        "            pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "            # print(pred)\n",
        "            # print(torch.argmax(labels, dim=1))\n",
        "            correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "            total = total + articles.shape[0]\n",
        "            # print(correct, total)\n",
        "        train_acc.append(correct/total)\n",
        "        train_losses.append(total_loss/total)\n",
        "\n",
        "        val_correct = 0\n",
        "        val_total_loss = 0\n",
        "        val_total = 0\n",
        "        for val_articles, val_labels in val_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                val_articles = val_articles.cuda()\n",
        "                val_labels = val_labels.cuda()\n",
        "            val_out = net(val_articles)\n",
        "            # print(val_imgs)\n",
        "            val_pred = torch.squeeze(val_out.max(1, keepdim=True)[1], 1)\n",
        "            val_correct = val_correct + val_pred.eq(torch.argmax(val_labels, dim=1)).sum().item()\n",
        "            val_total = val_total + val_articles.shape[0]\n",
        "            val_total_loss = val_total_loss + (criterion(val_out, val_labels)).item() * val_articles.shape[0]\n",
        "        val_losses.append(val_total_loss/val_total) # Append the average loss\n",
        "        val_acc.append(val_correct/val_total)\n",
        "\n",
        "        print(\"Epoch {0}:\\ntraining accuracy: {1}\\ttraining loss: {2}\\tvalidation accuracy: {3}\\tvalidation loss:{4}\".format(epoch, train_acc[epoch], train_losses[epoch], val_acc[epoch], val_losses[epoch]))\n",
        "        print(\"Correct number of outputs in validation: {0}\\tTotal number of outputs in validation: {1}\\tTotal validation loss {2}\".format(val_correct, val_total, val_total_loss))\n",
        "        model_path = get_model_path(net.name, batch_size, learning_rate, epoch, exercise_code)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "    end_time = time.time()\n",
        "    print(\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % (\n",
        "    (end_time - start_time), ((end_time - start_time) / num_epochs)))\n",
        "\n",
        "    best_epoch, best_epoch_acc = find_the_best_model(val_acc)\n",
        "    print(\"The best epoch: {0}\\tAccuracy:{1}\".format(best_epoch, best_epoch_acc))\n",
        "\n",
        "    csv_path = get_csv_path(net.name, batch_size, learning_rate, exercise_code)\n",
        "    header = [\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Validation Loss\", \"Validation Accuracy\"]\n",
        "    save_to_csv(csv_path, epochs, train_losses, train_acc, val_losses, val_acc, header)\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.plot(epochs, train_losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Accuracy Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Training\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Loss Curve\")\n",
        "    plt.plot(epochs, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Accuracy Curve\")\n",
        "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Validation Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def test_model(net_type, parameters, use_cuda, model_path, data_loader, criterion):\n",
        "    state = torch.load(model_path)\n",
        "    net = net_type(parameters[0], parameters[1], parameters[2])\n",
        "    net.load_state_dict(state)\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        net.cuda()\n",
        "        print('CUDA is available!  Training on GPU ...')\n",
        "    else:\n",
        "        print('CUDA is not available.  Training on CPU ...')\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    for articles, labels in data_loader:\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            articles = articles.cuda()\n",
        "            labels = labels.cuda()\n",
        "        out = net(articles)\n",
        "        pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "        correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "        total = total + articles.shape[0]\n",
        "        total_loss = total_loss + (criterion(out, labels)).item() * articles.shape[0]\n",
        "    return correct, total, correct / total, total_loss / total"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G3SQ8YIm0lNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test your model here"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XHaSVNYM0lNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "News_model = Transformer_news_classifier_2(50, 256, 7)\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  News_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')"
      ],
      "metadata": {
        "id": "e5qO3oIjFmFN",
        "outputId": "519dbe12-51ea-4c19-d4a2-3cd303c01b9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_net(News_model, 128, 0.01, 400, train_loader, val_loader, 'Aug_13_00_28_hidden_size_256')"
      ],
      "metadata": {
        "id": "Yov5VrVvJOWd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ae535aa-4aac-4df5-bcba-b1ee9f7daf77"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "training accuracy: 0.14545454545454545\ttraining loss: 1078.0420481021129\tvalidation accuracy: 0.19166666666666668\tvalidation loss:14.534831291589981\n",
            "Correct number of outputs in validation: 299\tTotal number of outputs in validation: 1560\tTotal validation loss 22674.33681488037\n",
            "Epoch 1:\n",
            "training accuracy: 0.13166144200626959\ttraining loss: 3.4760059594734334\tvalidation accuracy: 0.125\tvalidation loss:0.7029064578887744\n",
            "Correct number of outputs in validation: 195\tTotal number of outputs in validation: 1560\tTotal validation loss 1096.534074306488\n",
            "Epoch 2:\n",
            "training accuracy: 0.1493730407523511\ttraining loss: 0.6340101403876158\tvalidation accuracy: 0.19230769230769232\tvalidation loss:0.4083230489339584\n",
            "Correct number of outputs in validation: 300\tTotal number of outputs in validation: 1560\tTotal validation loss 636.9839563369751\n",
            "Epoch 3:\n",
            "training accuracy: 0.1724137931034483\ttraining loss: 0.4533218097724137\tvalidation accuracy: 0.1891025641025641\tvalidation loss:0.34856139513162465\n",
            "Correct number of outputs in validation: 295\tTotal number of outputs in validation: 1560\tTotal validation loss 543.7557764053345\n",
            "Epoch 4:\n",
            "training accuracy: 0.17648902821316614\ttraining loss: 0.3840395577648964\tvalidation accuracy: 0.19166666666666668\tvalidation loss:0.3673346935174404\n",
            "Correct number of outputs in validation: 299\tTotal number of outputs in validation: 1560\tTotal validation loss 573.042121887207\n",
            "Epoch 5:\n",
            "training accuracy: 0.1669278996865204\ttraining loss: 0.36070849362959306\tvalidation accuracy: 0.1737179487179487\tvalidation loss:0.4045620355850611\n",
            "Correct number of outputs in validation: 271\tTotal number of outputs in validation: 1560\tTotal validation loss 631.1167755126953\n",
            "Epoch 6:\n",
            "training accuracy: 0.16206896551724137\ttraining loss: 0.34259354659008756\tvalidation accuracy: 0.20512820512820512\tvalidation loss:0.596905134121577\n",
            "Correct number of outputs in validation: 320\tTotal number of outputs in validation: 1560\tTotal validation loss 931.17200922966\n",
            "Epoch 7:\n",
            "training accuracy: 0.18134796238244513\ttraining loss: 0.4516201756964657\tvalidation accuracy: 0.16538461538461538\tvalidation loss:0.42312229627218\n",
            "Correct number of outputs in validation: 258\tTotal number of outputs in validation: 1560\tTotal validation loss 660.0707821846008\n",
            "Epoch 8:\n",
            "training accuracy: 0.1847962382445141\ttraining loss: 0.3994488489852056\tvalidation accuracy: 0.18012820512820513\tvalidation loss:0.38553021404987725\n",
            "Correct number of outputs in validation: 281\tTotal number of outputs in validation: 1560\tTotal validation loss 601.4271339178085\n",
            "Epoch 9:\n",
            "training accuracy: 0.1945141065830721\ttraining loss: 0.4029082915439127\tvalidation accuracy: 0.2358974358974359\tvalidation loss:0.17102532272155468\n",
            "Correct number of outputs in validation: 368\tTotal number of outputs in validation: 1560\tTotal validation loss 266.7995034456253\n",
            "Epoch 10:\n",
            "training accuracy: 0.15391849529780563\ttraining loss: 0.5754889055105586\tvalidation accuracy: 0.13846153846153847\tvalidation loss:0.781931820893899\n",
            "Correct number of outputs in validation: 216\tTotal number of outputs in validation: 1560\tTotal validation loss 1219.8136405944824\n",
            "Epoch 11:\n",
            "training accuracy: 0.13746081504702196\ttraining loss: 1.119117053997554\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.9516282628744076\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 1484.540090084076\n",
            "Epoch 12:\n",
            "training accuracy: 0.1432601880877743\ttraining loss: 0.9623066263886455\tvalidation accuracy: 0.14294871794871794\tvalidation loss:1.8895849466323853\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 2947.752516746521\n",
            "Epoch 13:\n",
            "training accuracy: 0.15094043887147335\ttraining loss: 1.2404618082375363\tvalidation accuracy: 0.1467948717948718\tvalidation loss:1.1016661744851333\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 1718.5992321968079\n",
            "Epoch 14:\n",
            "training accuracy: 0.1573667711598746\ttraining loss: 1.454590364272318\tvalidation accuracy: 0.14294871794871794\tvalidation loss:1.442731420810406\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 2250.6610164642334\n",
            "Epoch 15:\n",
            "training accuracy: 0.1463949843260188\ttraining loss: 1.5367014446228648\tvalidation accuracy: 0.1467948717948718\tvalidation loss:1.0584564750011152\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 1651.1921010017395\n",
            "Epoch 16:\n",
            "training accuracy: 0.14420062695924765\ttraining loss: 1.8030558481485492\tvalidation accuracy: 0.14294871794871794\tvalidation loss:2.2277955055236816\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 3475.3609886169434\n",
            "Epoch 17:\n",
            "training accuracy: 0.14028213166144202\ttraining loss: 1.1085926725572928\tvalidation accuracy: 0.14358974358974358\tvalidation loss:2.1128424283785696\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 3296.034188270569\n",
            "Epoch 18:\n",
            "training accuracy: 0.15501567398119123\ttraining loss: 1.399563313053693\tvalidation accuracy: 0.14166666666666666\tvalidation loss:1.9518039758388812\n",
            "Correct number of outputs in validation: 221\tTotal number of outputs in validation: 1560\tTotal validation loss 3044.814202308655\n",
            "Epoch 19:\n",
            "training accuracy: 0.14890282131661442\ttraining loss: 1.3705715525486626\tvalidation accuracy: 0.14102564102564102\tvalidation loss:1.6766511586996224\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 2615.575807571411\n",
            "Epoch 20:\n",
            "training accuracy: 0.1525078369905956\ttraining loss: 1.1460021959950557\tvalidation accuracy: 0.1467948717948718\tvalidation loss:1.2562025449214838\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 1959.6759700775146\n",
            "Epoch 21:\n",
            "training accuracy: 0.1482758620689655\ttraining loss: 1.2425167615884525\tvalidation accuracy: 0.14551282051282052\tvalidation loss:1.2858210151012128\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 2005.8807835578918\n",
            "Epoch 22:\n",
            "training accuracy: 0.15470219435736676\ttraining loss: 1.3135884486395737\tvalidation accuracy: 0.14551282051282052\tvalidation loss:1.4268275963954435\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 2225.851050376892\n",
            "Epoch 23:\n",
            "training accuracy: 0.1614420062695925\ttraining loss: 1.0966518806439582\tvalidation accuracy: 0.14423076923076922\tvalidation loss:1.0963667187935267\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 1710.3320813179016\n",
            "Epoch 24:\n",
            "training accuracy: 0.16191222570532915\ttraining loss: 1.2258759814370015\tvalidation accuracy: 0.20833333333333334\tvalidation loss:0.5108333948331002\n",
            "Correct number of outputs in validation: 325\tTotal number of outputs in validation: 1560\tTotal validation loss 796.9000959396362\n",
            "Epoch 25:\n",
            "training accuracy: 0.16927899686520376\ttraining loss: 1.1777412677072807\tvalidation accuracy: 0.18974358974358974\tvalidation loss:0.589253080655367\n",
            "Correct number of outputs in validation: 296\tTotal number of outputs in validation: 1560\tTotal validation loss 919.2348058223724\n",
            "Epoch 26:\n",
            "training accuracy: 0.17115987460815046\ttraining loss: 1.1648810394692197\tvalidation accuracy: 0.20448717948717948\tvalidation loss:0.6397995583522014\n",
            "Correct number of outputs in validation: 319\tTotal number of outputs in validation: 1560\tTotal validation loss 998.0873110294342\n",
            "Epoch 27:\n",
            "training accuracy: 0.1688087774294671\ttraining loss: 1.095930633985884\tvalidation accuracy: 0.191025641025641\tvalidation loss:0.8438718639887296\n",
            "Correct number of outputs in validation: 298\tTotal number of outputs in validation: 1560\tTotal validation loss 1316.4401078224182\n",
            "Epoch 28:\n",
            "training accuracy: 0.17774294670846394\ttraining loss: 1.0127615675657147\tvalidation accuracy: 0.16666666666666666\tvalidation loss:0.4799010782669752\n",
            "Correct number of outputs in validation: 260\tTotal number of outputs in validation: 1560\tTotal validation loss 748.6456820964813\n",
            "Epoch 29:\n",
            "training accuracy: 0.17586206896551723\ttraining loss: 1.0119684559985014\tvalidation accuracy: 0.16282051282051282\tvalidation loss:0.4251162814788329\n",
            "Correct number of outputs in validation: 254\tTotal number of outputs in validation: 1560\tTotal validation loss 663.1813991069794\n",
            "Epoch 30:\n",
            "training accuracy: 0.17037617554858933\ttraining loss: 0.9659824653852696\tvalidation accuracy: 0.2230769230769231\tvalidation loss:0.5471793054006039\n",
            "Correct number of outputs in validation: 348\tTotal number of outputs in validation: 1560\tTotal validation loss 853.599716424942\n",
            "Epoch 31:\n",
            "training accuracy: 0.15940438871473353\ttraining loss: 0.9781417165430362\tvalidation accuracy: 0.2064102564102564\tvalidation loss:0.498714881676894\n",
            "Correct number of outputs in validation: 322\tTotal number of outputs in validation: 1560\tTotal validation loss 777.9952154159546\n",
            "Epoch 32:\n",
            "training accuracy: 0.15532915360501567\ttraining loss: 0.9493028638318041\tvalidation accuracy: 0.19294871794871796\tvalidation loss:0.4355106616631532\n",
            "Correct number of outputs in validation: 301\tTotal number of outputs in validation: 1560\tTotal validation loss 679.396632194519\n",
            "Epoch 33:\n",
            "training accuracy: 0.16504702194357368\ttraining loss: 1.0186912548953089\tvalidation accuracy: 0.23653846153846153\tvalidation loss:0.8128454972536135\n",
            "Correct number of outputs in validation: 369\tTotal number of outputs in validation: 1560\tTotal validation loss 1268.0389757156372\n",
            "Epoch 34:\n",
            "training accuracy: 0.1590909090909091\ttraining loss: 0.9312453912717048\tvalidation accuracy: 0.19807692307692307\tvalidation loss:0.4873193288460756\n",
            "Correct number of outputs in validation: 309\tTotal number of outputs in validation: 1560\tTotal validation loss 760.2181529998779\n",
            "Epoch 35:\n",
            "training accuracy: 0.1750783699059561\ttraining loss: 0.7949940839904976\tvalidation accuracy: 0.17884615384615385\tvalidation loss:0.4261876560174502\n",
            "Correct number of outputs in validation: 279\tTotal number of outputs in validation: 1560\tTotal validation loss 664.8527433872223\n",
            "Epoch 36:\n",
            "training accuracy: 0.1797805642633229\ttraining loss: 0.8182693383910439\tvalidation accuracy: 0.14807692307692308\tvalidation loss:0.5158063848813375\n",
            "Correct number of outputs in validation: 231\tTotal number of outputs in validation: 1560\tTotal validation loss 804.6579604148865\n",
            "Epoch 37:\n",
            "training accuracy: 0.17774294670846394\ttraining loss: 0.8138082607599635\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.5414903882222298\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 844.7250056266785\n",
            "Epoch 38:\n",
            "training accuracy: 0.1811912225705329\ttraining loss: 0.7477106988616872\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.42491015104147106\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 662.8598356246948\n",
            "Epoch 39:\n",
            "training accuracy: 0.17695924764890283\ttraining loss: 0.6440409338212686\tvalidation accuracy: 0.1467948717948718\tvalidation loss:0.4741372070251367\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 739.6540429592133\n",
            "Epoch 40:\n",
            "training accuracy: 0.1738244514106583\ttraining loss: 0.6450564606996912\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.4424832680286505\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 690.2738981246948\n",
            "Epoch 41:\n",
            "training accuracy: 0.17178683385579938\ttraining loss: 0.6269799202213466\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.5359769695844405\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 836.1240725517273\n",
            "Epoch 42:\n",
            "training accuracy: 0.1700626959247649\ttraining loss: 0.6246846680357164\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.5985278410789294\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 933.7034320831299\n",
            "Epoch 43:\n",
            "training accuracy: 0.1719435736677116\ttraining loss: 0.5948184012152185\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.5954103133617303\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 928.8400888442993\n",
            "Epoch 44:\n",
            "training accuracy: 0.16614420062695925\ttraining loss: 0.568616142186999\tvalidation accuracy: 0.14166666666666666\tvalidation loss:0.5989595572153728\n",
            "Correct number of outputs in validation: 221\tTotal number of outputs in validation: 1560\tTotal validation loss 934.3769092559814\n",
            "Epoch 45:\n",
            "training accuracy: 0.16050156739811913\ttraining loss: 0.5682031099699134\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.5593439527046986\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 872.5765662193298\n",
            "Epoch 46:\n",
            "training accuracy: 0.1700626959247649\ttraining loss: 0.5606198263953098\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.4731483085033221\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 738.1113612651825\n",
            "Epoch 47:\n",
            "training accuracy: 0.1719435736677116\ttraining loss: 0.5374724801618104\tvalidation accuracy: 0.14807692307692308\tvalidation loss:0.46469641495973635\n",
            "Correct number of outputs in validation: 231\tTotal number of outputs in validation: 1560\tTotal validation loss 724.9264073371887\n",
            "Epoch 48:\n",
            "training accuracy: 0.1669278996865204\ttraining loss: 0.5127832565188034\tvalidation accuracy: 0.15128205128205127\tvalidation loss:0.3736423507714883\n",
            "Correct number of outputs in validation: 236\tTotal number of outputs in validation: 1560\tTotal validation loss 582.8820672035217\n",
            "Epoch 49:\n",
            "training accuracy: 0.17225705329153604\ttraining loss: 0.5080313379488022\tvalidation accuracy: 0.15064102564102563\tvalidation loss:0.3706699259770222\n",
            "Correct number of outputs in validation: 235\tTotal number of outputs in validation: 1560\tTotal validation loss 578.2450845241547\n",
            "Epoch 50:\n",
            "training accuracy: 0.17539184952978057\ttraining loss: 0.47068982528855435\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.3410527181931031\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 532.0422403812408\n",
            "Epoch 51:\n",
            "training accuracy: 0.17852664576802507\ttraining loss: 0.46772112493231005\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.39627100703043816\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 618.1827709674835\n",
            "Epoch 52:\n",
            "training accuracy: 0.17476489028213166\ttraining loss: 0.4593215822239281\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.37516409617203933\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 585.2559900283813\n",
            "Epoch 53:\n",
            "training accuracy: 0.17523510971786835\ttraining loss: 0.45730059569158527\tvalidation accuracy: 0.14743589743589744\tvalidation loss:0.3992455841639103\n",
            "Correct number of outputs in validation: 230\tTotal number of outputs in validation: 1560\tTotal validation loss 622.8231112957001\n",
            "Epoch 54:\n",
            "training accuracy: 0.1797805642633229\ttraining loss: 0.4454297432892001\tvalidation accuracy: 0.14807692307692308\tvalidation loss:0.40120320167296974\n",
            "Correct number of outputs in validation: 231\tTotal number of outputs in validation: 1560\tTotal validation loss 625.8769946098328\n",
            "Epoch 55:\n",
            "training accuracy: 0.1847962382445141\ttraining loss: 0.44134415158283746\tvalidation accuracy: 0.15128205128205127\tvalidation loss:0.36430255342752504\n",
            "Correct number of outputs in validation: 236\tTotal number of outputs in validation: 1560\tTotal validation loss 568.3119833469391\n",
            "Epoch 56:\n",
            "training accuracy: 0.19592476489028213\ttraining loss: 0.42208015971983487\tvalidation accuracy: 0.16666666666666666\tvalidation loss:0.3278278541870606\n",
            "Correct number of outputs in validation: 260\tTotal number of outputs in validation: 1560\tTotal validation loss 511.4114525318146\n",
            "Epoch 57:\n",
            "training accuracy: 0.19404388714733542\ttraining loss: 0.4114520819116162\tvalidation accuracy: 0.16538461538461538\tvalidation loss:0.33281152278949055\n",
            "Correct number of outputs in validation: 258\tTotal number of outputs in validation: 1560\tTotal validation loss 519.1859755516052\n",
            "Epoch 58:\n",
            "training accuracy: 0.19122257053291536\ttraining loss: 0.413981163800697\tvalidation accuracy: 0.18205128205128204\tvalidation loss:0.31368022973720844\n",
            "Correct number of outputs in validation: 284\tTotal number of outputs in validation: 1560\tTotal validation loss 489.34115839004517\n",
            "Epoch 59:\n",
            "training accuracy: 0.18683385579937303\ttraining loss: 0.42542156983505597\tvalidation accuracy: 0.16474358974358974\tvalidation loss:0.33466291534595\n",
            "Correct number of outputs in validation: 257\tTotal number of outputs in validation: 1560\tTotal validation loss 522.074147939682\n",
            "Epoch 60:\n",
            "training accuracy: 0.1847962382445141\ttraining loss: 0.45976848387419245\tvalidation accuracy: 0.20705128205128207\tvalidation loss:0.2958120379692469\n",
            "Correct number of outputs in validation: 323\tTotal number of outputs in validation: 1560\tTotal validation loss 461.46677923202515\n",
            "Epoch 61:\n",
            "training accuracy: 0.1981191222570533\ttraining loss: 0.507607675532936\tvalidation accuracy: 0.27115384615384613\tvalidation loss:0.2751832173420833\n",
            "Correct number of outputs in validation: 423\tTotal number of outputs in validation: 1560\tTotal validation loss 429.2858190536499\n",
            "Epoch 62:\n",
            "training accuracy: 0.19247648902821315\ttraining loss: 0.5031237797490482\tvalidation accuracy: 0.22179487179487178\tvalidation loss:0.30930618185263414\n",
            "Correct number of outputs in validation: 346\tTotal number of outputs in validation: 1560\tTotal validation loss 482.51764369010925\n",
            "Epoch 63:\n",
            "training accuracy: 0.18307210031347962\ttraining loss: 0.5264697245202468\tvalidation accuracy: 0.14423076923076922\tvalidation loss:1.07060527129051\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 1670.1442232131958\n",
            "Epoch 64:\n",
            "training accuracy: 0.1688087774294671\ttraining loss: 0.43058755975158236\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.5249612560639014\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 818.9395594596863\n",
            "Epoch 65:\n",
            "training accuracy: 0.1877742946708464\ttraining loss: 0.3178167396391447\tvalidation accuracy: 0.1519230769230769\tvalidation loss:0.5527181738462204\n",
            "Correct number of outputs in validation: 237\tTotal number of outputs in validation: 1560\tTotal validation loss 862.2403512001038\n",
            "Epoch 66:\n",
            "training accuracy: 0.18683385579937303\ttraining loss: 0.3267200174937054\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.5074663030795562\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 791.6474328041077\n",
            "Epoch 67:\n",
            "training accuracy: 0.19357366771159876\ttraining loss: 0.32859418059591217\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.48734069695839516\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 760.2514872550964\n",
            "Epoch 68:\n",
            "training accuracy: 0.1896551724137931\ttraining loss: 0.3327276949598498\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.41098153866254367\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 641.1312003135681\n",
            "Epoch 69:\n",
            "training accuracy: 0.20172413793103447\ttraining loss: 0.3115000934436403\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.39569723453277195\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 617.2876858711243\n",
            "Epoch 70:\n",
            "training accuracy: 0.2079937304075235\ttraining loss: 0.3190859774810767\tvalidation accuracy: 0.15576923076923077\tvalidation loss:0.3886371102088537\n",
            "Correct number of outputs in validation: 243\tTotal number of outputs in validation: 1560\tTotal validation loss 606.2738919258118\n",
            "Epoch 71:\n",
            "training accuracy: 0.21724137931034482\ttraining loss: 0.29623489951638965\tvalidation accuracy: 0.30128205128205127\tvalidation loss:0.33004875977834064\n",
            "Correct number of outputs in validation: 470\tTotal number of outputs in validation: 1560\tTotal validation loss 514.8760652542114\n",
            "Epoch 72:\n",
            "training accuracy: 0.23605015673981192\ttraining loss: 0.3078873176186062\tvalidation accuracy: 0.27564102564102566\tvalidation loss:0.2829377992030902\n",
            "Correct number of outputs in validation: 430\tTotal number of outputs in validation: 1560\tTotal validation loss 441.3829667568207\n",
            "Epoch 73:\n",
            "training accuracy: 0.23056426332288402\ttraining loss: 0.2994992985620768\tvalidation accuracy: 0.3211538461538462\tvalidation loss:0.2086559983400198\n",
            "Correct number of outputs in validation: 501\tTotal number of outputs in validation: 1560\tTotal validation loss 325.5033574104309\n",
            "Epoch 74:\n",
            "training accuracy: 0.23620689655172414\ttraining loss: 0.3075168595044964\tvalidation accuracy: 0.2423076923076923\tvalidation loss:0.22213112880022098\n",
            "Correct number of outputs in validation: 378\tTotal number of outputs in validation: 1560\tTotal validation loss 346.5245609283447\n",
            "Epoch 75:\n",
            "training accuracy: 0.2426332288401254\ttraining loss: 0.30874310193764376\tvalidation accuracy: 0.17884615384615385\tvalidation loss:0.30103008701251105\n",
            "Correct number of outputs in validation: 279\tTotal number of outputs in validation: 1560\tTotal validation loss 469.6069357395172\n",
            "Epoch 76:\n",
            "training accuracy: 0.20282131661442007\ttraining loss: 0.31947871538165223\tvalidation accuracy: 0.24102564102564103\tvalidation loss:0.5293178807466458\n",
            "Correct number of outputs in validation: 376\tTotal number of outputs in validation: 1560\tTotal validation loss 825.7358939647675\n",
            "Epoch 77:\n",
            "training accuracy: 0.22946708463949844\ttraining loss: 0.2640642850937141\tvalidation accuracy: 0.23333333333333334\tvalidation loss:0.3863688533122723\n",
            "Correct number of outputs in validation: 364\tTotal number of outputs in validation: 1560\tTotal validation loss 602.7354111671448\n",
            "Epoch 78:\n",
            "training accuracy: 0.24294670846394983\ttraining loss: 0.24513417439400964\tvalidation accuracy: 0.22884615384615384\tvalidation loss:0.37485745297028467\n",
            "Correct number of outputs in validation: 357\tTotal number of outputs in validation: 1560\tTotal validation loss 584.7776266336441\n",
            "Epoch 79:\n",
            "training accuracy: 0.24655172413793103\ttraining loss: 0.2400207788779818\tvalidation accuracy: 0.2282051282051282\tvalidation loss:0.33808963757294874\n",
            "Correct number of outputs in validation: 356\tTotal number of outputs in validation: 1560\tTotal validation loss 527.4198346138\n",
            "Epoch 80:\n",
            "training accuracy: 0.25407523510971786\ttraining loss: 0.23171553899501932\tvalidation accuracy: 0.20448717948717948\tvalidation loss:0.3335543752480776\n",
            "Correct number of outputs in validation: 319\tTotal number of outputs in validation: 1560\tTotal validation loss 520.344825387001\n",
            "Epoch 81:\n",
            "training accuracy: 0.2493730407523511\ttraining loss: 0.24051328279007939\tvalidation accuracy: 0.1955128205128205\tvalidation loss:0.32207538684209186\n",
            "Correct number of outputs in validation: 305\tTotal number of outputs in validation: 1560\tTotal validation loss 502.43760347366333\n",
            "Epoch 82:\n",
            "training accuracy: 0.24545454545454545\ttraining loss: 0.23632060405228952\tvalidation accuracy: 0.20448717948717948\tvalidation loss:0.3252300852384323\n",
            "Correct number of outputs in validation: 319\tTotal number of outputs in validation: 1560\tTotal validation loss 507.35893297195435\n",
            "Epoch 83:\n",
            "training accuracy: 0.24231974921630095\ttraining loss: 0.24068016823743205\tvalidation accuracy: 0.29743589743589743\tvalidation loss:0.31597023201294433\n",
            "Correct number of outputs in validation: 464\tTotal number of outputs in validation: 1560\tTotal validation loss 492.9135619401932\n",
            "Epoch 84:\n",
            "training accuracy: 0.24623824451410659\ttraining loss: 0.24310497982561774\tvalidation accuracy: 0.3294871794871795\tvalidation loss:0.3256567096863037\n",
            "Correct number of outputs in validation: 514\tTotal number of outputs in validation: 1560\tTotal validation loss 508.02446711063385\n",
            "Epoch 85:\n",
            "training accuracy: 0.2567398119122257\ttraining loss: 0.22599363647471402\tvalidation accuracy: 0.2967948717948718\tvalidation loss:0.33733145059683384\n",
            "Correct number of outputs in validation: 463\tTotal number of outputs in validation: 1560\tTotal validation loss 526.2370629310608\n",
            "Epoch 86:\n",
            "training accuracy: 0.24373040752351097\ttraining loss: 0.2237369600788553\tvalidation accuracy: 0.23846153846153847\tvalidation loss:0.3653957962989807\n",
            "Correct number of outputs in validation: 372\tTotal number of outputs in validation: 1560\tTotal validation loss 570.0174422264099\n",
            "Epoch 87:\n",
            "training accuracy: 0.23025078369905957\ttraining loss: 0.22506279594098513\tvalidation accuracy: 0.2814102564102564\tvalidation loss:0.2575831474402012\n",
            "Correct number of outputs in validation: 439\tTotal number of outputs in validation: 1560\tTotal validation loss 401.82971000671387\n",
            "Epoch 88:\n",
            "training accuracy: 0.23620689655172414\ttraining loss: 0.2027908274279119\tvalidation accuracy: 0.33653846153846156\tvalidation loss:0.19242107379130827\n",
            "Correct number of outputs in validation: 525\tTotal number of outputs in validation: 1560\tTotal validation loss 300.1768751144409\n",
            "Epoch 89:\n",
            "training accuracy: 0.25141065830721004\ttraining loss: 0.18892704741708163\tvalidation accuracy: 0.266025641025641\tvalidation loss:0.18671226096458923\n",
            "Correct number of outputs in validation: 415\tTotal number of outputs in validation: 1560\tTotal validation loss 291.2711271047592\n",
            "Epoch 90:\n",
            "training accuracy: 0.24717868338557994\ttraining loss: 0.18801400307390756\tvalidation accuracy: 0.3596153846153846\tvalidation loss:0.17086744052477373\n",
            "Correct number of outputs in validation: 561\tTotal number of outputs in validation: 1560\tTotal validation loss 266.553207218647\n",
            "Epoch 91:\n",
            "training accuracy: 0.24780564263322885\ttraining loss: 0.18499348988540493\tvalidation accuracy: 0.34615384615384615\tvalidation loss:0.15858683100877663\n",
            "Correct number of outputs in validation: 540\tTotal number of outputs in validation: 1560\tTotal validation loss 247.39545637369156\n",
            "Epoch 92:\n",
            "training accuracy: 0.2782131661442006\ttraining loss: 0.1770597527299929\tvalidation accuracy: 0.35833333333333334\tvalidation loss:0.15192753894206806\n",
            "Correct number of outputs in validation: 559\tTotal number of outputs in validation: 1560\tTotal validation loss 237.00696074962616\n",
            "Epoch 93:\n",
            "training accuracy: 0.2811912225705329\ttraining loss: 0.18167608229904714\tvalidation accuracy: 0.37051282051282053\tvalidation loss:0.1405103996396065\n",
            "Correct number of outputs in validation: 578\tTotal number of outputs in validation: 1560\tTotal validation loss 219.1962234377861\n",
            "Epoch 94:\n",
            "training accuracy: 0.30094043887147337\ttraining loss: 0.1771220658546705\tvalidation accuracy: 0.40192307692307694\tvalidation loss:0.12966097746139918\n",
            "Correct number of outputs in validation: 627\tTotal number of outputs in validation: 1560\tTotal validation loss 202.27112483978271\n",
            "Epoch 95:\n",
            "training accuracy: 0.32241379310344825\ttraining loss: 0.17210451024453094\tvalidation accuracy: 0.4403846153846154\tvalidation loss:0.12389889944058198\n",
            "Correct number of outputs in validation: 687\tTotal number of outputs in validation: 1560\tTotal validation loss 193.2822831273079\n",
            "Epoch 96:\n",
            "training accuracy: 0.3203761755485893\ttraining loss: 0.17778437024560467\tvalidation accuracy: 0.4403846153846154\tvalidation loss:0.12659740910316125\n",
            "Correct number of outputs in validation: 687\tTotal number of outputs in validation: 1560\tTotal validation loss 197.49195820093155\n",
            "Epoch 97:\n",
            "training accuracy: 0.3415360501567398\ttraining loss: 0.17113119508592312\tvalidation accuracy: 0.4230769230769231\tvalidation loss:0.12286668144739592\n",
            "Correct number of outputs in validation: 660\tTotal number of outputs in validation: 1560\tTotal validation loss 191.67202305793762\n",
            "Epoch 98:\n",
            "training accuracy: 0.3575235109717868\ttraining loss: 0.1645218408780412\tvalidation accuracy: 0.44743589743589746\tvalidation loss:0.12141061673561732\n",
            "Correct number of outputs in validation: 698\tTotal number of outputs in validation: 1560\tTotal validation loss 189.40056210756302\n",
            "Epoch 99:\n",
            "training accuracy: 0.36802507836990594\ttraining loss: 0.16407016040202593\tvalidation accuracy: 0.4596153846153846\tvalidation loss:0.12488426409470729\n",
            "Correct number of outputs in validation: 717\tTotal number of outputs in validation: 1560\tTotal validation loss 194.81945198774338\n",
            "Epoch 100:\n",
            "training accuracy: 0.3749216300940439\ttraining loss: 0.16838084660166858\tvalidation accuracy: 0.38269230769230766\tvalidation loss:0.15301859783820618\n",
            "Correct number of outputs in validation: 597\tTotal number of outputs in validation: 1560\tTotal validation loss 238.70901262760162\n",
            "Epoch 101:\n",
            "training accuracy: 0.3938871473354232\ttraining loss: 0.16237248416324393\tvalidation accuracy: 0.4230769230769231\tvalidation loss:0.14626761835355026\n",
            "Correct number of outputs in validation: 660\tTotal number of outputs in validation: 1560\tTotal validation loss 228.1774846315384\n",
            "Epoch 102:\n",
            "training accuracy: 0.4177115987460815\ttraining loss: 0.15814698995280788\tvalidation accuracy: 0.4064102564102564\tvalidation loss:0.15831433431460307\n",
            "Correct number of outputs in validation: 634\tTotal number of outputs in validation: 1560\tTotal validation loss 246.9703615307808\n",
            "Epoch 103:\n",
            "training accuracy: 0.42758620689655175\ttraining loss: 0.15431896232792577\tvalidation accuracy: 0.37756410256410255\tvalidation loss:0.19480991279467558\n",
            "Correct number of outputs in validation: 589\tTotal number of outputs in validation: 1560\tTotal validation loss 303.9034639596939\n",
            "Epoch 104:\n",
            "training accuracy: 0.4158307210031348\ttraining loss: 0.15526083741442162\tvalidation accuracy: 0.38333333333333336\tvalidation loss:0.1961659291997934\n",
            "Correct number of outputs in validation: 598\tTotal number of outputs in validation: 1560\tTotal validation loss 306.0188495516777\n",
            "Epoch 105:\n",
            "training accuracy: 0.41724137931034483\ttraining loss: 0.15617967030284546\tvalidation accuracy: 0.37756410256410255\tvalidation loss:0.17157327395219069\n",
            "Correct number of outputs in validation: 589\tTotal number of outputs in validation: 1560\tTotal validation loss 267.6543073654175\n",
            "Epoch 106:\n",
            "training accuracy: 0.430564263322884\ttraining loss: 0.15126167943111407\tvalidation accuracy: 0.44551282051282054\tvalidation loss:0.13238966690424162\n",
            "Correct number of outputs in validation: 695\tTotal number of outputs in validation: 1560\tTotal validation loss 206.5278803706169\n",
            "Epoch 107:\n",
            "training accuracy: 0.45846394984326017\ttraining loss: 0.1408337780580999\tvalidation accuracy: 0.5333333333333333\tvalidation loss:0.1163183046075014\n",
            "Correct number of outputs in validation: 832\tTotal number of outputs in validation: 1560\tTotal validation loss 181.45655518770218\n",
            "Epoch 108:\n",
            "training accuracy: 0.4581504702194357\ttraining loss: 0.1436631154677711\tvalidation accuracy: 0.5705128205128205\tvalidation loss:0.11173426325504597\n",
            "Correct number of outputs in validation: 890\tTotal number of outputs in validation: 1560\tTotal validation loss 174.3054506778717\n",
            "Epoch 109:\n",
            "training accuracy: 0.46849529780564264\ttraining loss: 0.13854647324563568\tvalidation accuracy: 0.6057692307692307\tvalidation loss:0.09768732832028315\n",
            "Correct number of outputs in validation: 945\tTotal number of outputs in validation: 1560\tTotal validation loss 152.39223217964172\n",
            "Epoch 110:\n",
            "training accuracy: 0.4962382445141066\ttraining loss: 0.13090707493426285\tvalidation accuracy: 0.6051282051282051\tvalidation loss:0.096226050838446\n",
            "Correct number of outputs in validation: 944\tTotal number of outputs in validation: 1560\tTotal validation loss 150.11263930797577\n",
            "Epoch 111:\n",
            "training accuracy: 0.5178683385579937\ttraining loss: 0.1270189503330422\tvalidation accuracy: 0.6192307692307693\tvalidation loss:0.09381763163285378\n",
            "Correct number of outputs in validation: 966\tTotal number of outputs in validation: 1560\tTotal validation loss 146.3555053472519\n",
            "Epoch 112:\n",
            "training accuracy: 0.5139498432601881\ttraining loss: 0.1282495008647255\tvalidation accuracy: 0.5916666666666667\tvalidation loss:0.09645951164838595\n",
            "Correct number of outputs in validation: 923\tTotal number of outputs in validation: 1560\tTotal validation loss 150.4768381714821\n",
            "Epoch 113:\n",
            "training accuracy: 0.542319749216301\ttraining loss: 0.11646019732316833\tvalidation accuracy: 0.6487179487179487\tvalidation loss:0.09542349091707132\n",
            "Correct number of outputs in validation: 1012\tTotal number of outputs in validation: 1560\tTotal validation loss 148.86064583063126\n",
            "Epoch 114:\n",
            "training accuracy: 0.5336990595611285\ttraining loss: 0.12060180740390078\tvalidation accuracy: 0.6173076923076923\tvalidation loss:0.09999475689270558\n",
            "Correct number of outputs in validation: 963\tTotal number of outputs in validation: 1560\tTotal validation loss 155.9918207526207\n",
            "Epoch 115:\n",
            "training accuracy: 0.5346394984326018\ttraining loss: 0.11991502595452305\tvalidation accuracy: 0.6410256410256411\tvalidation loss:0.09612203882290767\n",
            "Correct number of outputs in validation: 1000\tTotal number of outputs in validation: 1560\tTotal validation loss 149.95038056373596\n",
            "Epoch 116:\n",
            "training accuracy: 0.5648902821316615\ttraining loss: 0.11280770319569447\tvalidation accuracy: 0.6474358974358975\tvalidation loss:0.09535806840046858\n",
            "Correct number of outputs in validation: 1010\tTotal number of outputs in validation: 1560\tTotal validation loss 148.758586704731\n",
            "Epoch 117:\n",
            "training accuracy: 0.5407523510971787\ttraining loss: 0.11952586440270224\tvalidation accuracy: 0.5205128205128206\tvalidation loss:0.10647081621946433\n",
            "Correct number of outputs in validation: 812\tTotal number of outputs in validation: 1560\tTotal validation loss 166.09447330236435\n",
            "Epoch 118:\n",
            "training accuracy: 0.5489028213166144\ttraining loss: 0.11724425820067384\tvalidation accuracy: 0.6307692307692307\tvalidation loss:0.09794941433729269\n",
            "Correct number of outputs in validation: 984\tTotal number of outputs in validation: 1560\tTotal validation loss 152.8010863661766\n",
            "Epoch 119:\n",
            "training accuracy: 0.527742946708464\ttraining loss: 0.1277284286986324\tvalidation accuracy: 0.5826923076923077\tvalidation loss:0.10592537434437337\n",
            "Correct number of outputs in validation: 909\tTotal number of outputs in validation: 1560\tTotal validation loss 165.24358397722244\n",
            "Epoch 120:\n",
            "training accuracy: 0.55\ttraining loss: 0.1197625852397243\tvalidation accuracy: 0.6262820512820513\tvalidation loss:0.09859412526473021\n",
            "Correct number of outputs in validation: 977\tTotal number of outputs in validation: 1560\tTotal validation loss 153.80683541297913\n",
            "Epoch 121:\n",
            "training accuracy: 0.541692789968652\ttraining loss: 0.12542433762064548\tvalidation accuracy: 0.5743589743589743\tvalidation loss:0.1281220468191\n",
            "Correct number of outputs in validation: 896\tTotal number of outputs in validation: 1560\tTotal validation loss 199.87039303779602\n",
            "Epoch 122:\n",
            "training accuracy: 0.5213166144200627\ttraining loss: 0.13274478086483515\tvalidation accuracy: 0.5903846153846154\tvalidation loss:0.10538609834053578\n",
            "Correct number of outputs in validation: 921\tTotal number of outputs in validation: 1560\tTotal validation loss 164.4023134112358\n",
            "Epoch 123:\n",
            "training accuracy: 0.5195924764890282\ttraining loss: 0.12520350456518065\tvalidation accuracy: 0.6019230769230769\tvalidation loss:0.12135580059809563\n",
            "Correct number of outputs in validation: 939\tTotal number of outputs in validation: 1560\tTotal validation loss 189.31504893302917\n",
            "Epoch 124:\n",
            "training accuracy: 0.565987460815047\ttraining loss: 0.11132403556082315\tvalidation accuracy: 0.5583333333333333\tvalidation loss:0.10968431796018895\n",
            "Correct number of outputs in validation: 871\tTotal number of outputs in validation: 1560\tTotal validation loss 171.10753601789474\n",
            "Epoch 125:\n",
            "training accuracy: 0.5799373040752351\ttraining loss: 0.10691952096724584\tvalidation accuracy: 0.6012820512820513\tvalidation loss:0.09761940523599967\n",
            "Correct number of outputs in validation: 938\tTotal number of outputs in validation: 1560\tTotal validation loss 152.28627216815948\n",
            "Epoch 126:\n",
            "training accuracy: 0.5799373040752351\ttraining loss: 0.10809568788470893\tvalidation accuracy: 0.6288461538461538\tvalidation loss:0.09812525992210094\n",
            "Correct number of outputs in validation: 981\tTotal number of outputs in validation: 1560\tTotal validation loss 153.07540547847748\n",
            "Epoch 127:\n",
            "training accuracy: 0.59858934169279\ttraining loss: 0.10635752577486457\tvalidation accuracy: 0.6294871794871795\tvalidation loss:0.09323086990759923\n",
            "Correct number of outputs in validation: 982\tTotal number of outputs in validation: 1560\tTotal validation loss 145.4401570558548\n",
            "Epoch 128:\n",
            "training accuracy: 0.5736677115987461\ttraining loss: 0.10823804222771366\tvalidation accuracy: 0.6583333333333333\tvalidation loss:0.08795510255373441\n",
            "Correct number of outputs in validation: 1027\tTotal number of outputs in validation: 1560\tTotal validation loss 137.20995998382568\n",
            "Epoch 129:\n",
            "training accuracy: 0.574294670846395\ttraining loss: 0.11363677669281497\tvalidation accuracy: 0.6596153846153846\tvalidation loss:0.11692962149779002\n",
            "Correct number of outputs in validation: 1029\tTotal number of outputs in validation: 1560\tTotal validation loss 182.41020953655243\n",
            "Epoch 130:\n",
            "training accuracy: 0.5952978056426332\ttraining loss: 0.10671699218522045\tvalidation accuracy: 0.6634615384615384\tvalidation loss:0.10390260838545286\n",
            "Correct number of outputs in validation: 1035\tTotal number of outputs in validation: 1560\tTotal validation loss 162.08806908130646\n",
            "Epoch 131:\n",
            "training accuracy: 0.6318181818181818\ttraining loss: 0.09560963105071675\tvalidation accuracy: 0.6916666666666667\tvalidation loss:0.09434738717018029\n",
            "Correct number of outputs in validation: 1079\tTotal number of outputs in validation: 1560\tTotal validation loss 147.18192398548126\n",
            "Epoch 132:\n",
            "training accuracy: 0.6310344827586207\ttraining loss: 0.09742095616637353\tvalidation accuracy: 0.6846153846153846\tvalidation loss:0.09328518047546729\n",
            "Correct number of outputs in validation: 1068\tTotal number of outputs in validation: 1560\tTotal validation loss 145.52488154172897\n",
            "Epoch 133:\n",
            "training accuracy: 0.6349529780564264\ttraining loss: 0.09571441302665723\tvalidation accuracy: 0.6519230769230769\tvalidation loss:0.09347915271153817\n",
            "Correct number of outputs in validation: 1017\tTotal number of outputs in validation: 1560\tTotal validation loss 145.82747822999954\n",
            "Epoch 134:\n",
            "training accuracy: 0.662539184952978\ttraining loss: 0.09058525980826829\tvalidation accuracy: 0.6256410256410256\tvalidation loss:0.09549541656787579\n",
            "Correct number of outputs in validation: 976\tTotal number of outputs in validation: 1560\tTotal validation loss 148.97284984588623\n",
            "Epoch 135:\n",
            "training accuracy: 0.6619122257053291\ttraining loss: 0.08923234650894392\tvalidation accuracy: 0.6717948717948717\tvalidation loss:0.09060254559302941\n",
            "Correct number of outputs in validation: 1048\tTotal number of outputs in validation: 1560\tTotal validation loss 141.33997112512589\n",
            "Epoch 136:\n",
            "training accuracy: 0.6703761755485893\ttraining loss: 0.0869965842198055\tvalidation accuracy: 0.6865384615384615\tvalidation loss:0.0846451066625424\n",
            "Correct number of outputs in validation: 1071\tTotal number of outputs in validation: 1560\tTotal validation loss 132.04636639356613\n",
            "Epoch 137:\n",
            "training accuracy: 0.6913793103448276\ttraining loss: 0.08337139575552417\tvalidation accuracy: 0.6993589743589743\tvalidation loss:0.08974291838896581\n",
            "Correct number of outputs in validation: 1091\tTotal number of outputs in validation: 1560\tTotal validation loss 139.99895268678665\n",
            "Epoch 138:\n",
            "training accuracy: 0.7003134796238244\ttraining loss: 0.08068880324359971\tvalidation accuracy: 0.7102564102564103\tvalidation loss:0.08487330105824348\n",
            "Correct number of outputs in validation: 1108\tTotal number of outputs in validation: 1560\tTotal validation loss 132.40234965085983\n",
            "Epoch 139:\n",
            "training accuracy: 0.7130094043887147\ttraining loss: 0.08031792761670385\tvalidation accuracy: 0.732051282051282\tvalidation loss:0.07773241519163816\n",
            "Correct number of outputs in validation: 1142\tTotal number of outputs in validation: 1560\tTotal validation loss 121.26256769895554\n",
            "Epoch 140:\n",
            "training accuracy: 0.7136363636363636\ttraining loss: 0.0778420216821391\tvalidation accuracy: 0.7455128205128205\tvalidation loss:0.0766249785438562\n",
            "Correct number of outputs in validation: 1163\tTotal number of outputs in validation: 1560\tTotal validation loss 119.53496652841568\n",
            "Epoch 141:\n",
            "training accuracy: 0.7247648902821316\ttraining loss: 0.07649174817490353\tvalidation accuracy: 0.7487179487179487\tvalidation loss:0.07541448378410094\n",
            "Correct number of outputs in validation: 1168\tTotal number of outputs in validation: 1560\tTotal validation loss 117.64659470319748\n",
            "Epoch 142:\n",
            "training accuracy: 0.7180250783699059\ttraining loss: 0.07802152865592589\tvalidation accuracy: 0.7583333333333333\tvalidation loss:0.0733245638700632\n",
            "Correct number of outputs in validation: 1183\tTotal number of outputs in validation: 1560\tTotal validation loss 114.38631963729858\n",
            "Epoch 143:\n",
            "training accuracy: 0.70282131661442\ttraining loss: 0.07985012301456966\tvalidation accuracy: 0.6685897435897435\tvalidation loss:0.0926192078452844\n",
            "Correct number of outputs in validation: 1043\tTotal number of outputs in validation: 1560\tTotal validation loss 144.48596423864365\n",
            "Epoch 144:\n",
            "training accuracy: 0.6974921630094044\ttraining loss: 0.08287488905520275\tvalidation accuracy: 0.717948717948718\tvalidation loss:0.08198244648102002\n",
            "Correct number of outputs in validation: 1120\tTotal number of outputs in validation: 1560\tTotal validation loss 127.89261651039124\n",
            "Epoch 145:\n",
            "training accuracy: 0.7172413793103448\ttraining loss: 0.07896541154776995\tvalidation accuracy: 0.7583333333333333\tvalidation loss:0.07438840839343193\n",
            "Correct number of outputs in validation: 1183\tTotal number of outputs in validation: 1560\tTotal validation loss 116.04591709375381\n",
            "Epoch 146:\n",
            "training accuracy: 0.7302507836990596\ttraining loss: 0.07700991772558996\tvalidation accuracy: 0.7352564102564103\tvalidation loss:0.07785787838391768\n",
            "Correct number of outputs in validation: 1147\tTotal number of outputs in validation: 1560\tTotal validation loss 121.45829027891159\n",
            "Epoch 147:\n",
            "training accuracy: 0.7283699059561128\ttraining loss: 0.0780385474145973\tvalidation accuracy: 0.7378205128205129\tvalidation loss:0.07479480482064761\n",
            "Correct number of outputs in validation: 1151\tTotal number of outputs in validation: 1560\tTotal validation loss 116.67989552021027\n",
            "Epoch 148:\n",
            "training accuracy: 0.746551724137931\ttraining loss: 0.07297642857630425\tvalidation accuracy: 0.7461538461538462\tvalidation loss:0.07321613429066462\n",
            "Correct number of outputs in validation: 1164\tTotal number of outputs in validation: 1560\tTotal validation loss 114.21716949343681\n",
            "Epoch 149:\n",
            "training accuracy: 0.7496865203761756\ttraining loss: 0.07369905638050137\tvalidation accuracy: 0.7621794871794871\tvalidation loss:0.06910872894984026\n",
            "Correct number of outputs in validation: 1189\tTotal number of outputs in validation: 1560\tTotal validation loss 107.8096171617508\n",
            "Epoch 150:\n",
            "training accuracy: 0.756896551724138\ttraining loss: 0.07108013817929548\tvalidation accuracy: 0.7551282051282051\tvalidation loss:0.06898154601072654\n",
            "Correct number of outputs in validation: 1178\tTotal number of outputs in validation: 1560\tTotal validation loss 107.6112117767334\n",
            "Epoch 151:\n",
            "training accuracy: 0.7655172413793103\ttraining loss: 0.07075113599950617\tvalidation accuracy: 0.7448717948717949\tvalidation loss:0.07482728469066131\n",
            "Correct number of outputs in validation: 1162\tTotal number of outputs in validation: 1560\tTotal validation loss 116.73056411743164\n",
            "Epoch 152:\n",
            "training accuracy: 0.7688087774294671\ttraining loss: 0.06876596590988689\tvalidation accuracy: 0.7756410256410257\tvalidation loss:0.06547254874156072\n",
            "Correct number of outputs in validation: 1210\tTotal number of outputs in validation: 1560\tTotal validation loss 102.13717603683472\n",
            "Epoch 153:\n",
            "training accuracy: 0.7641065830721003\ttraining loss: 0.07109170115339719\tvalidation accuracy: 0.7608974358974359\tvalidation loss:0.06664073782471511\n",
            "Correct number of outputs in validation: 1187\tTotal number of outputs in validation: 1560\tTotal validation loss 103.95955100655556\n",
            "Epoch 154:\n",
            "training accuracy: 0.768025078369906\ttraining loss: 0.06966621327596398\tvalidation accuracy: 0.7480769230769231\tvalidation loss:0.07146956865222026\n",
            "Correct number of outputs in validation: 1167\tTotal number of outputs in validation: 1560\tTotal validation loss 111.49252709746361\n",
            "Epoch 155:\n",
            "training accuracy: 0.7653605015673981\ttraining loss: 0.07205268448703342\tvalidation accuracy: 0.7583333333333333\tvalidation loss:0.06880219618861493\n",
            "Correct number of outputs in validation: 1183\tTotal number of outputs in validation: 1560\tTotal validation loss 107.33142605423927\n",
            "Epoch 156:\n",
            "training accuracy: 0.7778996865203762\ttraining loss: 0.0663159697570584\tvalidation accuracy: 0.767948717948718\tvalidation loss:0.07288031799670977\n",
            "Correct number of outputs in validation: 1198\tTotal number of outputs in validation: 1560\tTotal validation loss 113.69329607486725\n",
            "Epoch 157:\n",
            "training accuracy: 0.780564263322884\ttraining loss: 0.06933402084398045\tvalidation accuracy: 0.7673076923076924\tvalidation loss:0.07847716418596415\n",
            "Correct number of outputs in validation: 1197\tTotal number of outputs in validation: 1560\tTotal validation loss 122.42437613010406\n",
            "Epoch 158:\n",
            "training accuracy: 0.770846394984326\ttraining loss: 0.07049697058327893\tvalidation accuracy: 0.775\tvalidation loss:0.07189567379462414\n",
            "Correct number of outputs in validation: 1209\tTotal number of outputs in validation: 1560\tTotal validation loss 112.15725111961365\n",
            "Epoch 159:\n",
            "training accuracy: 0.7873040752351097\ttraining loss: 0.06633976670361612\tvalidation accuracy: 0.7346153846153847\tvalidation loss:0.0775450010330249\n",
            "Correct number of outputs in validation: 1146\tTotal number of outputs in validation: 1560\tTotal validation loss 120.97020161151886\n",
            "Epoch 160:\n",
            "training accuracy: 0.7716300940438872\ttraining loss: 0.07017513765343304\tvalidation accuracy: 0.7307692307692307\tvalidation loss:0.08115415236888787\n",
            "Correct number of outputs in validation: 1140\tTotal number of outputs in validation: 1560\tTotal validation loss 126.60047769546509\n",
            "Epoch 161:\n",
            "training accuracy: 0.7760188087774295\ttraining loss: 0.07103140806796783\tvalidation accuracy: 0.7455128205128205\tvalidation loss:0.08046087209994976\n",
            "Correct number of outputs in validation: 1163\tTotal number of outputs in validation: 1560\tTotal validation loss 125.51896047592163\n",
            "Epoch 162:\n",
            "training accuracy: 0.7942006269592476\ttraining loss: 0.06612834336008398\tvalidation accuracy: 0.7653846153846153\tvalidation loss:0.06927516618982339\n",
            "Correct number of outputs in validation: 1194\tTotal number of outputs in validation: 1560\tTotal validation loss 108.0692592561245\n",
            "Epoch 163:\n",
            "training accuracy: 0.8031347962382445\ttraining loss: 0.06436909864828878\tvalidation accuracy: 0.7583333333333333\tvalidation loss:0.07872080168662927\n",
            "Correct number of outputs in validation: 1183\tTotal number of outputs in validation: 1560\tTotal validation loss 122.80445063114166\n",
            "Epoch 164:\n",
            "training accuracy: 0.7913793103448276\ttraining loss: 0.06594025419096589\tvalidation accuracy: 0.7769230769230769\tvalidation loss:0.07227009552029463\n",
            "Correct number of outputs in validation: 1212\tTotal number of outputs in validation: 1560\tTotal validation loss 112.74134901165962\n",
            "Epoch 165:\n",
            "training accuracy: 0.7978056426332288\ttraining loss: 0.0659173079045215\tvalidation accuracy: 0.7608974358974359\tvalidation loss:0.06897872365438021\n",
            "Correct number of outputs in validation: 1187\tTotal number of outputs in validation: 1560\tTotal validation loss 107.60680890083313\n",
            "Epoch 166:\n",
            "training accuracy: 0.8012539184952978\ttraining loss: 0.06283589191618011\tvalidation accuracy: 0.7884615384615384\tvalidation loss:0.06870421925798441\n",
            "Correct number of outputs in validation: 1230\tTotal number of outputs in validation: 1560\tTotal validation loss 107.17858204245567\n",
            "Epoch 167:\n",
            "training accuracy: 0.8043887147335423\ttraining loss: 0.061071310804275136\tvalidation accuracy: 0.7724358974358975\tvalidation loss:0.07621338753364025\n",
            "Correct number of outputs in validation: 1205\tTotal number of outputs in validation: 1560\tTotal validation loss 118.89288455247879\n",
            "Epoch 168:\n",
            "training accuracy: 0.8059561128526646\ttraining loss: 0.06145247056099315\tvalidation accuracy: 0.7878205128205128\tvalidation loss:0.07292652600086652\n",
            "Correct number of outputs in validation: 1229\tTotal number of outputs in validation: 1560\tTotal validation loss 113.76538056135178\n",
            "Epoch 169:\n",
            "training accuracy: 0.8172413793103448\ttraining loss: 0.05893437638178141\tvalidation accuracy: 0.7743589743589744\tvalidation loss:0.06914339183996886\n",
            "Correct number of outputs in validation: 1208\tTotal number of outputs in validation: 1560\tTotal validation loss 107.86369127035141\n",
            "Epoch 170:\n",
            "training accuracy: 0.8148902821316615\ttraining loss: 0.059547691883338284\tvalidation accuracy: 0.7948717948717948\tvalidation loss:0.06919954520387528\n",
            "Correct number of outputs in validation: 1240\tTotal number of outputs in validation: 1560\tTotal validation loss 107.95129051804543\n",
            "Epoch 171:\n",
            "training accuracy: 0.8221003134796239\ttraining loss: 0.05664064490169193\tvalidation accuracy: 0.7942307692307692\tvalidation loss:0.06898648095054505\n",
            "Correct number of outputs in validation: 1239\tTotal number of outputs in validation: 1560\tTotal validation loss 107.61891028285027\n",
            "Epoch 172:\n",
            "training accuracy: 0.8191222570532916\ttraining loss: 0.058097402826185134\tvalidation accuracy: 0.7852564102564102\tvalidation loss:0.07640604571654247\n",
            "Correct number of outputs in validation: 1225\tTotal number of outputs in validation: 1560\tTotal validation loss 119.19343131780624\n",
            "Epoch 173:\n",
            "training accuracy: 0.8189655172413793\ttraining loss: 0.06189287146991323\tvalidation accuracy: 0.8032051282051282\tvalidation loss:0.06820802914026455\n",
            "Correct number of outputs in validation: 1253\tTotal number of outputs in validation: 1560\tTotal validation loss 106.40452545881271\n",
            "Epoch 174:\n",
            "training accuracy: 0.8090909090909091\ttraining loss: 0.06308296827313295\tvalidation accuracy: 0.7948717948717948\tvalidation loss:0.0687305649312643\n",
            "Correct number of outputs in validation: 1240\tTotal number of outputs in validation: 1560\tTotal validation loss 107.2196812927723\n",
            "Epoch 175:\n",
            "training accuracy: 0.8186520376175549\ttraining loss: 0.05929228105701997\tvalidation accuracy: 0.7794871794871795\tvalidation loss:0.06812256754208834\n",
            "Correct number of outputs in validation: 1216\tTotal number of outputs in validation: 1560\tTotal validation loss 106.2712053656578\n",
            "Epoch 176:\n",
            "training accuracy: 0.8225705329153605\ttraining loss: 0.05630760681012581\tvalidation accuracy: 0.7897435897435897\tvalidation loss:0.07199649774493315\n",
            "Correct number of outputs in validation: 1232\tTotal number of outputs in validation: 1560\tTotal validation loss 112.31453648209572\n",
            "Epoch 177:\n",
            "training accuracy: 0.8355799373040752\ttraining loss: 0.05442051927918177\tvalidation accuracy: 0.7878205128205128\tvalidation loss:0.07283045722123904\n",
            "Correct number of outputs in validation: 1229\tTotal number of outputs in validation: 1560\tTotal validation loss 113.6155132651329\n",
            "Epoch 178:\n",
            "training accuracy: 0.8280564263322884\ttraining loss: 0.05925020903675907\tvalidation accuracy: 0.7717948717948718\tvalidation loss:0.07665766236873774\n",
            "Correct number of outputs in validation: 1204\tTotal number of outputs in validation: 1560\tTotal validation loss 119.58595329523087\n",
            "Epoch 179:\n",
            "training accuracy: 0.8310344827586207\ttraining loss: 0.05622929098043696\tvalidation accuracy: 0.7730769230769231\tvalidation loss:0.08037913296467218\n",
            "Correct number of outputs in validation: 1206\tTotal number of outputs in validation: 1560\tTotal validation loss 125.39144742488861\n",
            "Epoch 180:\n",
            "training accuracy: 0.8330721003134797\ttraining loss: 0.05570902798943759\tvalidation accuracy: 0.764102564102564\tvalidation loss:0.07613699151537358\n",
            "Correct number of outputs in validation: 1192\tTotal number of outputs in validation: 1560\tTotal validation loss 118.77370676398277\n",
            "Epoch 181:\n",
            "training accuracy: 0.8206896551724138\ttraining loss: 0.06062433792505892\tvalidation accuracy: 0.7916666666666666\tvalidation loss:0.06804538344343504\n",
            "Correct number of outputs in validation: 1235\tTotal number of outputs in validation: 1560\tTotal validation loss 106.15079817175865\n",
            "Epoch 182:\n",
            "training accuracy: 0.8463949843260188\ttraining loss: 0.05244319239006521\tvalidation accuracy: 0.7923076923076923\tvalidation loss:0.06601258646219205\n",
            "Correct number of outputs in validation: 1236\tTotal number of outputs in validation: 1560\tTotal validation loss 102.97963488101959\n",
            "Epoch 183:\n",
            "training accuracy: 0.8495297805642633\ttraining loss: 0.05049391405008803\tvalidation accuracy: 0.7942307692307692\tvalidation loss:0.06580311598686071\n",
            "Correct number of outputs in validation: 1239\tTotal number of outputs in validation: 1560\tTotal validation loss 102.65286093950272\n",
            "Epoch 184:\n",
            "training accuracy: 0.8498432601880878\ttraining loss: 0.05211865354948283\tvalidation accuracy: 0.7858974358974359\tvalidation loss:0.06950945294438264\n",
            "Correct number of outputs in validation: 1226\tTotal number of outputs in validation: 1560\tTotal validation loss 108.43474659323692\n",
            "Epoch 185:\n",
            "training accuracy: 0.8336990595611286\ttraining loss: 0.0561642896489103\tvalidation accuracy: 0.7923076923076923\tvalidation loss:0.07813586195309957\n",
            "Correct number of outputs in validation: 1236\tTotal number of outputs in validation: 1560\tTotal validation loss 121.89194464683533\n",
            "Epoch 186:\n",
            "training accuracy: 0.7976489028213166\ttraining loss: 0.07117986683281238\tvalidation accuracy: 0.7717948717948718\tvalidation loss:0.06930647257428903\n",
            "Correct number of outputs in validation: 1204\tTotal number of outputs in validation: 1560\tTotal validation loss 108.11809721589088\n",
            "Epoch 187:\n",
            "training accuracy: 0.8394984326018808\ttraining loss: 0.05431410273227572\tvalidation accuracy: 0.7717948717948718\tvalidation loss:0.06902909328540166\n",
            "Correct number of outputs in validation: 1204\tTotal number of outputs in validation: 1560\tTotal validation loss 107.6853855252266\n",
            "Epoch 188:\n",
            "training accuracy: 0.8518808777429467\ttraining loss: 0.050487065046651985\tvalidation accuracy: 0.7974358974358975\tvalidation loss:0.06296615659808501\n",
            "Correct number of outputs in validation: 1244\tTotal number of outputs in validation: 1560\tTotal validation loss 98.22720429301262\n",
            "Epoch 189:\n",
            "training accuracy: 0.8528213166144201\ttraining loss: 0.0504433566967148\tvalidation accuracy: 0.7794871794871795\tvalidation loss:0.07134871650964786\n",
            "Correct number of outputs in validation: 1216\tTotal number of outputs in validation: 1560\tTotal validation loss 111.30399775505066\n",
            "Epoch 190:\n",
            "training accuracy: 0.8564263322884013\ttraining loss: 0.049625688597419795\tvalidation accuracy: 0.7878205128205128\tvalidation loss:0.06755654208171062\n",
            "Correct number of outputs in validation: 1229\tTotal number of outputs in validation: 1560\tTotal validation loss 105.38820564746857\n",
            "Epoch 191:\n",
            "training accuracy: 0.8557993730407524\ttraining loss: 0.049006836067266225\tvalidation accuracy: 0.7737179487179487\tvalidation loss:0.07101810274597926\n",
            "Correct number of outputs in validation: 1207\tTotal number of outputs in validation: 1560\tTotal validation loss 110.78824028372765\n",
            "Epoch 192:\n",
            "training accuracy: 0.856269592476489\ttraining loss: 0.04994215523841613\tvalidation accuracy: 0.7942307692307692\tvalidation loss:0.06395054155817399\n",
            "Correct number of outputs in validation: 1239\tTotal number of outputs in validation: 1560\tTotal validation loss 99.76284483075142\n",
            "Epoch 193:\n",
            "training accuracy: 0.8526645768025078\ttraining loss: 0.05157826614323828\tvalidation accuracy: 0.7993589743589744\tvalidation loss:0.06301323748551882\n",
            "Correct number of outputs in validation: 1247\tTotal number of outputs in validation: 1560\tTotal validation loss 98.30065047740936\n",
            "Epoch 194:\n",
            "training accuracy: 0.8478056426332289\ttraining loss: 0.05315941090120417\tvalidation accuracy: 0.791025641025641\tvalidation loss:0.07079847470307961\n",
            "Correct number of outputs in validation: 1234\tTotal number of outputs in validation: 1560\tTotal validation loss 110.4456205368042\n",
            "Epoch 195:\n",
            "training accuracy: 0.8529780564263323\ttraining loss: 0.05132252021362789\tvalidation accuracy: 0.7871794871794872\tvalidation loss:0.06948106955641355\n",
            "Correct number of outputs in validation: 1228\tTotal number of outputs in validation: 1560\tTotal validation loss 108.39046850800514\n",
            "Epoch 196:\n",
            "training accuracy: 0.8523510971786834\ttraining loss: 0.0515286247278082\tvalidation accuracy: 0.7948717948717948\tvalidation loss:0.06719198444714913\n",
            "Correct number of outputs in validation: 1240\tTotal number of outputs in validation: 1560\tTotal validation loss 104.81949573755264\n",
            "Epoch 197:\n",
            "training accuracy: 0.8545454545454545\ttraining loss: 0.05188727901320099\tvalidation accuracy: 0.7871794871794872\tvalidation loss:0.06534027422849949\n",
            "Correct number of outputs in validation: 1228\tTotal number of outputs in validation: 1560\tTotal validation loss 101.9308277964592\n",
            "Epoch 198:\n",
            "training accuracy: 0.856269592476489\ttraining loss: 0.04973112589746807\tvalidation accuracy: 0.8070512820512821\tvalidation loss:0.06268428266048431\n",
            "Correct number of outputs in validation: 1259\tTotal number of outputs in validation: 1560\tTotal validation loss 97.78748095035553\n",
            "Epoch 199:\n",
            "training accuracy: 0.8490595611285267\ttraining loss: 0.05377889457728048\tvalidation accuracy: 0.8173076923076923\tvalidation loss:0.05829162781055157\n",
            "Correct number of outputs in validation: 1275\tTotal number of outputs in validation: 1560\tTotal validation loss 90.93493938446045\n",
            "Epoch 200:\n",
            "training accuracy: 0.8518808777429467\ttraining loss: 0.05129178218239901\tvalidation accuracy: 0.8025641025641026\tvalidation loss:0.06314841707547506\n",
            "Correct number of outputs in validation: 1252\tTotal number of outputs in validation: 1560\tTotal validation loss 98.51153063774109\n",
            "Epoch 201:\n",
            "training accuracy: 0.8615987460815047\ttraining loss: 0.04991535645527152\tvalidation accuracy: 0.801923076923077\tvalidation loss:0.0612086744644703\n",
            "Correct number of outputs in validation: 1251\tTotal number of outputs in validation: 1560\tTotal validation loss 95.48553216457367\n",
            "Epoch 202:\n",
            "training accuracy: 0.8691222570532915\ttraining loss: 0.04719073437738194\tvalidation accuracy: 0.8051282051282052\tvalidation loss:0.060599359411459705\n",
            "Correct number of outputs in validation: 1256\tTotal number of outputs in validation: 1560\tTotal validation loss 94.53500068187714\n",
            "Epoch 203:\n",
            "training accuracy: 0.8689655172413793\ttraining loss: 0.04745225671643748\tvalidation accuracy: 0.7974358974358975\tvalidation loss:0.062466162787033964\n",
            "Correct number of outputs in validation: 1244\tTotal number of outputs in validation: 1560\tTotal validation loss 97.44721394777298\n",
            "Epoch 204:\n",
            "training accuracy: 0.8789968652037617\ttraining loss: 0.044985101194497557\tvalidation accuracy: 0.8224358974358974\tvalidation loss:0.06009156310405487\n",
            "Correct number of outputs in validation: 1283\tTotal number of outputs in validation: 1560\tTotal validation loss 93.74283844232559\n",
            "Epoch 205:\n",
            "training accuracy: 0.8753918495297806\ttraining loss: 0.04669529385981515\tvalidation accuracy: 0.8\tvalidation loss:0.06376242049229451\n",
            "Correct number of outputs in validation: 1248\tTotal number of outputs in validation: 1560\tTotal validation loss 99.46937596797943\n",
            "Epoch 206:\n",
            "training accuracy: 0.8736677115987461\ttraining loss: 0.0468477794205694\tvalidation accuracy: 0.8121794871794872\tvalidation loss:0.05813515377350342\n",
            "Correct number of outputs in validation: 1267\tTotal number of outputs in validation: 1560\tTotal validation loss 90.69083988666534\n",
            "Epoch 207:\n",
            "training accuracy: 0.8772727272727273\ttraining loss: 0.045281868579806206\tvalidation accuracy: 0.8012820512820513\tvalidation loss:0.060543169730748886\n",
            "Correct number of outputs in validation: 1250\tTotal number of outputs in validation: 1560\tTotal validation loss 94.44734477996826\n",
            "Epoch 208:\n",
            "training accuracy: 0.8636363636363636\ttraining loss: 0.05197401057496714\tvalidation accuracy: 0.7923076923076923\tvalidation loss:0.06690462097907678\n",
            "Correct number of outputs in validation: 1236\tTotal number of outputs in validation: 1560\tTotal validation loss 104.37120872735977\n",
            "Epoch 209:\n",
            "training accuracy: 0.8741379310344828\ttraining loss: 0.04760821042903538\tvalidation accuracy: 0.775\tvalidation loss:0.06450748160863534\n",
            "Correct number of outputs in validation: 1209\tTotal number of outputs in validation: 1560\tTotal validation loss 100.63167130947113\n",
            "Epoch 210:\n",
            "training accuracy: 0.8813479623824452\ttraining loss: 0.0444847364270575\tvalidation accuracy: 0.782051282051282\tvalidation loss:0.06374001224071552\n",
            "Correct number of outputs in validation: 1220\tTotal number of outputs in validation: 1560\tTotal validation loss 99.4344190955162\n",
            "Epoch 211:\n",
            "training accuracy: 0.8827586206896552\ttraining loss: 0.042760665880568725\tvalidation accuracy: 0.782051282051282\tvalidation loss:0.06200689589365935\n",
            "Correct number of outputs in validation: 1220\tTotal number of outputs in validation: 1560\tTotal validation loss 96.73075759410858\n",
            "Epoch 212:\n",
            "training accuracy: 0.8808777429467085\ttraining loss: 0.044103526851880515\tvalidation accuracy: 0.7980769230769231\tvalidation loss:0.05883945547617399\n",
            "Correct number of outputs in validation: 1245\tTotal number of outputs in validation: 1560\tTotal validation loss 91.78955054283142\n",
            "Epoch 213:\n",
            "training accuracy: 0.8830721003134796\ttraining loss: 0.04399755921763686\tvalidation accuracy: 0.8153846153846154\tvalidation loss:0.05973676485128892\n",
            "Correct number of outputs in validation: 1272\tTotal number of outputs in validation: 1560\tTotal validation loss 93.18935316801071\n",
            "Epoch 214:\n",
            "training accuracy: 0.879153605015674\ttraining loss: 0.0443596951173017\tvalidation accuracy: 0.801923076923077\tvalidation loss:0.05929261170900785\n",
            "Correct number of outputs in validation: 1251\tTotal number of outputs in validation: 1560\tTotal validation loss 92.49647426605225\n",
            "Epoch 215:\n",
            "training accuracy: 0.8727272727272727\ttraining loss: 0.046258012118944924\tvalidation accuracy: 0.8096153846153846\tvalidation loss:0.05903038413096697\n",
            "Correct number of outputs in validation: 1263\tTotal number of outputs in validation: 1560\tTotal validation loss 92.08739924430847\n",
            "Epoch 216:\n",
            "training accuracy: 0.893730407523511\ttraining loss: 0.040291030644249395\tvalidation accuracy: 0.8173076923076923\tvalidation loss:0.05357162203544225\n",
            "Correct number of outputs in validation: 1275\tTotal number of outputs in validation: 1560\tTotal validation loss 83.57173037528992\n",
            "Epoch 217:\n",
            "training accuracy: 0.8805642633228841\ttraining loss: 0.04108258969965026\tvalidation accuracy: 0.8044871794871795\tvalidation loss:0.055637867213823855\n",
            "Correct number of outputs in validation: 1255\tTotal number of outputs in validation: 1560\tTotal validation loss 86.79507285356522\n",
            "Epoch 218:\n",
            "training accuracy: 0.8907523510971787\ttraining loss: 0.04136070795941128\tvalidation accuracy: 0.8012820512820513\tvalidation loss:0.05895703404377668\n",
            "Correct number of outputs in validation: 1250\tTotal number of outputs in validation: 1560\tTotal validation loss 91.97297310829163\n",
            "Epoch 219:\n",
            "training accuracy: 0.888871473354232\ttraining loss: 0.04099199349136562\tvalidation accuracy: 0.7961538461538461\tvalidation loss:0.06142482933325645\n",
            "Correct number of outputs in validation: 1242\tTotal number of outputs in validation: 1560\tTotal validation loss 95.82273375988007\n",
            "Epoch 220:\n",
            "training accuracy: 0.8793103448275862\ttraining loss: 0.04448584731096011\tvalidation accuracy: 0.7801282051282051\tvalidation loss:0.061258276991355116\n",
            "Correct number of outputs in validation: 1217\tTotal number of outputs in validation: 1560\tTotal validation loss 95.56291210651398\n",
            "Epoch 221:\n",
            "training accuracy: 0.8927899686520376\ttraining loss: 0.03990283753010546\tvalidation accuracy: 0.8243589743589743\tvalidation loss:0.06050655922064414\n",
            "Correct number of outputs in validation: 1286\tTotal number of outputs in validation: 1560\tTotal validation loss 94.39023238420486\n",
            "Epoch 222:\n",
            "training accuracy: 0.8796238244514106\ttraining loss: 0.045155347362861364\tvalidation accuracy: 0.8179487179487179\tvalidation loss:0.06256221611148272\n",
            "Correct number of outputs in validation: 1276\tTotal number of outputs in validation: 1560\tTotal validation loss 97.59705713391304\n",
            "Epoch 223:\n",
            "training accuracy: 0.8545454545454545\ttraining loss: 0.05446306565151693\tvalidation accuracy: 0.8147435897435897\tvalidation loss:0.05760437683799328\n",
            "Correct number of outputs in validation: 1271\tTotal number of outputs in validation: 1560\tTotal validation loss 89.86282786726952\n",
            "Epoch 224:\n",
            "training accuracy: 0.8747648902821317\ttraining loss: 0.0436542896524679\tvalidation accuracy: 0.8237179487179487\tvalidation loss:0.05283491292443031\n",
            "Correct number of outputs in validation: 1285\tTotal number of outputs in validation: 1560\tTotal validation loss 82.42246416211128\n",
            "Epoch 225:\n",
            "training accuracy: 0.8847962382445141\ttraining loss: 0.040206353111794005\tvalidation accuracy: 0.8185897435897436\tvalidation loss:0.05620729873577754\n",
            "Correct number of outputs in validation: 1277\tTotal number of outputs in validation: 1560\tTotal validation loss 87.68338602781296\n",
            "Epoch 226:\n",
            "training accuracy: 0.8633228840125392\ttraining loss: 0.04819744693518246\tvalidation accuracy: 0.8064102564102564\tvalidation loss:0.057109937759546134\n",
            "Correct number of outputs in validation: 1258\tTotal number of outputs in validation: 1560\tTotal validation loss 89.09150290489197\n",
            "Epoch 227:\n",
            "training accuracy: 0.8799373040752351\ttraining loss: 0.043524383606395003\tvalidation accuracy: 0.8217948717948718\tvalidation loss:0.05275299002726873\n",
            "Correct number of outputs in validation: 1282\tTotal number of outputs in validation: 1560\tTotal validation loss 82.29466444253922\n",
            "Epoch 228:\n",
            "training accuracy: 0.8924764890282132\ttraining loss: 0.03879003018187505\tvalidation accuracy: 0.8224358974358974\tvalidation loss:0.05135637804483756\n",
            "Correct number of outputs in validation: 1283\tTotal number of outputs in validation: 1560\tTotal validation loss 80.1159497499466\n",
            "Epoch 229:\n",
            "training accuracy: 0.886833855799373\ttraining loss: 0.042973349600750076\tvalidation accuracy: 0.8423076923076923\tvalidation loss:0.055194185368525675\n",
            "Correct number of outputs in validation: 1314\tTotal number of outputs in validation: 1560\tTotal validation loss 86.10292917490005\n",
            "Epoch 230:\n",
            "training accuracy: 0.8869905956112852\ttraining loss: 0.039851992566804155\tvalidation accuracy: 0.8294871794871795\tvalidation loss:0.052568482206417966\n",
            "Correct number of outputs in validation: 1294\tTotal number of outputs in validation: 1560\tTotal validation loss 82.00683224201202\n",
            "Epoch 231:\n",
            "training accuracy: 0.8978056426332288\ttraining loss: 0.03838756205776829\tvalidation accuracy: 0.833974358974359\tvalidation loss:0.049172660842155796\n",
            "Correct number of outputs in validation: 1301\tTotal number of outputs in validation: 1560\tTotal validation loss 76.70935091376305\n",
            "Epoch 232:\n",
            "training accuracy: 0.8970219435736677\ttraining loss: 0.039877936402832076\tvalidation accuracy: 0.8262820512820512\tvalidation loss:0.0507154300235785\n",
            "Correct number of outputs in validation: 1289\tTotal number of outputs in validation: 1560\tTotal validation loss 79.11607083678246\n",
            "Epoch 233:\n",
            "training accuracy: 0.8916927899686521\ttraining loss: 0.039903119479694334\tvalidation accuracy: 0.7993589743589744\tvalidation loss:0.056835153832649574\n",
            "Correct number of outputs in validation: 1247\tTotal number of outputs in validation: 1560\tTotal validation loss 88.66283997893333\n",
            "Epoch 234:\n",
            "training accuracy: 0.8956112852664577\ttraining loss: 0.03738526697372755\tvalidation accuracy: 0.8012820512820513\tvalidation loss:0.05999374966590833\n",
            "Correct number of outputs in validation: 1250\tTotal number of outputs in validation: 1560\tTotal validation loss 93.59024947881699\n",
            "Epoch 235:\n",
            "training accuracy: 0.8869905956112852\ttraining loss: 0.04287782861941661\tvalidation accuracy: 0.8185897435897436\tvalidation loss:0.05589524499880962\n",
            "Correct number of outputs in validation: 1277\tTotal number of outputs in validation: 1560\tTotal validation loss 87.196582198143\n",
            "Epoch 236:\n",
            "training accuracy: 0.8989028213166145\ttraining loss: 0.037531003990096734\tvalidation accuracy: 0.8192307692307692\tvalidation loss:0.0514194647089029\n",
            "Correct number of outputs in validation: 1278\tTotal number of outputs in validation: 1560\tTotal validation loss 80.21436494588852\n",
            "Epoch 237:\n",
            "training accuracy: 0.9043887147335423\ttraining loss: 0.03475809602364664\tvalidation accuracy: 0.8166666666666667\tvalidation loss:0.05362063447634379\n",
            "Correct number of outputs in validation: 1274\tTotal number of outputs in validation: 1560\tTotal validation loss 83.64818978309631\n",
            "Epoch 238:\n",
            "training accuracy: 0.8904388714733542\ttraining loss: 0.04327648428259972\tvalidation accuracy: 0.7935897435897435\tvalidation loss:0.06477120037262256\n",
            "Correct number of outputs in validation: 1238\tTotal number of outputs in validation: 1560\tTotal validation loss 101.0430725812912\n",
            "Epoch 239:\n",
            "training accuracy: 0.8840125391849529\ttraining loss: 0.040306962745083164\tvalidation accuracy: 0.8\tvalidation loss:0.06223337871906085\n",
            "Correct number of outputs in validation: 1248\tTotal number of outputs in validation: 1560\tTotal validation loss 97.08407080173492\n",
            "Epoch 240:\n",
            "training accuracy: 0.8935736677115987\ttraining loss: 0.03917268720867118\tvalidation accuracy: 0.816025641025641\tvalidation loss:0.049398163763376385\n",
            "Correct number of outputs in validation: 1273\tTotal number of outputs in validation: 1560\tTotal validation loss 77.06113547086716\n",
            "Epoch 241:\n",
            "training accuracy: 0.9075235109717869\ttraining loss: 0.032767982747067104\tvalidation accuracy: 0.8307692307692308\tvalidation loss:0.05072327143488786\n",
            "Correct number of outputs in validation: 1296\tTotal number of outputs in validation: 1560\tTotal validation loss 79.12830343842506\n",
            "Epoch 242:\n",
            "training accuracy: 0.9152037617554859\ttraining loss: 0.031906818148904836\tvalidation accuracy: 0.8301282051282052\tvalidation loss:0.05220801868499854\n",
            "Correct number of outputs in validation: 1295\tTotal number of outputs in validation: 1560\tTotal validation loss 81.44450914859772\n",
            "Epoch 243:\n",
            "training accuracy: 0.9181818181818182\ttraining loss: 0.03121382868191852\tvalidation accuracy: 0.8256410256410256\tvalidation loss:0.049619877185577\n",
            "Correct number of outputs in validation: 1288\tTotal number of outputs in validation: 1560\tTotal validation loss 77.40700840950012\n",
            "Epoch 244:\n",
            "training accuracy: 0.9153605015673981\ttraining loss: 0.03190190152711816\tvalidation accuracy: 0.8262820512820512\tvalidation loss:0.05106451725348448\n",
            "Correct number of outputs in validation: 1289\tTotal number of outputs in validation: 1560\tTotal validation loss 79.66064691543579\n",
            "Epoch 245:\n",
            "training accuracy: 0.9108150470219436\ttraining loss: 0.03508089934139977\tvalidation accuracy: 0.8224358974358974\tvalidation loss:0.051993494824721265\n",
            "Correct number of outputs in validation: 1283\tTotal number of outputs in validation: 1560\tTotal validation loss 81.10985192656517\n",
            "Epoch 246:\n",
            "training accuracy: 0.912539184952978\ttraining loss: 0.03332881790623769\tvalidation accuracy: 0.8217948717948718\tvalidation loss:0.05085418835664407\n",
            "Correct number of outputs in validation: 1282\tTotal number of outputs in validation: 1560\tTotal validation loss 79.33253383636475\n",
            "Epoch 247:\n",
            "training accuracy: 0.9144200626959248\ttraining loss: 0.03322568605172223\tvalidation accuracy: 0.8198717948717948\tvalidation loss:0.05514771399589685\n",
            "Correct number of outputs in validation: 1279\tTotal number of outputs in validation: 1560\tTotal validation loss 86.03043383359909\n",
            "Epoch 248:\n",
            "training accuracy: 0.9219435736677116\ttraining loss: 0.03146011255634803\tvalidation accuracy: 0.8275641025641025\tvalidation loss:0.04806725249076501\n",
            "Correct number of outputs in validation: 1291\tTotal number of outputs in validation: 1560\tTotal validation loss 74.98491388559341\n",
            "Epoch 249:\n",
            "training accuracy: 0.9192789968652038\ttraining loss: 0.03181943533982976\tvalidation accuracy: 0.8217948717948718\tvalidation loss:0.057210289858854735\n",
            "Correct number of outputs in validation: 1282\tTotal number of outputs in validation: 1560\tTotal validation loss 89.24805217981339\n",
            "Epoch 250:\n",
            "training accuracy: 0.9133228840125391\ttraining loss: 0.03306781251952753\tvalidation accuracy: 0.8314102564102565\tvalidation loss:0.05192838502235902\n",
            "Correct number of outputs in validation: 1297\tTotal number of outputs in validation: 1560\tTotal validation loss 81.00828063488007\n",
            "Epoch 251:\n",
            "training accuracy: 0.9246081504702194\ttraining loss: 0.02951910332966374\tvalidation accuracy: 0.8352564102564103\tvalidation loss:0.04828687615883656\n",
            "Correct number of outputs in validation: 1303\tTotal number of outputs in validation: 1560\tTotal validation loss 75.32752680778503\n",
            "Epoch 252:\n",
            "training accuracy: 0.9244514106583072\ttraining loss: 0.02923673884154861\tvalidation accuracy: 0.8378205128205128\tvalidation loss:0.04787143293099526\n",
            "Correct number of outputs in validation: 1307\tTotal number of outputs in validation: 1560\tTotal validation loss 74.6794353723526\n",
            "Epoch 253:\n",
            "training accuracy: 0.9227272727272727\ttraining loss: 0.02890751897401197\tvalidation accuracy: 0.8352564102564103\tvalidation loss:0.0506712542512478\n",
            "Correct number of outputs in validation: 1303\tTotal number of outputs in validation: 1560\tTotal validation loss 79.04715663194656\n",
            "Epoch 254:\n",
            "training accuracy: 0.9112852664576803\ttraining loss: 0.03341551534247623\tvalidation accuracy: 0.8205128205128205\tvalidation loss:0.05010097439472492\n",
            "Correct number of outputs in validation: 1280\tTotal number of outputs in validation: 1560\tTotal validation loss 78.15752005577087\n",
            "Epoch 255:\n",
            "training accuracy: 0.9137931034482759\ttraining loss: 0.03278771741052967\tvalidation accuracy: 0.8371794871794872\tvalidation loss:0.049213139407145674\n",
            "Correct number of outputs in validation: 1306\tTotal number of outputs in validation: 1560\tTotal validation loss 76.77249747514725\n",
            "Epoch 256:\n",
            "training accuracy: 0.9186520376175549\ttraining loss: 0.03217520401302176\tvalidation accuracy: 0.8185897435897436\tvalidation loss:0.05251713582338431\n",
            "Correct number of outputs in validation: 1277\tTotal number of outputs in validation: 1560\tTotal validation loss 81.92673188447952\n",
            "Epoch 257:\n",
            "training accuracy: 0.921473354231975\ttraining loss: 0.03104292802092237\tvalidation accuracy: 0.8294871794871795\tvalidation loss:0.04921860553515263\n",
            "Correct number of outputs in validation: 1294\tTotal number of outputs in validation: 1560\tTotal validation loss 76.7810246348381\n",
            "Epoch 258:\n",
            "training accuracy: 0.9241379310344827\ttraining loss: 0.027725311159667178\tvalidation accuracy: 0.8307692307692308\tvalidation loss:0.050123630960782366\n",
            "Correct number of outputs in validation: 1296\tTotal number of outputs in validation: 1560\tTotal validation loss 78.1928642988205\n",
            "Epoch 259:\n",
            "training accuracy: 0.9258620689655173\ttraining loss: 0.030625980962826913\tvalidation accuracy: 0.808974358974359\tvalidation loss:0.054200671231135346\n",
            "Correct number of outputs in validation: 1262\tTotal number of outputs in validation: 1560\tTotal validation loss 84.55304712057114\n",
            "Epoch 260:\n",
            "training accuracy: 0.9268025078369906\ttraining loss: 0.029698330337958274\tvalidation accuracy: 0.8108974358974359\tvalidation loss:0.052785584750847936\n",
            "Correct number of outputs in validation: 1265\tTotal number of outputs in validation: 1560\tTotal validation loss 82.34551221132278\n",
            "Epoch 261:\n",
            "training accuracy: 0.925705329153605\ttraining loss: 0.030387357164606405\tvalidation accuracy: 0.8256410256410256\tvalidation loss:0.04921048302681018\n",
            "Correct number of outputs in validation: 1288\tTotal number of outputs in validation: 1560\tTotal validation loss 76.76835352182388\n",
            "Epoch 262:\n",
            "training accuracy: 0.927115987460815\ttraining loss: 0.028479627978792384\tvalidation accuracy: 0.8262820512820512\tvalidation loss:0.05138585059306561\n",
            "Correct number of outputs in validation: 1289\tTotal number of outputs in validation: 1560\tTotal validation loss 80.16192692518234\n",
            "Epoch 263:\n",
            "training accuracy: 0.9264890282131661\ttraining loss: 0.029486700582980734\tvalidation accuracy: 0.833974358974359\tvalidation loss:0.048279778850384245\n",
            "Correct number of outputs in validation: 1301\tTotal number of outputs in validation: 1560\tTotal validation loss 75.31645500659943\n",
            "Epoch 264:\n",
            "training accuracy: 0.9175548589341693\ttraining loss: 0.033123288748546455\tvalidation accuracy: 0.8006410256410257\tvalidation loss:0.06264253445924857\n",
            "Correct number of outputs in validation: 1249\tTotal number of outputs in validation: 1560\tTotal validation loss 97.72235375642776\n",
            "Epoch 265:\n",
            "training accuracy: 0.9126959247648903\ttraining loss: 0.03471842612428912\tvalidation accuracy: 0.8352564102564103\tvalidation loss:0.054240080217520394\n",
            "Correct number of outputs in validation: 1303\tTotal number of outputs in validation: 1560\tTotal validation loss 84.61452513933182\n",
            "Epoch 266:\n",
            "training accuracy: 0.9189655172413793\ttraining loss: 0.03268009375161886\tvalidation accuracy: 0.8314102564102565\tvalidation loss:0.05071281190866079\n",
            "Correct number of outputs in validation: 1297\tTotal number of outputs in validation: 1560\tTotal validation loss 79.11198657751083\n",
            "Epoch 267:\n",
            "training accuracy: 0.9095611285266457\ttraining loss: 0.03468976072313083\tvalidation accuracy: 0.8307692307692308\tvalidation loss:0.051445640891026226\n",
            "Correct number of outputs in validation: 1296\tTotal number of outputs in validation: 1560\tTotal validation loss 80.25519979000092\n",
            "Epoch 268:\n",
            "training accuracy: 0.9137931034482759\ttraining loss: 0.03218100001235554\tvalidation accuracy: 0.8358974358974359\tvalidation loss:0.050081372452087894\n",
            "Correct number of outputs in validation: 1304\tTotal number of outputs in validation: 1560\tTotal validation loss 78.12694102525711\n",
            "Epoch 269:\n",
            "training accuracy: 0.9224137931034483\ttraining loss: 0.029511025997585264\tvalidation accuracy: 0.8217948717948718\tvalidation loss:0.048815937072802816\n",
            "Correct number of outputs in validation: 1282\tTotal number of outputs in validation: 1560\tTotal validation loss 76.15286183357239\n",
            "Epoch 270:\n",
            "training accuracy: 0.9241379310344827\ttraining loss: 0.028844038051404175\tvalidation accuracy: 0.8346153846153846\tvalidation loss:0.04820529146072192\n",
            "Correct number of outputs in validation: 1302\tTotal number of outputs in validation: 1560\tTotal validation loss 75.2002546787262\n",
            "Epoch 271:\n",
            "training accuracy: 0.9231974921630094\ttraining loss: 0.030244524667162133\tvalidation accuracy: 0.8314102564102565\tvalidation loss:0.05278845318616965\n",
            "Correct number of outputs in validation: 1297\tTotal number of outputs in validation: 1560\tTotal validation loss 82.34998697042465\n",
            "Epoch 272:\n",
            "training accuracy: 0.9147335423197492\ttraining loss: 0.03439347374028173\tvalidation accuracy: 0.8301282051282052\tvalidation loss:0.05358807245890299\n",
            "Correct number of outputs in validation: 1295\tTotal number of outputs in validation: 1560\tTotal validation loss 83.59739303588867\n",
            "Epoch 273:\n",
            "training accuracy: 0.9051724137931034\ttraining loss: 0.038074556077161925\tvalidation accuracy: 0.8102564102564103\tvalidation loss:0.051720933386912714\n",
            "Correct number of outputs in validation: 1264\tTotal number of outputs in validation: 1560\tTotal validation loss 80.68465608358383\n",
            "Epoch 274:\n",
            "training accuracy: 0.9120689655172414\ttraining loss: 0.03435228182744457\tvalidation accuracy: 0.7826923076923077\tvalidation loss:0.07019219188353955\n",
            "Correct number of outputs in validation: 1221\tTotal number of outputs in validation: 1560\tTotal validation loss 109.49981933832169\n",
            "Epoch 275:\n",
            "training accuracy: 0.28949843260188085\ttraining loss: 1576.921385329719\tvalidation accuracy: 0.12115384615384615\tvalidation loss:124.63952178955078\n",
            "Correct number of outputs in validation: 189\tTotal number of outputs in validation: 1560\tTotal validation loss 194437.65399169922\n",
            "Epoch 276:\n",
            "training accuracy: 0.16191222570532915\ttraining loss: 12.99691233612527\tvalidation accuracy: 0.1685897435897436\tvalidation loss:1.0774697695022974\n",
            "Correct number of outputs in validation: 263\tTotal number of outputs in validation: 1560\tTotal validation loss 1680.852840423584\n",
            "Epoch 277:\n",
            "training accuracy: 0.15752351097178682\ttraining loss: 0.5099669908281405\tvalidation accuracy: 0.175\tvalidation loss:0.6348561607874357\n",
            "Correct number of outputs in validation: 273\tTotal number of outputs in validation: 1560\tTotal validation loss 990.3756108283997\n",
            "Epoch 278:\n",
            "training accuracy: 0.15438871473354232\ttraining loss: 0.4475781799483822\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.6248740431589958\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 974.8035073280334\n",
            "Epoch 279:\n",
            "training accuracy: 0.15532915360501567\ttraining loss: 0.4246833527349753\tvalidation accuracy: 0.15512820512820513\tvalidation loss:0.5580936872042143\n",
            "Correct number of outputs in validation: 242\tTotal number of outputs in validation: 1560\tTotal validation loss 870.6261520385742\n",
            "Epoch 280:\n",
            "training accuracy: 0.16222570532915362\ttraining loss: 0.43717251104247234\tvalidation accuracy: 0.1814102564102564\tvalidation loss:0.7809061071811578\n",
            "Correct number of outputs in validation: 283\tTotal number of outputs in validation: 1560\tTotal validation loss 1218.2135272026062\n",
            "Epoch 281:\n",
            "training accuracy: 0.15031347962382446\ttraining loss: 0.5753853066961594\tvalidation accuracy: 0.18269230769230768\tvalidation loss:0.5457927772632012\n",
            "Correct number of outputs in validation: 285\tTotal number of outputs in validation: 1560\tTotal validation loss 851.4367325305939\n",
            "Epoch 282:\n",
            "training accuracy: 0.15987460815047022\ttraining loss: 0.4091107596798003\tvalidation accuracy: 0.17756410256410257\tvalidation loss:0.41270295091164416\n",
            "Correct number of outputs in validation: 277\tTotal number of outputs in validation: 1560\tTotal validation loss 643.8166034221649\n",
            "Epoch 283:\n",
            "training accuracy: 0.16410658307210033\ttraining loss: 0.3355198730028535\tvalidation accuracy: 0.18012820512820513\tvalidation loss:0.34623771554384475\n",
            "Correct number of outputs in validation: 281\tTotal number of outputs in validation: 1560\tTotal validation loss 540.1308362483978\n",
            "Epoch 284:\n",
            "training accuracy: 0.1633228840125392\ttraining loss: 0.29393424195555684\tvalidation accuracy: 0.18269230769230768\tvalidation loss:0.31430049599745336\n",
            "Correct number of outputs in validation: 285\tTotal number of outputs in validation: 1560\tTotal validation loss 490.3087737560272\n",
            "Epoch 285:\n",
            "training accuracy: 0.1664576802507837\ttraining loss: 0.2603433003246224\tvalidation accuracy: 0.17756410256410257\tvalidation loss:0.27778068276552054\n",
            "Correct number of outputs in validation: 277\tTotal number of outputs in validation: 1560\tTotal validation loss 433.33786511421204\n",
            "Epoch 286:\n",
            "training accuracy: 0.1702194357366771\ttraining loss: 0.23915027744344036\tvalidation accuracy: 0.1814102564102564\tvalidation loss:0.25736722365403786\n",
            "Correct number of outputs in validation: 283\tTotal number of outputs in validation: 1560\tTotal validation loss 401.4928689002991\n",
            "Epoch 287:\n",
            "training accuracy: 0.16786833855799374\ttraining loss: 0.22376418920893654\tvalidation accuracy: 0.20064102564102565\tvalidation loss:0.23742161079859123\n",
            "Correct number of outputs in validation: 313\tTotal number of outputs in validation: 1560\tTotal validation loss 370.3777128458023\n",
            "Epoch 288:\n",
            "training accuracy: 0.16630094043887148\ttraining loss: 0.21378794325556502\tvalidation accuracy: 0.19423076923076923\tvalidation loss:0.2269376556078593\n",
            "Correct number of outputs in validation: 303\tTotal number of outputs in validation: 1560\tTotal validation loss 354.0227427482605\n",
            "Epoch 289:\n",
            "training accuracy: 0.16551724137931034\ttraining loss: 0.2041423641869267\tvalidation accuracy: 0.1955128205128205\tvalidation loss:0.21645669906567305\n",
            "Correct number of outputs in validation: 305\tTotal number of outputs in validation: 1560\tTotal validation loss 337.67245054244995\n",
            "Epoch 290:\n",
            "training accuracy: 0.17053291536050158\ttraining loss: 0.19683065136024572\tvalidation accuracy: 0.1891025641025641\tvalidation loss:0.20867580588047321\n",
            "Correct number of outputs in validation: 295\tTotal number of outputs in validation: 1560\tTotal validation loss 325.5342571735382\n",
            "Epoch 291:\n",
            "training accuracy: 0.16536050156739812\ttraining loss: 0.19239524640259698\tvalidation accuracy: 0.1935897435897436\tvalidation loss:0.20050785617950634\n",
            "Correct number of outputs in validation: 302\tTotal number of outputs in validation: 1560\tTotal validation loss 312.7922556400299\n",
            "Epoch 292:\n",
            "training accuracy: 0.16050156739811913\ttraining loss: 0.18507334569404865\tvalidation accuracy: 0.19807692307692307\tvalidation loss:0.19373314350079268\n",
            "Correct number of outputs in validation: 309\tTotal number of outputs in validation: 1560\tTotal validation loss 302.2237038612366\n",
            "Epoch 293:\n",
            "training accuracy: 0.16206896551724137\ttraining loss: 0.17980955730785023\tvalidation accuracy: 0.19807692307692307\tvalidation loss:0.18860990855938348\n",
            "Correct number of outputs in validation: 309\tTotal number of outputs in validation: 1560\tTotal validation loss 294.23145735263824\n",
            "Epoch 294:\n",
            "training accuracy: 0.164576802507837\ttraining loss: 0.17658473683935721\tvalidation accuracy: 0.19294871794871796\tvalidation loss:0.1837897363381508\n",
            "Correct number of outputs in validation: 301\tTotal number of outputs in validation: 1560\tTotal validation loss 286.71198868751526\n",
            "Epoch 295:\n",
            "training accuracy: 0.16755485893416927\ttraining loss: 0.17490288904841791\tvalidation accuracy: 0.19230769230769232\tvalidation loss:0.18016107892378783\n",
            "Correct number of outputs in validation: 300\tTotal number of outputs in validation: 1560\tTotal validation loss 281.051283121109\n",
            "Epoch 296:\n",
            "training accuracy: 0.16912225705329154\ttraining loss: 0.17266651517171472\tvalidation accuracy: 0.19487179487179487\tvalidation loss:0.17676646136320553\n",
            "Correct number of outputs in validation: 304\tTotal number of outputs in validation: 1560\tTotal validation loss 275.75567972660065\n",
            "Epoch 297:\n",
            "training accuracy: 0.17037617554858933\ttraining loss: 0.17066299294042736\tvalidation accuracy: 0.1858974358974359\tvalidation loss:0.17439679098434938\n",
            "Correct number of outputs in validation: 290\tTotal number of outputs in validation: 1560\tTotal validation loss 272.058993935585\n",
            "Epoch 298:\n",
            "training accuracy: 0.16990595611285267\ttraining loss: 0.16879390277272108\tvalidation accuracy: 0.18076923076923077\tvalidation loss:0.17274694977662503\n",
            "Correct number of outputs in validation: 282\tTotal number of outputs in validation: 1560\tTotal validation loss 269.48524165153503\n",
            "Epoch 299:\n",
            "training accuracy: 0.16739811912225705\ttraining loss: 0.16660931315915337\tvalidation accuracy: 0.18653846153846154\tvalidation loss:0.1707384494634775\n",
            "Correct number of outputs in validation: 291\tTotal number of outputs in validation: 1560\tTotal validation loss 266.3519811630249\n",
            "Epoch 300:\n",
            "training accuracy: 0.17633228840125392\ttraining loss: 0.16407687655623804\tvalidation accuracy: 0.18846153846153846\tvalidation loss:0.16628858554057585\n",
            "Correct number of outputs in validation: 294\tTotal number of outputs in validation: 1560\tTotal validation loss 259.41019344329834\n",
            "Epoch 301:\n",
            "training accuracy: 0.17680250783699059\ttraining loss: 0.1621349800716747\tvalidation accuracy: 0.18653846153846154\tvalidation loss:0.1606892173106854\n",
            "Correct number of outputs in validation: 291\tTotal number of outputs in validation: 1560\tTotal validation loss 250.6751790046692\n",
            "Epoch 302:\n",
            "training accuracy: 0.17398119122257052\ttraining loss: 0.15998282546533688\tvalidation accuracy: 0.191025641025641\tvalidation loss:0.15784980272635435\n",
            "Correct number of outputs in validation: 298\tTotal number of outputs in validation: 1560\tTotal validation loss 246.2456922531128\n",
            "Epoch 303:\n",
            "training accuracy: 0.17288401253918495\ttraining loss: 0.16023286664186973\tvalidation accuracy: 0.18461538461538463\tvalidation loss:0.15789605547220278\n",
            "Correct number of outputs in validation: 288\tTotal number of outputs in validation: 1560\tTotal validation loss 246.31784653663635\n",
            "Epoch 304:\n",
            "training accuracy: 0.17351097178683386\ttraining loss: 0.15985252140644576\tvalidation accuracy: 0.18525641025641026\tvalidation loss:0.1564839956852106\n",
            "Correct number of outputs in validation: 289\tTotal number of outputs in validation: 1560\tTotal validation loss 244.11503326892853\n",
            "Epoch 305:\n",
            "training accuracy: 0.17821316614420063\ttraining loss: 0.15933054237156452\tvalidation accuracy: 0.183974358974359\tvalidation loss:0.1533901088512861\n",
            "Correct number of outputs in validation: 287\tTotal number of outputs in validation: 1560\tTotal validation loss 239.2885698080063\n",
            "Epoch 306:\n",
            "training accuracy: 0.17836990595611285\ttraining loss: 0.15861444491017201\tvalidation accuracy: 0.18076923076923077\tvalidation loss:0.15136531239900833\n",
            "Correct number of outputs in validation: 282\tTotal number of outputs in validation: 1560\tTotal validation loss 236.129887342453\n",
            "Epoch 307:\n",
            "training accuracy: 0.17586206896551723\ttraining loss: 0.15960009656729743\tvalidation accuracy: 0.1685897435897436\tvalidation loss:0.1557129367803916\n",
            "Correct number of outputs in validation: 263\tTotal number of outputs in validation: 1560\tTotal validation loss 242.9121813774109\n",
            "Epoch 308:\n",
            "training accuracy: 0.17445141065830722\ttraining loss: 0.16007001736321047\tvalidation accuracy: 0.1685897435897436\tvalidation loss:0.15885369922870246\n",
            "Correct number of outputs in validation: 263\tTotal number of outputs in validation: 1560\tTotal validation loss 247.81177079677582\n",
            "Epoch 309:\n",
            "training accuracy: 0.1724137931034483\ttraining loss: 0.1556646534921981\tvalidation accuracy: 0.16346153846153846\tvalidation loss:0.15980074122930185\n",
            "Correct number of outputs in validation: 255\tTotal number of outputs in validation: 1560\tTotal validation loss 249.28915631771088\n",
            "Epoch 310:\n",
            "training accuracy: 0.17351097178683386\ttraining loss: 0.15201634469450828\tvalidation accuracy: 0.16474358974358974\tvalidation loss:0.15793705945595718\n",
            "Correct number of outputs in validation: 257\tTotal number of outputs in validation: 1560\tTotal validation loss 246.38181275129318\n",
            "Epoch 311:\n",
            "training accuracy: 0.17351097178683386\ttraining loss: 0.15004914509465328\tvalidation accuracy: 0.16666666666666666\tvalidation loss:0.15459747089025302\n",
            "Correct number of outputs in validation: 260\tTotal number of outputs in validation: 1560\tTotal validation loss 241.1720545887947\n",
            "Epoch 312:\n",
            "training accuracy: 0.1702194357366771\ttraining loss: 0.14913303603572906\tvalidation accuracy: 0.16538461538461538\tvalidation loss:0.15172828409152153\n",
            "Correct number of outputs in validation: 258\tTotal number of outputs in validation: 1560\tTotal validation loss 236.6961231827736\n",
            "Epoch 313:\n",
            "training accuracy: 0.1683385579937304\ttraining loss: 0.14860033126647196\tvalidation accuracy: 0.17115384615384616\tvalidation loss:0.148854571275222\n",
            "Correct number of outputs in validation: 267\tTotal number of outputs in validation: 1560\tTotal validation loss 232.2131311893463\n",
            "Epoch 314:\n",
            "training accuracy: 0.1719435736677116\ttraining loss: 0.1486390441749537\tvalidation accuracy: 0.16923076923076924\tvalidation loss:0.14846549171667833\n",
            "Correct number of outputs in validation: 264\tTotal number of outputs in validation: 1560\tTotal validation loss 231.6061670780182\n",
            "Epoch 315:\n",
            "training accuracy: 0.1778996865203762\ttraining loss: 0.14809649776328693\tvalidation accuracy: 0.1685897435897436\tvalidation loss:0.14848492458844798\n",
            "Correct number of outputs in validation: 263\tTotal number of outputs in validation: 1560\tTotal validation loss 231.63648235797882\n",
            "Epoch 316:\n",
            "training accuracy: 0.17821316614420063\ttraining loss: 0.14705279471358534\tvalidation accuracy: 0.16474358974358974\tvalidation loss:0.14853783123768294\n",
            "Correct number of outputs in validation: 257\tTotal number of outputs in validation: 1560\tTotal validation loss 231.71901673078537\n",
            "Epoch 317:\n",
            "training accuracy: 0.17758620689655172\ttraining loss: 0.1461310742697372\tvalidation accuracy: 0.1685897435897436\tvalidation loss:0.14790552793404996\n",
            "Correct number of outputs in validation: 263\tTotal number of outputs in validation: 1560\tTotal validation loss 230.73262357711792\n",
            "Epoch 318:\n",
            "training accuracy: 0.1786833855799373\ttraining loss: 0.14512888804124816\tvalidation accuracy: 0.16474358974358974\tvalidation loss:0.14755255912358944\n",
            "Correct number of outputs in validation: 257\tTotal number of outputs in validation: 1560\tTotal validation loss 230.18199223279953\n",
            "Epoch 319:\n",
            "training accuracy: 0.17774294670846394\ttraining loss: 0.1444413292837741\tvalidation accuracy: 0.1576923076923077\tvalidation loss:0.14732405631205975\n",
            "Correct number of outputs in validation: 246\tTotal number of outputs in validation: 1560\tTotal validation loss 229.8255278468132\n",
            "Epoch 320:\n",
            "training accuracy: 0.17993730407523512\ttraining loss: 0.1441968172414923\tvalidation accuracy: 0.16538461538461538\tvalidation loss:0.1472596248755088\n",
            "Correct number of outputs in validation: 258\tTotal number of outputs in validation: 1560\tTotal validation loss 229.72501480579376\n",
            "Epoch 321:\n",
            "training accuracy: 0.17915360501567398\ttraining loss: 0.14408552881131725\tvalidation accuracy: 0.1621794871794872\tvalidation loss:0.14722077472087663\n",
            "Correct number of outputs in validation: 253\tTotal number of outputs in validation: 1560\tTotal validation loss 229.66440856456757\n",
            "Epoch 322:\n",
            "training accuracy: 0.174294670846395\ttraining loss: 0.14469110257573262\tvalidation accuracy: 0.1608974358974359\tvalidation loss:0.14674024574267558\n",
            "Correct number of outputs in validation: 251\tTotal number of outputs in validation: 1560\tTotal validation loss 228.9147833585739\n",
            "Epoch 323:\n",
            "training accuracy: 0.17053291536050158\ttraining loss: 0.14587630172695112\tvalidation accuracy: 0.1608974358974359\tvalidation loss:0.14621224380456485\n",
            "Correct number of outputs in validation: 251\tTotal number of outputs in validation: 1560\tTotal validation loss 228.09110033512115\n",
            "Epoch 324:\n",
            "training accuracy: 0.1683385579937304\ttraining loss: 0.14813648635130316\tvalidation accuracy: 0.1544871794871795\tvalidation loss:0.1472783360725794\n",
            "Correct number of outputs in validation: 241\tTotal number of outputs in validation: 1560\tTotal validation loss 229.75420427322388\n",
            "Epoch 325:\n",
            "training accuracy: 0.16614420062695925\ttraining loss: 0.1515462235223537\tvalidation accuracy: 0.1608974358974359\tvalidation loss:0.15216746972157405\n",
            "Correct number of outputs in validation: 251\tTotal number of outputs in validation: 1560\tTotal validation loss 237.38125276565552\n",
            "Epoch 326:\n",
            "training accuracy: 0.1664576802507837\ttraining loss: 0.15506416998313138\tvalidation accuracy: 0.17692307692307693\tvalidation loss:0.16721579333146414\n",
            "Correct number of outputs in validation: 276\tTotal number of outputs in validation: 1560\tTotal validation loss 260.85663759708405\n",
            "Epoch 327:\n",
            "training accuracy: 0.1688087774294671\ttraining loss: 0.15794700473827256\tvalidation accuracy: 0.18653846153846154\tvalidation loss:0.20111052088248424\n",
            "Correct number of outputs in validation: 291\tTotal number of outputs in validation: 1560\tTotal validation loss 313.7324125766754\n",
            "Epoch 328:\n",
            "training accuracy: 0.1731974921630094\ttraining loss: 0.1613775139505213\tvalidation accuracy: 0.19423076923076923\tvalidation loss:0.2377853084069032\n",
            "Correct number of outputs in validation: 303\tTotal number of outputs in validation: 1560\tTotal validation loss 370.945081114769\n",
            "Epoch 329:\n",
            "training accuracy: 0.16849529780564262\ttraining loss: 0.16768041036345743\tvalidation accuracy: 0.2012820512820513\tvalidation loss:0.2732780769849435\n",
            "Correct number of outputs in validation: 314\tTotal number of outputs in validation: 1560\tTotal validation loss 426.31380009651184\n",
            "Epoch 330:\n",
            "training accuracy: 0.1628526645768025\ttraining loss: 0.17800731197419958\tvalidation accuracy: 0.18653846153846154\tvalidation loss:0.3419180289292947\n",
            "Correct number of outputs in validation: 291\tTotal number of outputs in validation: 1560\tTotal validation loss 533.3921251296997\n",
            "Epoch 331:\n",
            "training accuracy: 0.15956112852664578\ttraining loss: 0.19176779913491215\tvalidation accuracy: 0.1782051282051282\tvalidation loss:0.43674504909759915\n",
            "Correct number of outputs in validation: 278\tTotal number of outputs in validation: 1560\tTotal validation loss 681.3222765922546\n",
            "Epoch 332:\n",
            "training accuracy: 0.15987460815047022\ttraining loss: 0.20678428281624114\tvalidation accuracy: 0.1782051282051282\tvalidation loss:0.4759293441589062\n",
            "Correct number of outputs in validation: 278\tTotal number of outputs in validation: 1560\tTotal validation loss 742.4497768878937\n",
            "Epoch 333:\n",
            "training accuracy: 0.16927899686520376\ttraining loss: 0.20881755433299326\tvalidation accuracy: 0.19294871794871796\tvalidation loss:0.40659117499987285\n",
            "Correct number of outputs in validation: 301\tTotal number of outputs in validation: 1560\tTotal validation loss 634.2822329998016\n",
            "Epoch 334:\n",
            "training accuracy: 0.17445141065830722\ttraining loss: 0.1987599279719834\tvalidation accuracy: 0.19230769230769232\tvalidation loss:0.3403054358103336\n",
            "Correct number of outputs in validation: 300\tTotal number of outputs in validation: 1560\tTotal validation loss 530.8764798641205\n",
            "Epoch 335:\n",
            "training accuracy: 0.16865203761755485\ttraining loss: 0.18963171212837615\tvalidation accuracy: 0.20384615384615384\tvalidation loss:0.342175639516268\n",
            "Correct number of outputs in validation: 318\tTotal number of outputs in validation: 1560\tTotal validation loss 533.7939976453781\n",
            "Epoch 336:\n",
            "training accuracy: 0.15658307210031347\ttraining loss: 0.1906574430136845\tvalidation accuracy: 0.2141025641025641\tvalidation loss:0.37405850291252135\n",
            "Correct number of outputs in validation: 334\tTotal number of outputs in validation: 1560\tTotal validation loss 583.5312645435333\n",
            "Epoch 337:\n",
            "training accuracy: 0.1493730407523511\ttraining loss: 0.19671857177650667\tvalidation accuracy: 0.21474358974358973\tvalidation loss:0.40795713189320687\n",
            "Correct number of outputs in validation: 335\tTotal number of outputs in validation: 1560\tTotal validation loss 636.4131257534027\n",
            "Epoch 338:\n",
            "training accuracy: 0.14733542319749215\ttraining loss: 0.2112232819199562\tvalidation accuracy: 0.21474358974358973\tvalidation loss:0.43367210534902717\n",
            "Correct number of outputs in validation: 335\tTotal number of outputs in validation: 1560\tTotal validation loss 676.5284843444824\n",
            "Epoch 339:\n",
            "training accuracy: 0.14482758620689656\ttraining loss: 0.23677479334666063\tvalidation accuracy: 0.2141025641025641\tvalidation loss:0.46708266735076903\n",
            "Correct number of outputs in validation: 334\tTotal number of outputs in validation: 1560\tTotal validation loss 728.6489610671997\n",
            "Epoch 340:\n",
            "training accuracy: 0.1481191222570533\ttraining loss: 0.27597493498956893\tvalidation accuracy: 0.21217948717948718\tvalidation loss:0.511458543019417\n",
            "Correct number of outputs in validation: 331\tTotal number of outputs in validation: 1560\tTotal validation loss 797.8753271102905\n",
            "Epoch 341:\n",
            "training accuracy: 0.1561128526645768\ttraining loss: 0.3295706586310856\tvalidation accuracy: 0.2064102564102564\tvalidation loss:0.48335175391955254\n",
            "Correct number of outputs in validation: 322\tTotal number of outputs in validation: 1560\tTotal validation loss 754.028736114502\n",
            "Epoch 342:\n",
            "training accuracy: 0.16426332288401255\ttraining loss: 0.3684524382917111\tvalidation accuracy: 0.18782051282051282\tvalidation loss:0.3673331644290533\n",
            "Correct number of outputs in validation: 293\tTotal number of outputs in validation: 1560\tTotal validation loss 573.0397365093231\n",
            "Epoch 343:\n",
            "training accuracy: 0.1669278996865204\ttraining loss: 0.3883390263143378\tvalidation accuracy: 0.18717948717948718\tvalidation loss:0.24271419911812514\n",
            "Correct number of outputs in validation: 292\tTotal number of outputs in validation: 1560\tTotal validation loss 378.6341506242752\n",
            "Epoch 344:\n",
            "training accuracy: 0.1738244514106583\ttraining loss: 0.38597661211946543\tvalidation accuracy: 0.2\tvalidation loss:0.1891267309586207\n",
            "Correct number of outputs in validation: 312\tTotal number of outputs in validation: 1560\tTotal validation loss 295.0377002954483\n",
            "Epoch 345:\n",
            "training accuracy: 0.1755485893416928\ttraining loss: 0.3728717402978377\tvalidation accuracy: 0.1762820512820513\tvalidation loss:0.14711443991997303\n",
            "Correct number of outputs in validation: 275\tTotal number of outputs in validation: 1560\tTotal validation loss 229.49852627515793\n",
            "Epoch 346:\n",
            "training accuracy: 0.17915360501567398\ttraining loss: 0.3198305869924611\tvalidation accuracy: 0.19743589743589743\tvalidation loss:0.13459611145349648\n",
            "Correct number of outputs in validation: 308\tTotal number of outputs in validation: 1560\tTotal validation loss 209.96993386745453\n",
            "Epoch 347:\n",
            "training accuracy: 0.1841692789968652\ttraining loss: 0.2632214457637464\tvalidation accuracy: 0.19423076923076923\tvalidation loss:0.13513211951805995\n",
            "Correct number of outputs in validation: 303\tTotal number of outputs in validation: 1560\tTotal validation loss 210.80610644817352\n",
            "Epoch 348:\n",
            "training accuracy: 0.17915360501567398\ttraining loss: 0.22085372063807185\tvalidation accuracy: 0.18782051282051282\tvalidation loss:0.1338429121634899\n",
            "Correct number of outputs in validation: 293\tTotal number of outputs in validation: 1560\tTotal validation loss 208.79494297504425\n",
            "Epoch 349:\n",
            "training accuracy: 0.18134796238244513\ttraining loss: 0.1970519168063017\tvalidation accuracy: 0.19423076923076923\tvalidation loss:0.13395160673520504\n",
            "Correct number of outputs in validation: 303\tTotal number of outputs in validation: 1560\tTotal validation loss 208.96450650691986\n",
            "Epoch 350:\n",
            "training accuracy: 0.17962382445141065\ttraining loss: 0.1862631688110507\tvalidation accuracy: 0.19743589743589743\tvalidation loss:0.1364351225969119\n",
            "Correct number of outputs in validation: 308\tTotal number of outputs in validation: 1560\tTotal validation loss 212.83879125118256\n",
            "Epoch 351:\n",
            "training accuracy: 0.1797805642633229\ttraining loss: 0.17773647195306316\tvalidation accuracy: 0.20064102564102565\tvalidation loss:0.1346709742377966\n",
            "Correct number of outputs in validation: 313\tTotal number of outputs in validation: 1560\tTotal validation loss 210.08671981096268\n",
            "Epoch 352:\n",
            "training accuracy: 0.17445141065830722\ttraining loss: 0.17619184602203788\tvalidation accuracy: 0.19487179487179487\tvalidation loss:0.13301327175054795\n",
            "Correct number of outputs in validation: 304\tTotal number of outputs in validation: 1560\tTotal validation loss 207.5007039308548\n",
            "Epoch 353:\n",
            "training accuracy: 0.17084639498432602\ttraining loss: 0.18242877203282143\tvalidation accuracy: 0.19807692307692307\tvalidation loss:0.14346188207467397\n",
            "Correct number of outputs in validation: 309\tTotal number of outputs in validation: 1560\tTotal validation loss 223.8005360364914\n",
            "Epoch 354:\n",
            "training accuracy: 0.16912225705329154\ttraining loss: 0.20301216082139448\tvalidation accuracy: 0.2108974358974359\tvalidation loss:0.18264465194482069\n",
            "Correct number of outputs in validation: 329\tTotal number of outputs in validation: 1560\tTotal validation loss 284.9256570339203\n",
            "Epoch 355:\n",
            "training accuracy: 0.16300940438871472\ttraining loss: 0.2380010843463826\tvalidation accuracy: 0.20448717948717948\tvalidation loss:0.29144797172301856\n",
            "Correct number of outputs in validation: 319\tTotal number of outputs in validation: 1560\tTotal validation loss 454.65883588790894\n",
            "Epoch 356:\n",
            "training accuracy: 0.16175548589341693\ttraining loss: 0.2815861667398375\tvalidation accuracy: 0.20705128205128207\tvalidation loss:0.4322437482002454\n",
            "Correct number of outputs in validation: 323\tTotal number of outputs in validation: 1560\tTotal validation loss 674.3002471923828\n",
            "Epoch 357:\n",
            "training accuracy: 0.16426332288401255\ttraining loss: 0.3126679271272731\tvalidation accuracy: 0.2076923076923077\tvalidation loss:0.4889796744554471\n",
            "Correct number of outputs in validation: 324\tTotal number of outputs in validation: 1560\tTotal validation loss 762.8082921504974\n",
            "Epoch 358:\n",
            "training accuracy: 0.15705329153605016\ttraining loss: 0.3163731276335014\tvalidation accuracy: 0.2108974358974359\tvalidation loss:0.45690314876727567\n",
            "Correct number of outputs in validation: 329\tTotal number of outputs in validation: 1560\tTotal validation loss 712.7689120769501\n",
            "Epoch 359:\n",
            "training accuracy: 0.16253918495297806\ttraining loss: 0.30243150938454094\tvalidation accuracy: 0.1967948717948718\tvalidation loss:0.3900304117263892\n",
            "Correct number of outputs in validation: 307\tTotal number of outputs in validation: 1560\tTotal validation loss 608.4474422931671\n",
            "Epoch 360:\n",
            "training accuracy: 0.16316614420062697\ttraining loss: 0.2808163672872472\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.31827122416251746\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 496.5031096935272\n",
            "Epoch 361:\n",
            "training accuracy: 0.15956112852664578\ttraining loss: 0.2723552093049949\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2734032056652583\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 426.5090008378029\n",
            "Epoch 362:\n",
            "training accuracy: 0.15501567398119123\ttraining loss: 0.2817990760631322\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.21422963035412323\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 334.19822335243225\n",
            "Epoch 363:\n",
            "training accuracy: 0.16269592476489028\ttraining loss: 0.29165124784816393\tvalidation accuracy: 0.1358974358974359\tvalidation loss:0.21359670089605526\n",
            "Correct number of outputs in validation: 212\tTotal number of outputs in validation: 1560\tTotal validation loss 333.2108533978462\n",
            "Epoch 364:\n",
            "training accuracy: 0.16269592476489028\ttraining loss: 0.2798612519491429\tvalidation accuracy: 0.17435897435897435\tvalidation loss:0.27335492968559266\n",
            "Correct number of outputs in validation: 272\tTotal number of outputs in validation: 1560\tTotal validation loss 426.43369030952454\n",
            "Epoch 365:\n",
            "training accuracy: 0.17084639498432602\ttraining loss: 0.27441826380532364\tvalidation accuracy: 0.1467948717948718\tvalidation loss:0.32919619587751536\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 513.546065568924\n",
            "Epoch 366:\n",
            "training accuracy: 0.16927899686520376\ttraining loss: 0.2835142261275677\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.32902164657910665\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 513.2737686634064\n",
            "Epoch 367:\n",
            "training accuracy: 0.16865203761755485\ttraining loss: 0.2981544155779303\tvalidation accuracy: 0.13846153846153847\tvalidation loss:0.2871476467603292\n",
            "Correct number of outputs in validation: 216\tTotal number of outputs in validation: 1560\tTotal validation loss 447.9503289461136\n",
            "Epoch 368:\n",
            "training accuracy: 0.1647335423197492\ttraining loss: 0.3056710034702265\tvalidation accuracy: 0.13782051282051283\tvalidation loss:0.2516051687491246\n",
            "Correct number of outputs in validation: 215\tTotal number of outputs in validation: 1560\tTotal validation loss 392.50406324863434\n",
            "Epoch 369:\n",
            "training accuracy: 0.16426332288401255\ttraining loss: 0.31328674013898666\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.2402906073973729\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 374.85334753990173\n",
            "Epoch 370:\n",
            "training accuracy: 0.1670846394984326\ttraining loss: 0.3216890274170424\tvalidation accuracy: 0.13782051282051283\tvalidation loss:0.23900503115012095\n",
            "Correct number of outputs in validation: 215\tTotal number of outputs in validation: 1560\tTotal validation loss 372.8478485941887\n",
            "Epoch 371:\n",
            "training accuracy: 0.1670846394984326\ttraining loss: 0.3296154951320547\tvalidation accuracy: 0.13846153846153847\tvalidation loss:0.23801931605125085\n",
            "Correct number of outputs in validation: 216\tTotal number of outputs in validation: 1560\tTotal validation loss 371.3101330399513\n",
            "Epoch 372:\n",
            "training accuracy: 0.16630094043887148\ttraining loss: 0.3343665628130533\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.23722166086618718\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 370.065790951252\n",
            "Epoch 373:\n",
            "training accuracy: 0.16551724137931034\ttraining loss: 0.33209322589131357\tvalidation accuracy: 0.1891025641025641\tvalidation loss:0.23484439849853517\n",
            "Correct number of outputs in validation: 295\tTotal number of outputs in validation: 1560\tTotal validation loss 366.35726165771484\n",
            "Epoch 374:\n",
            "training accuracy: 0.16363636363636364\ttraining loss: 0.33169077529242047\tvalidation accuracy: 0.2064102564102564\tvalidation loss:0.23369803829835012\n",
            "Correct number of outputs in validation: 322\tTotal number of outputs in validation: 1560\tTotal validation loss 364.5689397454262\n",
            "Epoch 375:\n",
            "training accuracy: 0.16489028213166143\ttraining loss: 0.3359530712369841\tvalidation accuracy: 0.2\tvalidation loss:0.2253528425708795\n",
            "Correct number of outputs in validation: 312\tTotal number of outputs in validation: 1560\tTotal validation loss 351.55043441057205\n",
            "Epoch 376:\n",
            "training accuracy: 0.16050156739811913\ttraining loss: 0.3340536316080153\tvalidation accuracy: 0.20192307692307693\tvalidation loss:0.20650128022982525\n",
            "Correct number of outputs in validation: 315\tTotal number of outputs in validation: 1560\tTotal validation loss 322.1419971585274\n",
            "Epoch 377:\n",
            "training accuracy: 0.16065830721003135\ttraining loss: 0.33171809960308496\tvalidation accuracy: 0.19935897435897437\tvalidation loss:0.19364316001152382\n",
            "Correct number of outputs in validation: 311\tTotal number of outputs in validation: 1560\tTotal validation loss 302.08332961797714\n",
            "Epoch 378:\n",
            "training accuracy: 0.15846394984326018\ttraining loss: 0.33100861537045445\tvalidation accuracy: 0.20705128205128207\tvalidation loss:0.18222677463140244\n",
            "Correct number of outputs in validation: 323\tTotal number of outputs in validation: 1560\tTotal validation loss 284.2737684249878\n",
            "Epoch 379:\n",
            "training accuracy: 0.16003134796238244\ttraining loss: 0.3303786573645463\tvalidation accuracy: 0.2153846153846154\tvalidation loss:0.1678198795670118\n",
            "Correct number of outputs in validation: 336\tTotal number of outputs in validation: 1560\tTotal validation loss 261.7990121245384\n",
            "Epoch 380:\n",
            "training accuracy: 0.15877742946708465\ttraining loss: 0.3268115671450815\tvalidation accuracy: 0.20448717948717948\tvalidation loss:0.1588815057124847\n",
            "Correct number of outputs in validation: 319\tTotal number of outputs in validation: 1560\tTotal validation loss 247.85514891147614\n",
            "Epoch 381:\n",
            "training accuracy: 0.16128526645768024\ttraining loss: 0.32463939361811434\tvalidation accuracy: 0.1987179487179487\tvalidation loss:0.15106342232380157\n",
            "Correct number of outputs in validation: 310\tTotal number of outputs in validation: 1560\tTotal validation loss 235.65893882513046\n",
            "Epoch 382:\n",
            "training accuracy: 0.16222570532915362\ttraining loss: 0.32293550190880754\tvalidation accuracy: 0.19935897435897437\tvalidation loss:0.1452772115667661\n",
            "Correct number of outputs in validation: 311\tTotal number of outputs in validation: 1560\tTotal validation loss 226.63245004415512\n",
            "Epoch 383:\n",
            "training accuracy: 0.15705329153605016\ttraining loss: 0.3239755948602593\tvalidation accuracy: 0.17884615384615385\tvalidation loss:0.1428134730993173\n",
            "Correct number of outputs in validation: 279\tTotal number of outputs in validation: 1560\tTotal validation loss 222.789018034935\n",
            "Epoch 384:\n",
            "training accuracy: 0.15877742946708465\ttraining loss: 0.324583172826184\tvalidation accuracy: 0.1794871794871795\tvalidation loss:0.13609043994011022\n",
            "Correct number of outputs in validation: 280\tTotal number of outputs in validation: 1560\tTotal validation loss 212.30108630657196\n",
            "Epoch 385:\n",
            "training accuracy: 0.15893416927899687\ttraining loss: 0.3230365348740431\tvalidation accuracy: 0.16025641025641027\tvalidation loss:0.13713877751277043\n",
            "Correct number of outputs in validation: 250\tTotal number of outputs in validation: 1560\tTotal validation loss 213.93649291992188\n",
            "Epoch 386:\n",
            "training accuracy: 0.16081504702194357\ttraining loss: 0.31611392067330757\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.14222140327478067\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 221.86538910865784\n",
            "Epoch 387:\n",
            "training accuracy: 0.1677115987460815\ttraining loss: 0.31752048408536704\tvalidation accuracy: 0.1544871794871795\tvalidation loss:0.1517216288890594\n",
            "Correct number of outputs in validation: 241\tTotal number of outputs in validation: 1560\tTotal validation loss 236.68574106693268\n",
            "Epoch 388:\n",
            "training accuracy: 0.17084639498432602\ttraining loss: 0.3214823732742322\tvalidation accuracy: 0.14807692307692308\tvalidation loss:0.1719027864627349\n",
            "Correct number of outputs in validation: 231\tTotal number of outputs in validation: 1560\tTotal validation loss 268.16834688186646\n",
            "Epoch 389:\n",
            "training accuracy: 0.1647335423197492\ttraining loss: 0.3053310982299075\tvalidation accuracy: 0.14871794871794872\tvalidation loss:0.19035329895141798\n",
            "Correct number of outputs in validation: 232\tTotal number of outputs in validation: 1560\tTotal validation loss 296.95114636421204\n",
            "Epoch 390:\n",
            "training accuracy: 0.16551724137931034\ttraining loss: 0.3066057667836874\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.21252962671793424\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 331.5462176799774\n",
            "Epoch 391:\n",
            "training accuracy: 0.16755485893416927\ttraining loss: 0.3032983161158696\tvalidation accuracy: 0.1467948717948718\tvalidation loss:0.2314838183231843\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 361.1147565841675\n",
            "Epoch 392:\n",
            "training accuracy: 0.16849529780564262\ttraining loss: 0.30377614688723814\tvalidation accuracy: 0.1467948717948718\tvalidation loss:0.2547596032802875\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 397.42498111724854\n",
            "Epoch 393:\n",
            "training accuracy: 0.1702194357366771\ttraining loss: 0.3023428987373005\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2590758426067157\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 404.15831446647644\n",
            "Epoch 394:\n",
            "training accuracy: 0.16927899686520376\ttraining loss: 0.2953874474408858\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.2493343724654271\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 388.9616210460663\n",
            "Epoch 395:\n",
            "training accuracy: 0.16363636363636364\ttraining loss: 0.2913381853634287\tvalidation accuracy: 0.13653846153846153\tvalidation loss:0.24253564140735528\n",
            "Correct number of outputs in validation: 213\tTotal number of outputs in validation: 1560\tTotal validation loss 378.35560059547424\n",
            "Epoch 396:\n",
            "training accuracy: 0.15956112852664578\ttraining loss: 0.28780364005543224\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.22622925379337408\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 352.9176359176636\n",
            "Epoch 397:\n",
            "training accuracy: 0.15595611285266459\ttraining loss: 0.2845752819204779\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.2019340292765544\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 315.01708567142487\n",
            "Epoch 398:\n",
            "training accuracy: 0.15721003134796238\ttraining loss: 0.2889177915631417\tvalidation accuracy: 0.14743589743589744\tvalidation loss:0.18092659902878297\n",
            "Correct number of outputs in validation: 230\tTotal number of outputs in validation: 1560\tTotal validation loss 282.2454944849014\n",
            "Epoch 399:\n",
            "training accuracy: 0.1614420062695925\ttraining loss: 0.2915973973872146\tvalidation accuracy: 0.18012820512820513\tvalidation loss:0.15817258327435224\n",
            "Correct number of outputs in validation: 281\tTotal number of outputs in validation: 1560\tTotal validation loss 246.7492299079895\n",
            "Total time:   240.12 s  Time per Epoch:   0.60 s \n",
            "The best epoch: 229\tAccuracy:0.8423076923076923\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hcVZnv8e+vExKuEiBtDOlggkTnRMYLpwU8Oh6EGQRUgsogjEpU5uTooOLBG+jzCMPIM+p4RFBkJki4CHIRUCKDAnIR9MglXOUi0gZikgmkIQRBNJDkPX/sVd2VSl+rald1r/w+z1NP71p7V+23d/bO22uvtddSRGBmZjaUjnYHYGZmY5+ThZmZDcvJwszMhuVkYWZmw3KyMDOzYTlZmJnZsJwsLDuSfippfrO3NduSyc9Z2Fgg6fmqt9sC64AN6f3/joiLWh9V/STtB1wYEV1t2LeATwILgNnAM8CvgVMi4jetjsfyMLHdAZgBRMT2lWVJjwP/GBE/r91O0sSIWN/K2Mah04F3Av8L+BUwAXhPKhtVsvDxtgrfhrIxTdJ+klZI+oKkJ4BzJe0k6WpJvZKeSctdVZ+5WdI/puUPS/qlpG+kbR+TdHCd286WdIuk5yT9XNKZki6s43f6b2m/ayU9KOnQqnWHSHoo7WOlpM+m8qnp91wraY2kWyVtdv1KmgMcCxwVETdGxLqIeCEiLoqIr9b+ztW/d9X7kHSspEeBRyWdJekbNfu5StLxaXlXSVekf4/HJH1qtMfExj4nCxsPXgHsDLyS4tZKB3Buer8b8GfgO0N8fh/gEWAq8HXgnHSrZrTb/gC4A9gFOBn40Gh/EUlbAT8BrgNeTnG76CJJr0mbnENx220HYE/gxlT+GWAF0AlMA74IDHQP+QBgRUTcMdrYahxGcSzmAhcD768cB0k7AQcCl6SE9RPgPmBG2v+nJb2jwf3bGONkYePBRuCk9FfynyPi6Yi4Iv3F/BxwKvA/h/j8sog4OyI2AOcD0yn+wx3xtpJ2A94EfDkiXoyIXwKL6/hd9gW2B76avudG4GrgqLT+JWCupJdFxDMRcXdV+XTglRHxUkTcGgM3OO4CrKojrlr/GhFrIuLPwK0Uielv0rrDgV9HxH9RHJPOiDgl/T5LgbOBI5sQg40hThY2HvRGxF8qbyRtK+k/JC2T9EfgFmCKpAmDfP6JykJEvJAWtx/ltrsCa6rKAJaP8vcgfc/yiNhYVbaM4q9ygPcBhwDLJP1C0ptT+b8BPcB1kpZKOmGQ73+aIqk0qu93S0npEvoT2j8AlQ4HrwR2TbfH1kpaS1HrGSwZ2zjlZGHjQe1f0J8BXgPsExEvA96Wyge7tdQMq4CdJW1bVTazju/5L2BmTXvDbsBKgIi4MyLmUdyi+jFwWSp/LiI+ExG7A4cCx0s6YIDvvwHoktQ9RAx/ouhxVvGKAbapPeYXA4dLeiXF7akrUvly4LGImFL12iEiDhli/zYOOVnYeLQDRTvFWkk7AyeVvcOIWAYsAU6WNCn9xf/u4T4naevqF0WbxwvA5yVtlbrYvpvi/v8kSR+QtGNEvAT8keIWHJLeJWmP1G7wLEW34o21+4uIR4HvAhenzgGT0r6PrKqN3Au8N9XQ9gCOGcHvfw/wFPA94NqIWJtW3QE8lzogbCNpgqQ9Jb1puO+08cXJwsajbwHbUPzndRvwsxbt9wPAmylu9XwFuJTieZDBzKBIatWvmRTJ4WCK+L8LHB0Rv02f+RDweLq99rG0T4A5wM+B5ymemfhuRNw0yH4/RdHgfyawFvg9RdfZn6T1pwEvAk9StMuM9BmWHwB/m34CkNp23gW8AXiM/oSy4wi/08YJP5RnVidJlwK/jYjSazZm7eaahdkISXqTpFdJ6pB0EDCPol3BLHt+gtts5F4BXEnRPXUF8PF0L98se74NZWZmw/JtKDMzG1aWt6GmTp0as2bNancYZmbjyl133fVURHQOtC7LZDFr1iyWLFnS7jDMzMYVScsGW+fbUGZmNiwnCzMzG1ZpyULSIkmrJT1QU/5JSb9N4/h/var8REk9kh6pHt5Y0kGprGeIwdPMzKxEZbZZnEcx5MAFlQJJb6d4kOn1EbFO0stT+VyKIY1fSzEq588lvTp97Ezg7yj6td8paXFEPFRi3GZmVqO0ZBERt0iaVVP8cYpx/NelbVan8nnAJan8MUk9wN5pXU8aIx9Jl6RtnSzMzFqo1W0Wrwb+RtLtaaz+ysiUM9h0boAVqWyw8s1IWiBpiaQlvb29JYRuZrblanWymEgxPea+wOeAy4aY3nJUImJhRHRHRHdn54DdhM3MrE6tThYrgCujcAfFePxTKSZ+qZ5IpiuVDVZuZmPUuvUb+OGS5Xgooby0Oln8GHg7QGrAnkQx/v1i4EhJkyXNphi7/w7gTmCOpNmSJlE0gtcz77GZtcgvH32Kz11+P488+Vy7Q7EmKq2BW9LFwH7AVEkrKGYzWwQsSt1pXwTmp/l9H5R0GUXD9Xrg2DSpCpI+AVwLTAAWRcSDZcVsZo17aUNRo1i/wTWLnJTZG+qoQVZ9cJDtTwVOHaD8GuCaJoZmZqUqkoTvQuXFT3CbWVNVkkTgbJETJwsza6pKinDNIi9OFmbWVP01C8uJk4WZNVX0tVk4XeTEycLMmso1izw5WZhZU7nNIk9OFmbWVP23n5wtcuJkYWalcM0iL04WZtZUbrPIk5OFmTVV+AnuLDlZmFlT9dUsnC2y4mRhZk3l21B5crIws6Zy19k8OVmYWVNVbj95IMG8OFmYWVPFZguWAycLM2sut1lkqbRkIWmRpNVpVrzadZ+RFJKmpveSdIakHkn3S9qratv5kh5Nr/llxWtmzeGus3kqs2ZxHnBQbaGkmcCBwB+qig+mmHd7DrAAOCttuzPFdKz7AHsDJ0naqcSYzaxBnvwoT6Uli4i4BVgzwKrTgM+zaS11HnBBFG4DpkiaDrwDuD4i1kTEM8D1DJCAzGzscG+oPLW0zULSPGBlRNxXs2oGsLzq/YpUNlj5QN+9QNISSUt6e3ubGLWZjYafs8hTy5KFpG2BLwJfLuP7I2JhRHRHRHdnZ2cZuzCzEfDkR3lqZc3iVcBs4D5JjwNdwN2SXgGsBGZWbduVygYrN7MxyjWLPLUsWUTEbyLi5RExKyJmUdxS2isingAWA0enXlH7As9GxCrgWuBASTulhu0DU5mZjVF+ziJPZXadvRj4NfAaSSskHTPE5tcAS4Ee4GzgnwAiYg3wL8Cd6XVKKjOzscpPcGdpYllfHBFHDbN+VtVyAMcOst0iYFFTgzOz0rg3VJ78BLeZNVX/EOXtjcOay8nCzJqqfyBBy4mThZk1Vf9tKKeLnDhZmFlTuetsnpwszKyp3MCdJycLM2uq/ttPzhY5cbIws1K4ZpEXJwszayq3WeTJycLMmsqTH+XJycLMmsqTH+XJycLMmsq9ofLkZGFmTeU2izw5WZhZU3nyozw5WZhZUzlH5MnJwsxK4aSRFycLM2uq8ORHWSpzprxFklZLeqCq7N8k/VbS/ZJ+JGlK1boTJfVIekTSO6rKD0plPZJOKCteM2sOz2eRpzJrFucBB9WUXQ/sGRGvA34HnAggaS5wJPDa9JnvSpogaQJwJnAwMBc4Km1rZmOUu87mqbRkERG3AGtqyq6LiPXp7W1AV1qeB1wSEesi4jGKubj3Tq+eiFgaES8Cl6RtzWyMctfZPLWzzeKjwE/T8gxgedW6FalssPLNSFogaYmkJb29vSWEa2Yj4a6zeWpLspD0JWA9cFGzvjMiFkZEd0R0d3Z2NutrzWyUXLPI08RW71DSh4F3AQdE/58eK4GZVZt1pTKGKDezMSg2W7ActLRmIekg4PPAoRHxQtWqxcCRkiZLmg3MAe4A7gTmSJotaRJFI/jiVsZsZqPkrrNZKq1mIeliYD9gqqQVwEkUvZ8mA9dLArgtIj4WEQ9Kugx4iOL21LERsSF9zyeAa4EJwKKIeLCsmM2sedxkkZfSkkVEHDVA8TlDbH8qcOoA5dcA1zQxNDMrkSdVzZOf4DazpvJDeXlysjCzpurrOuu6RVacLMysqVyzyJOThZk1ldss8uRkYWZNFR4cKktOFmbWVP1tFpYTJwszay63WWTJycLMmqr/LpSzRU6cLMysqfpnyrOcOFlUefr5dbz6Sz/lwtuWtTsUs3HLXWfz5GRR48UNG9mw0We5Wb3cdTZPThZVOorBDX2v1awB/TULX0c5cbKoknIFrliY1c/DfOTJyaKKKjWLNsdhNp65zSJPThZVKjULV5/NGucaRl6cLKr0t1m0ORCzcayv66yvo6yUliwkLZK0WtIDVWU7S7pe0qPp506pXJLOkNQj6X5Je1V9Zn7a/lFJ88uKFyBVLNjos9ysbu4NlacyaxbnAQfVlJ0A3BARc4Ab0nuAgynm3Z4DLADOgiK5UEzHug+wN3BSJcGUoe82VFk7MNsCuM0iT6Uli4i4BVhTUzwPOD8tnw8cVlV+QRRuA6ZImg68A7g+ItZExDPA9WyegJrGt6HMGufJj/LU6jaLaRGxKi0/AUxLyzOA5VXbrUhlg5WXyrehzOrnmkWe2tbAHUUrWNNOJ0kLJC2RtKS3t7eu76jULMysfs4ReWp1sngy3V4i/VydylcCM6u260plg5VvJiIWRkR3RHR3dnbWFVzfQ3l+Ks+sbn6CO0+tThaLgUqPpvnAVVXlR6deUfsCz6bbVdcCB0raKTVsH5jKStHhh/LMmsBdZ3M0cbgNJL0KWBER6yTtB7yOojF67TCfuxjYD5gqaQVFr6avApdJOgZYBhyRNr8GOAToAV4APgIQEWsk/QtwZ9rulIiobTRvGnedNWtcX82ivWFYkw2bLIArgG5JewALKWoDP6D4z31QEXHUIKsOGGDbAI4d5HsWAYtGEGfD+p/gbsXezPLkBu48jeQ21MaIWA+8B/h2RHwOmF5uWO0hjzpr1jB3nc3TSJLFS5KOomhjuDqVbVVeSO0lufps1gjXLPI0kmTxEeDNwKkR8Zik2cD3yw2rfTokt1mYNcDDfeRp2DaLiHgI+BRA6pG0Q0R8rezA2kX4LyKzRvRdP76QsjJszULSzZJelsZpuhs4W9I3yw+tPTok/0Vk1oD+NgvLyUhuQ+0YEX8E3kvRZXYf4G/LDauN5K6zZg1xm0WWRpIsJqanrY+gv4E7Wx3CfxKZNaC/zcIXUk5GkixOoXhq+vcRcaek3YFHyw2rfYQbuM0a4cmP8jSSBu4fAj+ser8UeF+ZQbVTh3ySmzXCvaHyNJIG7i5JP0qz3q2WdIWkrlYE1w6S8DiCZvXzcxZ5GsltqHMpBvrbNb1+ksqyVDyU57PcrF5us8jTSJJFZ0ScGxHr0+s8oL4xwMcBP2dh1pjwSIJZGkmyeFrSByVNSK8PAk+XHVi7SPLYUGYNcJtFnkaSLD5K0W32CWAVcDjw4RJjaqsOjw1l1hhPfpSlkfSGWgYcWl0m6RvAZ8sKqp3ksaHMGhKe/ChL9c6Ud8Twm4xP7jpr1hg3WeSp3mSh4TcZ4sPS/5H0oKQHJF0saWtJsyXdLqlH0qWSJqVtJ6f3PWn9rEb2PYLo3HXWrAHuOpunQZOFpJ0Hee1CA8lC0gyKUWy7I2JPYAJwJPA14LSI2AN4BjgmfeQY4JlUflrarjQdAv9NZFY/T36Up6HaLO6i+F9zoMTwYhP2u42kl4BtKRrO9wf+Ia0/HzgZOAuYl5YBLge+I0lRUuuZBBs3lvHNZlsG1yzyNGiyiIjZZewwIlamBvI/AH8GrqNITGvT9K0AK4AZaXkGsDx9dr2kZ4FdgKfKiK8YotxnuVm9fPXkqd42i7qlCZTmAbMpngjfDjioCd+7QNISSUt6e3vr/x5wm4VZA8JdZ7PU8mRBMRfGYxHRGxEvAVcCbwGmSKrUdLqAlWl5JTATIK3fkQEeCoyIhRHRHRHdnZ31P2BePJRX98fNzJMfZakdyeIPwL6StpUk4ADgIeAmigf+AOYDV6Xlxek9af2NZbVXgMeGMmuU2yzyNOxDeQCSJgDTqrePiD/Us8OIuF3S5RRTtK4H7gEWAv8JXCLpK6nsnPSRc4DvS+oB1lD0nCqN/JyFWUM8kGCehk0Wkj4JnAQ8CVT6CQXwunp3GhEnpe+sthTYe4Bt/wL8fb37Gq0Ojw1l1hBPfpSnkdQsjgNeExHZDh5YzQ3cZo3xQIJ5GkmbxXLg2bIDGSuKrrNmVi+3WeRpJDWLpcDNkv4TWFcpjIhvlhZVOwkPJGjWgBhgyca/kSSLP6TXpPTKWoc8RrlZI9xmkaeRDFH+z60IZKwo2ix8lps1ypdRXgZNFpK+FRGflvQTBvhbOyIOHeBj4567zpo1pn+Icl9IORmqZvH99PMbrQhkrPDYUGaN8eRHeRpqIMG70s9ftC6cscFdZ83q58mP8jSSh/LmAP8KzAW2rpRHxO4lxtU2HR4byqwh7jqbp5E8Z3EuxbwS64G3AxcAF5YZVDsVbRY+y83q5cmP8jSSZLFNRNwAKCKWRcTJwDvLDat9/FCeWWPCj3BnaSTPWayT1AE8KukTFEOGb19uWO0jP5Rn1hDnijyNpGZxHMXUp58C/jvwQfqHDM+O57Mwa5AnP8rSkDWLNDT5+yPis8DzwEdaElUb+aE8s8aEJz/K0qA1C0kTI2ID8NYWxtN2UrsjMBvf3BsqT0PVLO4A9gLukbQY+CHwp8rKiLiy5Njawl1nzZrDl1FeRtLAvTXFnNf7U/z7K/3MMln4NpRZY/oauH0dZWWoZPFySccDD9CfJCoaOgskTQG+B+yZvuujwCPApcAs4HHgiIh4Js3TfTpwCPAC8OGIuLuR/Q/FNQuzxvSNOtvmOKy5huoNNYGii+z2wA5Vy5VXI04HfhYRfwW8HngYOAG4ISLmADek9wAHA3PSawHFA4LlcddZs4bEZguWg6FqFqsi4pRm71DSjsDbgA8DRMSLwIuS5gH7pc3OB24GvgDMAy6I4s+V2yRNkTQ9IlY1OzaADnlsKLNGeNTZPA1VsyirX9BsoBc4V9I9kr4naTtgWlUCeAKYlpZnUEztWrEilW0arLRA0hJJS3p7e+sOTsj3Ws0a0N9m0dYwrMmGShYHlLTPiRS9rM6KiDdS9LA6oXqDVIsY1akWEQsjojsiujs7O+sOrqPDJ7lZQzxTXpYGTRYRsaakfa4AVkTE7en95RTJ40lJ0wHSz9Vp/UpgZtXnu1JZKYTcZmHWgP7hPnwd5WQkw300VUQ8ASyX9JpUdADwELCY/mFE5gNXpeXFwNEq7As8W1Z7BaRRZ8v6crMtgB/Ky9NInrMowyeBiyRNApZSDCPSAVwm6RhgGXBE2vYaim6zPRRdZ0sdckSSG7jNGuDhPvLUlmQREfcC3QOs2qydJLVfHFt6UImKnbZqd2bZcc0iTy2/DTXWdfg2lFlDwg9aZMnJokZxG8onuVm93HU2T04WNTrkk9ysER7uI09OFptxA7dZM/jh1rw4WdQoahY+yc3q1T/ch+XEyaKGfBvKrCF9XWd9HWXFyaJGh+QnT80a4JpFnpwsasijzpo1xJMf5cnJooZHnTVrjK+fPDlZ1PDYUGaN8XMWeXKyqCFPq2rWGE9+lCUnixruOmvWGNcs8uRkUUO4gdusEeHJj7LkZFHDXWfNGuPJj/LkZFFLsHFju4MwG788RHmenCxqdEjtDsFsXPPkR3lqW7KQNEHSPZKuTu9nS7pdUo+kS9MsekianN73pPWzSo0LPES5WQOi/z6UZaSdNYvjgIer3n8NOC0i9gCeAY5J5ccAz6Ty09J2pfHYUGaNCXedzVJbkoWkLuCdwPfSewH7A5enTc4HDkvL89J70voD0valcAO3WXP4j668tKtm8S3g80ClKXkXYG1ErE/vVwAz0vIMYDlAWv9s2n4TkhZIWiJpSW9vb92BeWwos8Z48qM8tTxZSHoXsDoi7mrm90bEwojojojuzs7Our/HT3CbNcYDCeZpYhv2+RbgUEmHAFsDLwNOB6ZImphqD13AyrT9SmAmsELSRGBH4OmyghM+yc0a4SHK89TymkVEnBgRXRExCzgSuDEiPgDcBByeNpsPXJWWF6f3pPU3Ron/mxdtFmZWL09+lKex9JzFF4DjJfVQtEmck8rPAXZJ5ccDJ5QZRNFm4bPcrF6uWeSpHbeh+kTEzcDNaXkpsPcA2/wF+PtWxdThNguzhvRdPr6QsjKWahZjhmsWZvVzzSJPThY1JHyWmzXEbRY5crKo4QZus8b4Ce48OVnU8NhQZo3x5Ed5crKo0dHhBm6zRnjyozw5WdRwzcKsMR50Nk9OFjXkNguzhvRPfuQrKSdOFjWKIcp9kpvVy9dPnpwsanR4PguzhriBO09OFjWE3GZh1gh3nc2Sk0UNyQ1zZo1wzSJPThY1PJ+FWWM8+VGenCxqVOZrdSOdWX08+VGenCxqdKTpvX2em9XHAwnmycmiRsoVbuQ2q1PgbJEjJ4saHSlZ+Dw3q4//zspTy5OFpJmSbpL0kKQHJR2XyneWdL2kR9PPnVK5JJ0hqUfS/ZL2Kjk+wDULs3p5uI88taNmsR74TETMBfYFjpU0l2K61BsiYg5wA/3Tpx4MzEmvBcBZZQZXuQ3lXGFWJw/3kaWWJ4uIWBURd6fl54CHgRnAPOD8tNn5wGFpeR5wQRRuA6ZIml5WfMIN3GaNqLRZ+BLKS1vbLCTNAt4I3A5Mi4hVadUTwLS0PANYXvWxFams9rsWSFoiaUlvb2/dMfW3WfhUN6tH/0CC7Y3DmqttyULS9sAVwKcj4o/V66Kov47qVIuIhRHRHRHdnZ2dDcRV/NzoE92sLv1tFr6IctKWZCFpK4pEcVFEXJmKn6zcXko/V6fylcDMqo93pbJyYuu7DeUT3awenvwoT+3oDSXgHODhiPhm1arFwPy0PB+4qqr86NQral/g2arbVSXEV/z0eW5WH48NlaeJbdjnW4APAb+RdG8q+yLwVeAySccAy4Aj0rprgEOAHuAF4CNlBlfpOhsby9yLWb6cJPLU8mQREb+kfwimWgcMsH0Ax5YaVBU3cJs1h2/l5sVPcNeoZDE3cJuNXnWC8CWUFyeLGh0dbuA2q1f1ZeNLKC9OFjVcszCrX2yy7IsoJ04WNfoauH2im43aJrehfAllxcmihseGMqtfDLJs45+TRQ2PDWVWP7dZ5MvJooa7zprVL1y3yJaTRQ2PDWXWHK5Z5MXJokZfA7fPdLNR2+Q2VPvCsBI4WdSodJ11rjBrjP/gyouTRY0OuYHbrF6uWeTLyaJGf5uFT3Wz0apu4PYllBcnixp9NYs2x2E2Hm3addZXUU6cLGq4ZmFWP3eczZeTxSCcK8xGL9xokS0nixqV21A+081Gr3LVSL6CcjNukoWkgyQ9IqlH0gnl7af46YfyzEavUrHokNxmkZlxkSwkTQDOBA4G5gJHSZpbxr4qNYsNI8gW6zds5E/r1o9oW7MtQroUdt5uEi+8tIHf9z7f3nisadoxB3c99gZ6ImIpgKRLgHnAQ83e0XaTi0Ny8Om3MnX7yXSoSCAdgpc2Bi+u38iL6zeybv2GvtpHh2Bix9B5V0oviu+SiiELVVlO+6mUVc88W6ntqOb7+pbTmk3LqrfdfBbbTbbt+/7N91n9XQN9T7OVvoeSd1B2/K34N2jExnRRHPmmmZx961IO+86v2HbyBIQ2OY+rf4/qa2Ogc70Zmv3nXDMrTc0eh27u9JfxHx/qbup3wvhJFjOA5VXvVwD7VG8gaQGwAGC33Xare0dvmzOVbx/1Rm5b+jQbo2iwiyh6R02cICZN6GDSxOK19cQJTJrYwfPr1rN+iNpFRHFCxCbfV1OWttsYNUOx9b0ZuP96ZXmw/u0xYNnmG2y6z82nxmzFHYWyd1H2bZHSD1FL/g1ikz8a6vHXXTvy3r26ePW0HfhVz1ObnP/FPvqviUpBURabrG92Xmx2Ampm4m5mbLvtsm0Tv63feEkWw4qIhcBCgO7u7rovK0m8+/W78u7X79q02My2RLOnbufrKCPjos0CWAnMrHrflcrMzKwFxkuyuBOYI2m2pEnAkcDiNsdkZrbFGBe3oSJivaRPANcCE4BFEfFgm8MyM9tijItkARAR1wDXtDsOM7Mt0Xi5DWVmZm3kZGFmZsNysjAzs2E5WZiZ2bCU42BfknqBZQ18xVTgqSaF00yOa3Qc1+iM1bhg7MaWW1yvjIjOgVZkmSwaJWlJRDR/cJUGOa7RcVyjM1bjgrEb25YUl29DmZnZsJwszMxsWE4WA1vY7gAG4bhGx3GNzliNC8ZubFtMXG6zMDOzYblmYWZmw3KyMDOzYTlZVJF0kKRHJPVIOqHNsTwu6TeS7pW0JJXtLOl6SY+mnzu1KJZFklZLeqCqbMBYVDgjHcP7Je3V4rhOlrQyHbd7JR1Ste7EFNcjkt5RYlwzJd0k6SFJD0o6LpW39ZgNEVdbj5mkrSXdIem+FNc/p/LZkm5P+780TU+ApMnpfU9aP6vFcZ0n6bGq4/WGVN6ycz/tb4KkeyRdnd6Xe7yKaT79ohj6/PfA7sAk4D5gbhvjeRyYWlP2deCEtHwC8LUWxfI2YC/ggeFiAQ4BfkoxU+S+wO0tjutk4LMDbDs3/ZtOBmanf+sJJcU1HdgrLe8A/C7tv63HbIi42nrM0u+9fVreCrg9HYfLgCNT+b8DH0/L/wT8e1o+Eri0pOM1WFznAYcPsH3Lzv20v+OBHwBXp/elHi/XLPrtDfRExNKIeBG4BJjX5phqzQPOT8vnA4e1YqcRcQuwZoSxzAMuiMJtwBRJ01sY12DmAZdExLqIeAzoofg3LyOuVRFxd1p+DniYYh75th6zIeIaTEuOWfq9n09vt0qvAPYHLk/ltcerchwvBw6Qmj1j95BxDaZl576kLuCdwPfSe1Hy8XKy6DcDWF71fgVDX0hlC+A6SXdJWpDKpkXEqrT8BDCtPaENGctYOI6fSLcBFlXdqmtLXKnK/0aKv0rHzDGriQvafMzSLZV7gdXA9RS1mLURsX6AfffFldY/C+zSirgionK8Tk3H6zRJk2vjGiDmZvsW8HlgY3q/CyUfLyeLseutEfI7Q7kAAAQLSURBVLEXcDBwrKS3Va+Mok45Jvo9j6VYgLOAVwFvAFYB/7ddgUjaHrgC+HRE/LF6XTuP2QBxtf2YRcSGiHgD0EVRe/mrVscwkNq4JO0JnEgR35uAnYEvtDImSe8CVkfEXa3cr5NFv5XAzKr3XamsLSJiZfq5GvgRxQX0ZKVam36ubld8Q8TS1uMYEU+mC3wjcDb9t01aGpekrSj+Q74oIq5MxW0/ZgPFNVaOWYplLXAT8GaK2ziV2Tyr990XV1q/I/B0i+I6KN3Oi4hYB5xL64/XW4BDJT1Ocbt8f+B0Sj5eThb97gTmpB4Fkygagha3IxBJ20naobIMHAg8kOKZnzabD1zVjviSwWJZDBydeobsCzxbdeuldDX3iN9DcdwqcR2ZeobMBuYAd5QUg4BzgIcj4ptVq9p6zAaLq93HTFKnpClpeRvg7yjaU24CDk+b1R6vynE8HLgx1dRaEddvqxK+KNoFqo9X6f+OEXFiRHRFxCyK/6dujIgPUPbxambr/Hh/UfRm+B3F/dIvtTGO3Sl6odwHPFiJheI+4w3Ao8DPgZ1bFM/FFLcnXqK4F3rMYLFQ9AQ5Mx3D3wDdLY7r+2m/96eLZHrV9l9KcT0CHFxiXG+luMV0P3Bveh3S7mM2RFxtPWbA64B70v4fAL5cdR3cQdGw/kNgcirfOr3vSet3b3FcN6bj9QBwIf09plp27lfFuB/9vaFKPV4e7sPMzIbl21BmZjYsJwszMxuWk4WZmQ3LycLMzIblZGFmZsNysjAbBUkbqkYbvVdNHJ1Y0ixVjaBrNpZMHH4TM6vy5yiGfzDborhmYdYEKuYf+bqKOUjukLRHKp8l6cY06NwNknZL5dMk/UjFXAn3Sfof6asmSDpbxfwJ16Unh5H0KRXzUNwv6ZI2/Zq2BXOyMBudbWpuQ72/at2zEfHXwHcoRgUF+DZwfkS8DrgIOCOVnwH8IiJeTzEnx4OpfA5wZkS8FlgLvC+VnwC8MX3Px8r65cwG4ye4zUZB0vMRsf0A5Y8D+0fE0jRY3xMRsYukpyiGz3gpla+KiKmSeoGuKAajq3zHLIphsOek918AtoqIr0j6GfA88GPgx9E/z4JZS7hmYdY8McjyaKyrWt5Af7viOynGHdoLuLNqdFGzlnCyMGue91f9/HVa/n8UI4MCfAC4NS3fAHwc+ibY2XGwL5XUAcyMiJso5k7YEdisdmNWJv91YjY626SZ0yp+FhGV7rM7SbqfonZwVCr7JHCupM8BvcBHUvlxwEJJx1DUID5OMYLuQCYAF6aEIuCMKOZXMGsZt1mYNUFqs+iOiKfaHYtZGXwbyszMhuWahZmZDcs1CzMzG5aThZmZDcvJwszMhuVkYWZmw3KyMDOzYf1/mEXRPyTAcP0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = (50, 256, 7) # (input size, hidden size, number of classes)\n",
        "model_path = get_model_path(\"Transformer_news_classifier_2\", 128, 0.01, 229, \"Aug_13_00_28_hidden_size_256\")\n",
        "test_result = test_model(Transformer_news_classifier_2, parameters, True, model_path, test_loader, nn.MSELoss())\n",
        "print(\"Correct: {0}\\tTotal: {1}\\tAccuracy: {2}\\tLoss: {3}\".format(test_result[0], test_result[1], test_result[2], test_result[3]))"
      ],
      "metadata": {
        "id": "gEeaAPkuKYEL",
        "outputId": "5c587f39-ffd0-401c-d48b-2f926e539b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Correct: 1306\tTotal: 1560\tAccuracy: 0.8371794871794872\tLoss: 0.05682820316690665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"Correct: 1306\tTotal: 1560\tAccuracy: 0.8371794871794872\tLoss: 0.05682820316690665\" >> /model/test_result.txt"
      ],
      "metadata": {
        "id": "7NcvTFK-3IH0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /model /content/drive/MyDrive/ -r"
      ],
      "metadata": {
        "id": "7BTvmlw9MO6o"
      },
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "all_code.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
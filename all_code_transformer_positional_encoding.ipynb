{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NENROZ0T0m9D",
        "outputId": "f85dd403-2d24-49a6-ec52-99a0b0cecfe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp '/content/drive/MyDrive/data' '/' -r"
      ],
      "metadata": {
        "id": "PSHfppoAE7Bj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm /model -r\n",
        "! mkdir /model"
      ],
      "metadata": {
        "id": "OssqkfxpGApJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "k4paDiag0lNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torchtext\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "BIhi0eyZq9HY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileNn = ''"
      ],
      "metadata": {
        "id": "jDZFsrDrtNe6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def skipFromHere(index):\n",
        "\n",
        "    if index > 50:\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "metadata": {
        "id": "7lz_LlH58PLv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YWA4tXeB0lNh"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import torchtext\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "def data_loader(batch_size=128):\n",
        "    # load data from csv file\n",
        "    fields = ['news_article', 'news_category']\n",
        "\n",
        "    train_data = pd.read_csv(fileNn + '/data/inshort_news_data-train.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    val_data = pd.read_csv(fileNn +'/data/inshort_news_data-val.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    test_data = pd.read_csv(fileNn +'/data/inshort_news_data-test.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    new_data = pd.read_csv(fileNn +'/data/new_news_articles.csv',header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True, skiprows=lambda x: skipFromHere(x))\n",
        "    # read_csv seems have bugs for skip_blank_lines accoring to return value of what i tried for \n",
        "    # new_data before and online forum, so i use skirows instead of skip_blank_lines\n",
        "\n",
        "\n",
        "    # Creating training and testing data\n",
        "    X_train = train_data['news_article']\n",
        "    Y_train = train_data['news_category']\n",
        "\n",
        "    X_test = test_data['news_article']\n",
        "    Y_test = test_data['news_category']\n",
        "\n",
        "    X_val = val_data['news_article']\n",
        "    Y_val = val_data['news_category']\n",
        "    \n",
        "    X_new = new_data['news_article']\n",
        "    Y_new = new_data['news_category']\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      X_train[i] = X_train[i].split()\n",
        "\n",
        "    for j in range(X_val.shape[0]):\n",
        "      X_val[j] = X_val[j].split()\n",
        "\n",
        "    for k in range(X_test.shape[0]):\n",
        "      X_test[k] = X_test[k].split()\n",
        "\n",
        "    for m in range(X_new.shape[0]):\n",
        "      X_new[m] = X_new[m].split()\n",
        "    # fixing bugs for interating out of range in above loop about new data\n",
        "\n",
        "\n",
        "    Y_train = pd.get_dummies(Y_train).to_numpy()\n",
        "    Y_val = pd.get_dummies(Y_val).to_numpy()\n",
        "    Y_test = pd.get_dummies(Y_test).to_numpy()\n",
        "    Y_new = pd.get_dummies(Y_new).to_numpy()\n",
        "\n",
        "    # stopwords to eliminate useless words\n",
        "    stopwords = []\n",
        "    stop = open(fileNn + '/data/stopwords.txt', encoding=\"utf-8\")\n",
        "    for line in stop:\n",
        "      stopwords.append(line.strip())\n",
        "    stop.close()\n",
        "\n",
        "    # choose first 61 words\n",
        "    for ix in X_train:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_val:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_test:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      if (len(X_new[i]) > 61):\n",
        "        X_new[i] = X_new[i][0:61]\n",
        "    # somehow above loops don't change len of each entry, now they are fine\n",
        "\n",
        "    # utilize Glove6B for embedding\n",
        "    glove = torchtext.vocab.GloVe(name='6B', dim=50)\n",
        "\n",
        "    # Filling the embedding matrix\n",
        "    embedding_matrix_train = np.zeros((X_train.shape[0], 61, 50))\n",
        "    embedding_matrix_val = np.zeros((X_val.shape[0], 61, 50))\n",
        "    embedding_matrix_test = np.zeros((X_test.shape[0], 61, 50))\n",
        "    embedding_matrix_new = np.zeros((X_new.shape[0], 61, 50))\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      for j in range(len(X_train[i])):\n",
        "        if not (X_train[i][j].lower() in stopwords):\n",
        "          embedding_matrix_train[i][j] = glove[X_train[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_val.shape[0]):\n",
        "      for j in range(len(X_val[i])):\n",
        "        if not (X_val[i][j].lower() in stopwords):\n",
        "          embedding_matrix_val[i][j] = glove[X_val[i][j].lower()]\n",
        "\n",
        "    for i in range(X_test.shape[0]):\n",
        "      for j in range(len(X_test[i])):\n",
        "        if not (X_test[i][j].lower() in stopwords):\n",
        "          embedding_matrix_test[i][j] = glove[X_test[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      for j in range(len(X_new[i])):\n",
        "        if not (X_new[i][j].lower() in stopwords):\n",
        "          embedding_matrix_new[i][j] = glove[X_new[i][j].lower()]\n",
        "\n",
        "    X_train_t = torch.from_numpy(embedding_matrix_train).to(torch.float32)\n",
        "    Y_train_t = torch.from_numpy(Y_train).to(torch.float32)\n",
        "    X_val_t = torch.from_numpy(embedding_matrix_val).to(torch.float32)\n",
        "    Y_val_t = torch.from_numpy(Y_val).to(torch.float32)\n",
        "    X_test_t = torch.from_numpy(embedding_matrix_test).to(torch.float32)\n",
        "    Y_test_t = torch.from_numpy(Y_test).to(torch.float32)\n",
        "    X_new_t = torch.from_numpy(embedding_matrix_new).to(torch.float32)\n",
        "    Y_new_t = torch.from_numpy(Y_new).to(torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
        "    val_dataset = TensorDataset(X_val_t, Y_val_t)\n",
        "    test_dataset = TensorDataset(X_test_t, Y_test_t)\n",
        "    new_dataset = TensorDataset(X_new_t, Y_new_t)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "    new_dataloader = DataLoader(new_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader, new_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader, new_loader = data_loader()"
      ],
      "metadata": {
        "id": "6RmVocW5sOcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd2dc59-ac03-4fde-9624-1322a41ee2f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.42MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:09<00:00, 42112.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num training articles:',len(train_loader.dataset))\n",
        "print('Num validation articles:',len(val_loader.dataset))\n",
        "print('Num test articles:',len(test_loader.dataset))\n",
        "print('Num new articles:',len(new_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Qt_1IlP7Lu",
        "outputId": "48397973-4eb6-416b-8996-2baa2039f9f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training articles: 6380\n",
            "Num validation articles: 1560\n",
            "Num test articles: 1560\n",
            "Num new articles: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NBx-LLzS0lNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from math import sin, cos\n",
        "use_cuda = True\n",
        "\n",
        "# I made this a bidirectional LSTM.\n",
        "class LSTM_news_classifier_3(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_3, self).__init__()\n",
        "        self.name = \"LSTM_3\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(out[:,-1,:])\n",
        "\n",
        "\n",
        "# LSTM model\n",
        "class LSTM_news_classifier_4(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_4, self).__init__()\n",
        "        self.name = \"LSTM_4\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, num_layers=2, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(4, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(4, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(out[:,-1,:])\n",
        "\n",
        "class positional_encoding(nn.Module):\n",
        "    def __init__(self, max_length, embedding_size):\n",
        "        super(positional_encoding, self).__init__()\n",
        "        self.pe_tensor = torch.zeros(max_length, embedding_size)\n",
        "        for pos in range(max_length):\n",
        "            for i in range(embedding_size):\n",
        "                if i % 2 == 0:\n",
        "                    pe = sin(pos / pow(10000, (2 * i / max_length)))\n",
        "                else:\n",
        "                    pe = cos(pos / pow(10000, (2 * (i - 1) / max_length)))\n",
        "                self.pe_tensor[pos][i] = pe\n",
        "\n",
        "    def forward(self, x):\n",
        "        pe_input = self.pe_tensor[:x.shape[1], :]\n",
        "        pe_input = pe_input.repeat(x.shape[0], 1, 1)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            pe_input = pe_input.cuda()\n",
        "        x = x + pe_input\n",
        "        return x\n",
        "\n",
        "\n",
        "class Transformer_news_classifier_2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(Transformer_news_classifier_2, self).__init__()\n",
        "        self.pos_encoding = positional_encoding(1000, input_size)\n",
        "        self.name = \"Transformer_news_classifier_2\"\n",
        "        self.linear_q = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_k = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_v = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_x = nn.Linear(input_size, hidden_size)\n",
        "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=4, batch_first=True)\n",
        "        self.fc1 = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size))\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = x + self.pos_encoding(x)\n",
        "        q, k, v = self.linear_q(x), self.linear_k(x), self.linear_v(x)\n",
        "        x = self.norm(self.linear_x(x) + self.attention(q, k, v)[0])\n",
        "        x = self.norm(x + self.fc1(x))\n",
        "        x = torch.sum(x, 1)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r97Hm3-x0lNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing Code"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JgVHyyl30lNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_model_path(name, batch_size, learning_rate, epoch, exercise_code):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}_exercise_{4}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_csv_path(name, batch_size, learning_rate, exercise_code):\n",
        "    \"\"\" Generate a name for the csv file consisting of all training and validation data\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"data_{0}_bs{1}_lr{2}_exercise_{3}.csv\".format(name,batch_size, learning_rate, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_fig_path(name1, name2, batch_size, learning_rate, exercise_code):\n",
        "    path = \"fig_{0}_bs{1}_lr{2}_exercise_{3}_{4}.png\".format(name1, batch_size, learning_rate, exercise_code, name2)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "def find_the_best_model(val_acc):\n",
        "    \"\"\" Find the model with the best validation accuracy\n",
        "\n",
        "    Args:\n",
        "        validation accuracy list\n",
        "    Returns:\n",
        "        The epoch with the greatest accuracy and its accuracy\n",
        "    \"\"\"\n",
        "    cur_largest = -1\n",
        "    cur_largest_epoch = -1\n",
        "    for epoch in range(len(val_acc)):\n",
        "        if(val_acc[epoch] > cur_largest):\n",
        "            cur_largest = val_acc[epoch]\n",
        "            cur_largest_epoch = epoch\n",
        "    return cur_largest_epoch, cur_largest\n",
        "\n",
        "\n",
        "def save_to_csv(path, epochs, train_losses, train_acc, val_losses, val_acc, header):\n",
        "    organized_data = []\n",
        "    organized_data.append(header)\n",
        "    for i in range(len(epochs)):\n",
        "        organized_data.append([epochs[i], train_losses[i], train_acc[i], val_losses[i], val_acc[i]])\n",
        "    f = open(path,'w+')\n",
        "    write_csv = csv.writer(f)\n",
        "    write_csv.writerows(organized_data)\n",
        "\n",
        "\n",
        "def train_net(net, batch_size, learning_rate, num_epochs, train_loader, val_loader, exercise_code):\n",
        "    assert num_epochs > 0, \"num_epochs must be an integer that is greater than 0\"\n",
        "    assert learning_rate > 0, \"learning_rate must be greater than 0\"\n",
        "    torch.manual_seed(1000)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(),\n",
        "                                 lr=learning_rate,\n",
        "                                 weight_decay=1e-5)\n",
        "    epochs, train_losses, train_acc, val_losses, val_acc = [], [], [], [], []\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        epochs.append(epoch)\n",
        "        total, correct = 0, 0\n",
        "        total_loss = 0\n",
        "        for articles, labels in train_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                articles = articles.cuda()\n",
        "                labels = labels.cuda()\n",
        "            out = net(articles)\n",
        "            loss = criterion(out, labels)\n",
        "            total_loss = total_loss + loss.item() * articles.shape[0]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # print(out.shape)\n",
        "            pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "            # print(pred)\n",
        "            # print(torch.argmax(labels, dim=1))\n",
        "            correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "            total = total + articles.shape[0]\n",
        "            # print(correct, total)\n",
        "        train_acc.append(correct/total)\n",
        "        train_losses.append(total_loss/total)\n",
        "\n",
        "        val_correct = 0\n",
        "        val_total_loss = 0\n",
        "        val_total = 0\n",
        "        for val_articles, val_labels in val_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                val_articles = val_articles.cuda()\n",
        "                val_labels = val_labels.cuda()\n",
        "            val_out = net(val_articles)\n",
        "            # print(val_imgs)\n",
        "            val_pred = torch.squeeze(val_out.max(1, keepdim=True)[1], 1)\n",
        "            val_correct = val_correct + val_pred.eq(torch.argmax(val_labels, dim=1)).sum().item()\n",
        "            val_total = val_total + val_articles.shape[0]\n",
        "            val_total_loss = val_total_loss + (criterion(val_out, val_labels)).item() * val_articles.shape[0]\n",
        "        val_losses.append(val_total_loss/val_total) # Append the average loss\n",
        "        val_acc.append(val_correct/val_total)\n",
        "\n",
        "        print(\"Epoch {0}:\\ntraining accuracy: {1}\\ttraining loss: {2}\\tvalidation accuracy: {3}\\tvalidation loss:{4}\".format(epoch, train_acc[epoch], train_losses[epoch], val_acc[epoch], val_losses[epoch]))\n",
        "        print(\"Correct number of outputs in validation: {0}\\tTotal number of outputs in validation: {1}\\tTotal validation loss {2}\".format(val_correct, val_total, val_total_loss))\n",
        "        model_path = get_model_path(net.name, batch_size, learning_rate, epoch, exercise_code)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "    end_time = time.time()\n",
        "    print(\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % (\n",
        "    (end_time - start_time), ((end_time - start_time) / num_epochs)))\n",
        "\n",
        "    best_epoch, best_epoch_acc = find_the_best_model(val_acc)\n",
        "    print(\"The best epoch: {0}\\tAccuracy:{1}\".format(best_epoch, best_epoch_acc))\n",
        "\n",
        "    csv_path = get_csv_path(net.name, batch_size, learning_rate, exercise_code)\n",
        "    header = [\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Validation Loss\", \"Validation Accuracy\"]\n",
        "    save_to_csv(csv_path, epochs, train_losses, train_acc, val_losses, val_acc, header)\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.plot(epochs, train_losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Accuracy Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Training\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Loss Curve\")\n",
        "    plt.plot(epochs, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Accuracy Curve\")\n",
        "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Validation Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def test_model(net_type, parameters, use_cuda, model_path, data_loader, criterion):\n",
        "    state = torch.load(model_path)\n",
        "    net = net_type(parameters[0], parameters[1], parameters[2])\n",
        "    net.load_state_dict(state)\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        net.cuda()\n",
        "        print('CUDA is available!  Training on GPU ...')\n",
        "    else:\n",
        "        print('CUDA is not available.  Training on CPU ...')\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    for articles, labels in data_loader:\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            articles = articles.cuda()\n",
        "            labels = labels.cuda()\n",
        "        out = net(articles)\n",
        "        pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "        correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "        total = total + articles.shape[0]\n",
        "        total_loss = total_loss + (criterion(out, labels)).item() * articles.shape[0]\n",
        "    return correct, total, correct / total, total_loss / total"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G3SQ8YIm0lNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test your model here"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XHaSVNYM0lNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "News_model = Transformer_news_classifier_2(50, 256, 7)\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  News_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')"
      ],
      "metadata": {
        "id": "e5qO3oIjFmFN",
        "outputId": "dc2da0cf-b225-4aee-d4b8-c8968878ef55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_net(News_model, 128, 0.01, 400, train_loader, val_loader, 'Aug_13_00_28_hidden_size_256')"
      ],
      "metadata": {
        "id": "Yov5VrVvJOWd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ff95647-f7c4-4a2f-e9bc-d06c4fea67c6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "training accuracy: 0.14623824451410658\ttraining loss: 962.2327593020137\tvalidation accuracy: 0.13141025641025642\tvalidation loss:8.30631846892528\n",
            "Correct number of outputs in validation: 205\tTotal number of outputs in validation: 1560\tTotal validation loss 12957.856811523438\n",
            "Epoch 1:\n",
            "training accuracy: 0.1482758620689655\ttraining loss: 2.854396748580155\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.9044209623948122\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 1410.896701335907\n",
            "Epoch 2:\n",
            "training accuracy: 0.13557993730407525\ttraining loss: 0.5232357175372611\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.30850950013368555\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 481.2748202085495\n",
            "Epoch 3:\n",
            "training accuracy: 0.14059561128526646\ttraining loss: 0.2987044688115673\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.36786524684001237\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 573.8697850704193\n",
            "Epoch 4:\n",
            "training accuracy: 0.1358934169278997\ttraining loss: 0.3658661846643705\tvalidation accuracy: 0.1423076923076923\tvalidation loss:0.5072987402096772\n",
            "Correct number of outputs in validation: 222\tTotal number of outputs in validation: 1560\tTotal validation loss 791.3860347270966\n",
            "Epoch 5:\n",
            "training accuracy: 0.14717868338557993\ttraining loss: 0.37000448473942316\tvalidation accuracy: 0.13782051282051283\tvalidation loss:0.4448129770083305\n",
            "Correct number of outputs in validation: 215\tTotal number of outputs in validation: 1560\tTotal validation loss 693.9082441329956\n",
            "Epoch 6:\n",
            "training accuracy: 0.1322884012539185\ttraining loss: 0.41035879110467843\tvalidation accuracy: 0.1371794871794872\tvalidation loss:0.4399579480672494\n",
            "Correct number of outputs in validation: 214\tTotal number of outputs in validation: 1560\tTotal validation loss 686.3343989849091\n",
            "Epoch 7:\n",
            "training accuracy: 0.16990595611285267\ttraining loss: 0.4939425221804915\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.3566933247905511\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 556.4415866732597\n",
            "Epoch 8:\n",
            "training accuracy: 0.14796238244514107\ttraining loss: 0.6640766707707348\tvalidation accuracy: 0.1608974358974359\tvalidation loss:0.23136005371044843\n",
            "Correct number of outputs in validation: 251\tTotal number of outputs in validation: 1560\tTotal validation loss 360.92168378829956\n",
            "Epoch 9:\n",
            "training accuracy: 0.14545454545454545\ttraining loss: 1.6133537523051413\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.467669210372827\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 729.5639681816101\n",
            "Epoch 10:\n",
            "training accuracy: 0.15768025078369907\ttraining loss: 1.2724931136941462\tvalidation accuracy: 0.14294871794871794\tvalidation loss:2.2884951444772574\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 3570.0524253845215\n",
            "Epoch 11:\n",
            "training accuracy: 0.13981191222570533\ttraining loss: 5.0512488558000905\tvalidation accuracy: 0.15064102564102563\tvalidation loss:0.7905213429377629\n",
            "Correct number of outputs in validation: 235\tTotal number of outputs in validation: 1560\tTotal validation loss 1233.2132949829102\n",
            "Epoch 12:\n",
            "training accuracy: 0.16018808777429466\ttraining loss: 1.0836272104406806\tvalidation accuracy: 0.14294871794871794\tvalidation loss:1.293709458448948\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 2018.186755180359\n",
            "Epoch 13:\n",
            "training accuracy: 0.1470219435736677\ttraining loss: 1.7336614440601075\tvalidation accuracy: 0.14294871794871794\tvalidation loss:1.4974431236584982\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 2336.011272907257\n",
            "Epoch 14:\n",
            "training accuracy: 0.1299373040752351\ttraining loss: 2.1783107243361517\tvalidation accuracy: 0.15\tvalidation loss:4.838730142055414\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 7548.419021606445\n",
            "Epoch 15:\n",
            "training accuracy: 0.13981191222570533\ttraining loss: 3.2172362752095287\tvalidation accuracy: 0.14294871794871794\tvalidation loss:1.9665408281179575\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 3067.8036918640137\n",
            "Epoch 16:\n",
            "training accuracy: 0.14169278996865203\ttraining loss: 2.2606848708888205\tvalidation accuracy: 0.15320512820512822\tvalidation loss:1.3963488676609137\n",
            "Correct number of outputs in validation: 239\tTotal number of outputs in validation: 1560\tTotal validation loss 2178.3042335510254\n",
            "Epoch 17:\n",
            "training accuracy: 0.14373040752351096\ttraining loss: 2.454854791515673\tvalidation accuracy: 0.14102564102564102\tvalidation loss:3.7284088012499685\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 5816.317729949951\n",
            "Epoch 18:\n",
            "training accuracy: 0.13761755485893418\ttraining loss: 3.1318675657798503\tvalidation accuracy: 0.14166666666666666\tvalidation loss:1.7644554633360643\n",
            "Correct number of outputs in validation: 221\tTotal number of outputs in validation: 1560\tTotal validation loss 2752.5505228042603\n",
            "Epoch 19:\n",
            "training accuracy: 0.14796238244514107\ttraining loss: 2.1145715040566406\tvalidation accuracy: 0.13333333333333333\tvalidation loss:0.7674365523533944\n",
            "Correct number of outputs in validation: 208\tTotal number of outputs in validation: 1560\tTotal validation loss 1197.2010216712952\n",
            "Epoch 20:\n",
            "training accuracy: 0.14623824451410658\ttraining loss: 2.2067485558949294\tvalidation accuracy: 0.14102564102564102\tvalidation loss:1.5946303282028589\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 2487.62331199646\n",
            "Epoch 21:\n",
            "training accuracy: 0.15517241379310345\ttraining loss: 2.1320141453728034\tvalidation accuracy: 0.14038461538461539\tvalidation loss:1.1924079418182374\n",
            "Correct number of outputs in validation: 219\tTotal number of outputs in validation: 1560\tTotal validation loss 1860.1563892364502\n",
            "Epoch 22:\n",
            "training accuracy: 0.1463949843260188\ttraining loss: 1.8662388780647685\tvalidation accuracy: 0.14102564102564102\tvalidation loss:2.138574504852295\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 3336.17622756958\n",
            "Epoch 23:\n",
            "training accuracy: 0.14623824451410658\ttraining loss: 2.1627956741655883\tvalidation accuracy: 0.14102564102564102\tvalidation loss:2.5412521863595035\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 3964.353410720825\n",
            "Epoch 24:\n",
            "training accuracy: 0.14655172413793102\ttraining loss: 2.0793647746681048\tvalidation accuracy: 0.14102564102564102\tvalidation loss:2.940725665214734\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 4587.532037734985\n",
            "Epoch 25:\n",
            "training accuracy: 0.1493730407523511\ttraining loss: 2.154545504247133\tvalidation accuracy: 0.14038461538461539\tvalidation loss:1.4095116884280474\n",
            "Correct number of outputs in validation: 219\tTotal number of outputs in validation: 1560\tTotal validation loss 2198.838233947754\n",
            "Epoch 26:\n",
            "training accuracy: 0.14169278996865203\ttraining loss: 1.6335805488230666\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.9145406551850148\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 1426.683422088623\n",
            "Epoch 27:\n",
            "training accuracy: 0.14075235109717868\ttraining loss: 1.7198683974884894\tvalidation accuracy: 0.14102564102564102\tvalidation loss:2.506140915552775\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 3909.579828262329\n",
            "Epoch 28:\n",
            "training accuracy: 0.14435736677115987\ttraining loss: 1.8087578228648553\tvalidation accuracy: 0.13076923076923078\tvalidation loss:0.5520813104433892\n",
            "Correct number of outputs in validation: 204\tTotal number of outputs in validation: 1560\tTotal validation loss 861.246844291687\n",
            "Epoch 29:\n",
            "training accuracy: 0.14608150470219436\ttraining loss: 1.3348784399630507\tvalidation accuracy: 0.1673076923076923\tvalidation loss:0.9757629865255111\n",
            "Correct number of outputs in validation: 261\tTotal number of outputs in validation: 1560\tTotal validation loss 1522.1902589797974\n",
            "Epoch 30:\n",
            "training accuracy: 0.14216300940438872\ttraining loss: 1.4880317247026018\tvalidation accuracy: 0.15320512820512822\tvalidation loss:1.4018404385982415\n",
            "Correct number of outputs in validation: 239\tTotal number of outputs in validation: 1560\tTotal validation loss 2186.871084213257\n",
            "Epoch 31:\n",
            "training accuracy: 0.14655172413793102\ttraining loss: 1.4579063569490438\tvalidation accuracy: 0.15256410256410258\tvalidation loss:1.1463362770202832\n",
            "Correct number of outputs in validation: 238\tTotal number of outputs in validation: 1560\tTotal validation loss 1788.2845921516418\n",
            "Epoch 32:\n",
            "training accuracy: 0.14952978056426333\ttraining loss: 1.3169473577816284\tvalidation accuracy: 0.15\tvalidation loss:1.1151890461261456\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 1739.694911956787\n",
            "Epoch 33:\n",
            "training accuracy: 0.15156739811912226\ttraining loss: 1.305203230627652\tvalidation accuracy: 0.16346153846153846\tvalidation loss:0.9284103531103868\n",
            "Correct number of outputs in validation: 255\tTotal number of outputs in validation: 1560\tTotal validation loss 1448.3201508522034\n",
            "Epoch 34:\n",
            "training accuracy: 0.15956112852664578\ttraining loss: 1.2444871711133043\tvalidation accuracy: 0.15128205128205127\tvalidation loss:0.8151839363269316\n",
            "Correct number of outputs in validation: 236\tTotal number of outputs in validation: 1560\tTotal validation loss 1271.6869406700134\n",
            "Epoch 35:\n",
            "training accuracy: 0.15673981191222572\ttraining loss: 1.218681818415005\tvalidation accuracy: 0.1608974358974359\tvalidation loss:0.7165107164627467\n",
            "Correct number of outputs in validation: 251\tTotal number of outputs in validation: 1560\tTotal validation loss 1117.7567176818848\n",
            "Epoch 36:\n",
            "training accuracy: 0.1523510971786834\ttraining loss: 1.1733840842232062\tvalidation accuracy: 0.2141025641025641\tvalidation loss:0.6380166192849477\n",
            "Correct number of outputs in validation: 334\tTotal number of outputs in validation: 1560\tTotal validation loss 995.3059260845184\n",
            "Epoch 37:\n",
            "training accuracy: 0.15282131661442006\ttraining loss: 1.067782425058299\tvalidation accuracy: 0.22243589743589742\tvalidation loss:0.4326914232510787\n",
            "Correct number of outputs in validation: 347\tTotal number of outputs in validation: 1560\tTotal validation loss 674.9986202716827\n",
            "Epoch 38:\n",
            "training accuracy: 0.15438871473354232\ttraining loss: 1.0166258573158409\tvalidation accuracy: 0.17051282051282052\tvalidation loss:0.48845642743966516\n",
            "Correct number of outputs in validation: 266\tTotal number of outputs in validation: 1560\tTotal validation loss 761.9920268058777\n",
            "Epoch 39:\n",
            "training accuracy: 0.16018808777429466\ttraining loss: 0.9668107765969064\tvalidation accuracy: 0.15128205128205127\tvalidation loss:0.5396195666912275\n",
            "Correct number of outputs in validation: 236\tTotal number of outputs in validation: 1560\tTotal validation loss 841.8065240383148\n",
            "Epoch 40:\n",
            "training accuracy: 0.1615987460815047\ttraining loss: 0.9341275627710229\tvalidation accuracy: 0.1423076923076923\tvalidation loss:0.5253252752316304\n",
            "Correct number of outputs in validation: 222\tTotal number of outputs in validation: 1560\tTotal validation loss 819.5074293613434\n",
            "Epoch 41:\n",
            "training accuracy: 0.16238244514106584\ttraining loss: 0.9846605644704406\tvalidation accuracy: 0.15576923076923077\tvalidation loss:0.36061265483880656\n",
            "Correct number of outputs in validation: 243\tTotal number of outputs in validation: 1560\tTotal validation loss 562.5557415485382\n",
            "Epoch 42:\n",
            "training accuracy: 0.17084639498432602\ttraining loss: 0.9132618033400149\tvalidation accuracy: 0.23012820512820512\tvalidation loss:0.16688360491624246\n",
            "Correct number of outputs in validation: 359\tTotal number of outputs in validation: 1560\tTotal validation loss 260.3384236693382\n",
            "Epoch 43:\n",
            "training accuracy: 0.18134796238244513\ttraining loss: 0.8029727068440667\tvalidation accuracy: 0.16794871794871793\tvalidation loss:0.18900833886403304\n",
            "Correct number of outputs in validation: 262\tTotal number of outputs in validation: 1560\tTotal validation loss 294.85300862789154\n",
            "Epoch 44:\n",
            "training accuracy: 0.1811912225705329\ttraining loss: 0.7881864952069465\tvalidation accuracy: 0.16153846153846155\tvalidation loss:0.22922978653357579\n",
            "Correct number of outputs in validation: 252\tTotal number of outputs in validation: 1560\tTotal validation loss 357.59846699237823\n",
            "Epoch 45:\n",
            "training accuracy: 0.17664576802507836\ttraining loss: 0.7902573850461309\tvalidation accuracy: 0.175\tvalidation loss:0.2290396693425301\n",
            "Correct number of outputs in validation: 273\tTotal number of outputs in validation: 1560\tTotal validation loss 357.3018841743469\n",
            "Epoch 46:\n",
            "training accuracy: 0.1797805642633229\ttraining loss: 0.7745252052444649\tvalidation accuracy: 0.20256410256410257\tvalidation loss:0.23638235445205982\n",
            "Correct number of outputs in validation: 316\tTotal number of outputs in validation: 1560\tTotal validation loss 368.7564729452133\n",
            "Epoch 47:\n",
            "training accuracy: 0.18040752351097178\ttraining loss: 0.7819014232547306\tvalidation accuracy: 0.1596153846153846\tvalidation loss:0.31335471165485873\n",
            "Correct number of outputs in validation: 249\tTotal number of outputs in validation: 1560\tTotal validation loss 488.8333501815796\n",
            "Epoch 48:\n",
            "training accuracy: 0.1866771159874608\ttraining loss: 0.7986196241034983\tvalidation accuracy: 0.15320512820512822\tvalidation loss:0.5062015102459834\n",
            "Correct number of outputs in validation: 239\tTotal number of outputs in validation: 1560\tTotal validation loss 789.6743559837341\n",
            "Epoch 49:\n",
            "training accuracy: 0.1921630094043887\ttraining loss: 0.8197712666936056\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.6918413446499752\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 1079.2724976539612\n",
            "Epoch 50:\n",
            "training accuracy: 0.18683385579937303\ttraining loss: 0.7924333481205669\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.4970526948953286\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 775.4022040367126\n",
            "Epoch 51:\n",
            "training accuracy: 0.18589341692789968\ttraining loss: 0.7916930507716714\tvalidation accuracy: 0.15128205128205127\tvalidation loss:0.35062225812520736\n",
            "Correct number of outputs in validation: 236\tTotal number of outputs in validation: 1560\tTotal validation loss 546.9707226753235\n",
            "Epoch 52:\n",
            "training accuracy: 0.17272727272727273\ttraining loss: 0.7124629704929818\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.298009232374338\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 464.8944025039673\n",
            "Epoch 53:\n",
            "training accuracy: 0.17413793103448275\ttraining loss: 0.6494778641712703\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.33804336266639906\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 527.3476457595825\n",
            "Epoch 54:\n",
            "training accuracy: 0.1664576802507837\ttraining loss: 0.6254392853351223\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.341515936759802\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 532.7648613452911\n",
            "Epoch 55:\n",
            "training accuracy: 0.1700626959247649\ttraining loss: 0.6188898675120362\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.2889220124635941\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 450.7183394432068\n",
            "Epoch 56:\n",
            "training accuracy: 0.16394984326018808\ttraining loss: 0.6250785722627908\tvalidation accuracy: 0.1641025641025641\tvalidation loss:0.25743734469780555\n",
            "Correct number of outputs in validation: 256\tTotal number of outputs in validation: 1560\tTotal validation loss 401.60225772857666\n",
            "Epoch 57:\n",
            "training accuracy: 0.1652037617554859\ttraining loss: 0.6313732025578478\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.3248000947328714\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 506.6881477832794\n",
            "Epoch 58:\n",
            "training accuracy: 0.18761755485893417\ttraining loss: 0.5970865692277687\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.2798970242341359\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 436.6393578052521\n",
            "Epoch 59:\n",
            "training accuracy: 0.18887147335423196\ttraining loss: 0.5256808983121173\tvalidation accuracy: 0.175\tvalidation loss:0.31274270934936327\n",
            "Correct number of outputs in validation: 273\tTotal number of outputs in validation: 1560\tTotal validation loss 487.8786265850067\n",
            "Epoch 60:\n",
            "training accuracy: 0.19106583072100314\ttraining loss: 0.48978487439103263\tvalidation accuracy: 0.1717948717948718\tvalidation loss:0.3120445896417667\n",
            "Correct number of outputs in validation: 268\tTotal number of outputs in validation: 1560\tTotal validation loss 486.789559841156\n",
            "Epoch 61:\n",
            "training accuracy: 0.1934169278996865\ttraining loss: 0.467876564737024\tvalidation accuracy: 0.1596153846153846\tvalidation loss:0.3249340569361662\n",
            "Correct number of outputs in validation: 249\tTotal number of outputs in validation: 1560\tTotal validation loss 506.8971288204193\n",
            "Epoch 62:\n",
            "training accuracy: 0.20094043887147336\ttraining loss: 0.45994402611143537\tvalidation accuracy: 0.1717948717948718\tvalidation loss:0.2917610246401567\n",
            "Correct number of outputs in validation: 268\tTotal number of outputs in validation: 1560\tTotal validation loss 455.1471984386444\n",
            "Epoch 63:\n",
            "training accuracy: 0.2103448275862069\ttraining loss: 0.4514607012645578\tvalidation accuracy: 0.17051282051282052\tvalidation loss:0.2949992049963046\n",
            "Correct number of outputs in validation: 266\tTotal number of outputs in validation: 1560\tTotal validation loss 460.19875979423523\n",
            "Epoch 64:\n",
            "training accuracy: 0.2079937304075235\ttraining loss: 0.4610119819827962\tvalidation accuracy: 0.18782051282051282\tvalidation loss:0.3054307115383637\n",
            "Correct number of outputs in validation: 293\tTotal number of outputs in validation: 1560\tTotal validation loss 476.4719099998474\n",
            "Epoch 65:\n",
            "training accuracy: 0.1974921630094044\ttraining loss: 0.48634955391614787\tvalidation accuracy: 0.1955128205128205\tvalidation loss:0.3727484617477808\n",
            "Correct number of outputs in validation: 305\tTotal number of outputs in validation: 1560\tTotal validation loss 581.4876003265381\n",
            "Epoch 66:\n",
            "training accuracy: 0.19059561128526645\ttraining loss: 0.5219157954368472\tvalidation accuracy: 0.18205128205128204\tvalidation loss:0.41704390415778525\n",
            "Correct number of outputs in validation: 284\tTotal number of outputs in validation: 1560\tTotal validation loss 650.588490486145\n",
            "Epoch 67:\n",
            "training accuracy: 0.18369905956112853\ttraining loss: 0.5678414635150036\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.3735646677322877\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 582.7608816623688\n",
            "Epoch 68:\n",
            "training accuracy: 0.17037617554858933\ttraining loss: 0.5997974428824123\tvalidation accuracy: 0.22115384615384615\tvalidation loss:1.0486396245467358\n",
            "Correct number of outputs in validation: 345\tTotal number of outputs in validation: 1560\tTotal validation loss 1635.8778142929077\n",
            "Epoch 69:\n",
            "training accuracy: 0.17852664576802507\ttraining loss: 0.5157644881723816\tvalidation accuracy: 0.20448717948717948\tvalidation loss:0.7270109054369804\n",
            "Correct number of outputs in validation: 319\tTotal number of outputs in validation: 1560\tTotal validation loss 1134.1370124816895\n",
            "Epoch 70:\n",
            "training accuracy: 0.2043887147335423\ttraining loss: 0.40515312453422425\tvalidation accuracy: 0.2403846153846154\tvalidation loss:0.734857960542043\n",
            "Correct number of outputs in validation: 375\tTotal number of outputs in validation: 1560\tTotal validation loss 1146.3784184455872\n",
            "Epoch 71:\n",
            "training accuracy: 0.20094043887147336\ttraining loss: 0.41405107933899454\tvalidation accuracy: 0.1794871794871795\tvalidation loss:0.6932307072174855\n",
            "Correct number of outputs in validation: 280\tTotal number of outputs in validation: 1560\tTotal validation loss 1081.4399032592773\n",
            "Epoch 72:\n",
            "training accuracy: 0.18087774294670847\ttraining loss: 0.43963370226019977\tvalidation accuracy: 0.1467948717948718\tvalidation loss:0.6244539673511799\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 974.1481890678406\n",
            "Epoch 73:\n",
            "training accuracy: 0.17821316614420063\ttraining loss: 0.43135455215238855\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.7187250727262252\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 1121.2111134529114\n",
            "Epoch 74:\n",
            "training accuracy: 0.1810344827586207\ttraining loss: 0.3639332108549937\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.6019816762361772\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 939.0914149284363\n",
            "Epoch 75:\n",
            "training accuracy: 0.19169278996865205\ttraining loss: 0.3228034345333853\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.5595997278506939\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 872.9755754470825\n",
            "Epoch 76:\n",
            "training accuracy: 0.1926332288401254\ttraining loss: 0.3243191361427307\tvalidation accuracy: 0.14807692307692308\tvalidation loss:0.5141630233862461\n",
            "Correct number of outputs in validation: 231\tTotal number of outputs in validation: 1560\tTotal validation loss 802.094316482544\n",
            "Epoch 77:\n",
            "training accuracy: 0.18871473354231974\ttraining loss: 0.31549120651890866\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.4321619036870125\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 674.1725697517395\n",
            "Epoch 78:\n",
            "training accuracy: 0.19357366771159876\ttraining loss: 0.29737685403106356\tvalidation accuracy: 0.175\tvalidation loss:0.35119137932092714\n",
            "Correct number of outputs in validation: 273\tTotal number of outputs in validation: 1560\tTotal validation loss 547.8585517406464\n",
            "Epoch 79:\n",
            "training accuracy: 0.2029780564263323\ttraining loss: 0.2792353032524683\tvalidation accuracy: 0.17756410256410257\tvalidation loss:0.3503881054046826\n",
            "Correct number of outputs in validation: 277\tTotal number of outputs in validation: 1560\tTotal validation loss 546.6054444313049\n",
            "Epoch 80:\n",
            "training accuracy: 0.20329153605015673\ttraining loss: 0.28634627250294703\tvalidation accuracy: 0.16794871794871793\tvalidation loss:0.31731475729208725\n",
            "Correct number of outputs in validation: 262\tTotal number of outputs in validation: 1560\tTotal validation loss 495.0110213756561\n",
            "Epoch 81:\n",
            "training accuracy: 0.20579937304075235\ttraining loss: 0.26515087575000656\tvalidation accuracy: 0.18205128205128204\tvalidation loss:0.3291889638472826\n",
            "Correct number of outputs in validation: 284\tTotal number of outputs in validation: 1560\tTotal validation loss 513.5347836017609\n",
            "Epoch 82:\n",
            "training accuracy: 0.21614420062695924\ttraining loss: 0.2560322699315122\tvalidation accuracy: 0.16538461538461538\tvalidation loss:0.43353685858922125\n",
            "Correct number of outputs in validation: 258\tTotal number of outputs in validation: 1560\tTotal validation loss 676.3174993991852\n",
            "Epoch 83:\n",
            "training accuracy: 0.19106583072100314\ttraining loss: 0.267380806308555\tvalidation accuracy: 0.1544871794871795\tvalidation loss:0.6031955508085397\n",
            "Correct number of outputs in validation: 241\tTotal number of outputs in validation: 1560\tTotal validation loss 940.985059261322\n",
            "Epoch 84:\n",
            "training accuracy: 0.20736677115987462\ttraining loss: 0.2649040036440643\tvalidation accuracy: 0.1596153846153846\tvalidation loss:0.5188313652307559\n",
            "Correct number of outputs in validation: 249\tTotal number of outputs in validation: 1560\tTotal validation loss 809.3769297599792\n",
            "Epoch 85:\n",
            "training accuracy: 0.20172413793103447\ttraining loss: 0.2419771498086684\tvalidation accuracy: 0.1621794871794872\tvalidation loss:0.4090387871632209\n",
            "Correct number of outputs in validation: 253\tTotal number of outputs in validation: 1560\tTotal validation loss 638.1005079746246\n",
            "Epoch 86:\n",
            "training accuracy: 0.20642633228840127\ttraining loss: 0.2282970944355274\tvalidation accuracy: 0.17884615384615385\tvalidation loss:0.3791186347985879\n",
            "Correct number of outputs in validation: 279\tTotal number of outputs in validation: 1560\tTotal validation loss 591.4250702857971\n",
            "Epoch 87:\n",
            "training accuracy: 0.21112852664576803\ttraining loss: 0.21923897574687826\tvalidation accuracy: 0.19166666666666668\tvalidation loss:0.30512405909024753\n",
            "Correct number of outputs in validation: 299\tTotal number of outputs in validation: 1560\tTotal validation loss 475.99353218078613\n",
            "Epoch 88:\n",
            "training accuracy: 0.22554858934169278\ttraining loss: 0.21090255054560575\tvalidation accuracy: 0.23205128205128206\tvalidation loss:0.25326987336843443\n",
            "Correct number of outputs in validation: 362\tTotal number of outputs in validation: 1560\tTotal validation loss 395.1010024547577\n",
            "Epoch 89:\n",
            "training accuracy: 0.2396551724137931\ttraining loss: 0.20489754936538146\tvalidation accuracy: 0.27371794871794874\tvalidation loss:0.2042022855618061\n",
            "Correct number of outputs in validation: 427\tTotal number of outputs in validation: 1560\tTotal validation loss 318.55556547641754\n",
            "Epoch 90:\n",
            "training accuracy: 0.2373040752351097\ttraining loss: 0.20151696995507962\tvalidation accuracy: 0.28525641025641024\tvalidation loss:0.1761246166168115\n",
            "Correct number of outputs in validation: 445\tTotal number of outputs in validation: 1560\tTotal validation loss 274.75440192222595\n",
            "Epoch 91:\n",
            "training accuracy: 0.2487460815047022\ttraining loss: 0.19448323169472076\tvalidation accuracy: 0.32243589743589746\tvalidation loss:0.1551420557575348\n",
            "Correct number of outputs in validation: 503\tTotal number of outputs in validation: 1560\tTotal validation loss 242.0216069817543\n",
            "Epoch 92:\n",
            "training accuracy: 0.2589341692789969\ttraining loss: 0.18773666543646667\tvalidation accuracy: 0.3032051282051282\tvalidation loss:0.14513614307611417\n",
            "Correct number of outputs in validation: 473\tTotal number of outputs in validation: 1560\tTotal validation loss 226.4123831987381\n",
            "Epoch 93:\n",
            "training accuracy: 0.26880877742946707\ttraining loss: 0.1778286146146003\tvalidation accuracy: 0.3262820512820513\tvalidation loss:0.13792509001034955\n",
            "Correct number of outputs in validation: 509\tTotal number of outputs in validation: 1560\tTotal validation loss 215.16314041614532\n",
            "Epoch 94:\n",
            "training accuracy: 0.2672413793103448\ttraining loss: 0.17366913669161663\tvalidation accuracy: 0.31025641025641026\tvalidation loss:0.13913851323036047\n",
            "Correct number of outputs in validation: 484\tTotal number of outputs in validation: 1560\tTotal validation loss 217.05608063936234\n",
            "Epoch 95:\n",
            "training accuracy: 0.26614420062695926\ttraining loss: 0.17117653625512197\tvalidation accuracy: 0.3019230769230769\tvalidation loss:0.14078765354859524\n",
            "Correct number of outputs in validation: 471\tTotal number of outputs in validation: 1560\tTotal validation loss 219.62873953580856\n",
            "Epoch 96:\n",
            "training accuracy: 0.2689655172413793\ttraining loss: 0.1677853804396985\tvalidation accuracy: 0.3038461538461538\tvalidation loss:0.14118953450368002\n",
            "Correct number of outputs in validation: 474\tTotal number of outputs in validation: 1560\tTotal validation loss 220.2556738257408\n",
            "Epoch 97:\n",
            "training accuracy: 0.2721003134796238\ttraining loss: 0.17525643758639273\tvalidation accuracy: 0.2826923076923077\tvalidation loss:0.14062751944248492\n",
            "Correct number of outputs in validation: 441\tTotal number of outputs in validation: 1560\tTotal validation loss 219.3789303302765\n",
            "Epoch 98:\n",
            "training accuracy: 0.2717868338557994\ttraining loss: 0.18155960388318124\tvalidation accuracy: 0.3108974358974359\tvalidation loss:0.13318991019175602\n",
            "Correct number of outputs in validation: 485\tTotal number of outputs in validation: 1560\tTotal validation loss 207.7762598991394\n",
            "Epoch 99:\n",
            "training accuracy: 0.27836990595611283\ttraining loss: 0.17479369404921338\tvalidation accuracy: 0.3019230769230769\tvalidation loss:0.13844159337190481\n",
            "Correct number of outputs in validation: 471\tTotal number of outputs in validation: 1560\tTotal validation loss 215.9688856601715\n",
            "Epoch 100:\n",
            "training accuracy: 0.284012539184953\ttraining loss: 0.16664592961906266\tvalidation accuracy: 0.26666666666666666\tvalidation loss:0.14769709882063745\n",
            "Correct number of outputs in validation: 416\tTotal number of outputs in validation: 1560\tTotal validation loss 230.4074741601944\n",
            "Epoch 101:\n",
            "training accuracy: 0.2901253918495298\ttraining loss: 0.1624955126577784\tvalidation accuracy: 0.2512820512820513\tvalidation loss:0.14190021386513343\n",
            "Correct number of outputs in validation: 392\tTotal number of outputs in validation: 1560\tTotal validation loss 221.36433362960815\n",
            "Epoch 102:\n",
            "training accuracy: 0.29686520376175546\ttraining loss: 0.15875006303144473\tvalidation accuracy: 0.2782051282051282\tvalidation loss:0.13934133633589132\n",
            "Correct number of outputs in validation: 434\tTotal number of outputs in validation: 1560\tTotal validation loss 217.37248468399048\n",
            "Epoch 103:\n",
            "training accuracy: 0.3054858934169279\ttraining loss: 0.15571453489106277\tvalidation accuracy: 0.2641025641025641\tvalidation loss:0.14283056220947168\n",
            "Correct number of outputs in validation: 412\tTotal number of outputs in validation: 1560\tTotal validation loss 222.81567704677582\n",
            "Epoch 104:\n",
            "training accuracy: 0.29247648902821316\ttraining loss: 0.15771862339450274\tvalidation accuracy: 0.2955128205128205\tvalidation loss:0.1369748898041554\n",
            "Correct number of outputs in validation: 461\tTotal number of outputs in validation: 1560\tTotal validation loss 213.68082809448242\n",
            "Epoch 105:\n",
            "training accuracy: 0.2940438871473354\ttraining loss: 0.15578673964944378\tvalidation accuracy: 0.3141025641025641\tvalidation loss:0.13958644767602285\n",
            "Correct number of outputs in validation: 490\tTotal number of outputs in validation: 1560\tTotal validation loss 217.75485837459564\n",
            "Epoch 106:\n",
            "training accuracy: 0.30893416927899686\ttraining loss: 0.1544359625787197\tvalidation accuracy: 0.2955128205128205\tvalidation loss:0.14083922589436557\n",
            "Correct number of outputs in validation: 461\tTotal number of outputs in validation: 1560\tTotal validation loss 219.70919239521027\n",
            "Epoch 107:\n",
            "training accuracy: 0.2995297805642633\ttraining loss: 0.1610860385584607\tvalidation accuracy: 0.30448717948717946\tvalidation loss:0.1330542193009303\n",
            "Correct number of outputs in validation: 475\tTotal number of outputs in validation: 1560\tTotal validation loss 207.5645821094513\n",
            "Epoch 108:\n",
            "training accuracy: 0.31677115987460813\ttraining loss: 0.15036150953239033\tvalidation accuracy: 0.29935897435897435\tvalidation loss:0.13208319460734344\n",
            "Correct number of outputs in validation: 467\tTotal number of outputs in validation: 1560\tTotal validation loss 206.04978358745575\n",
            "Epoch 109:\n",
            "training accuracy: 0.3249216300940439\ttraining loss: 0.1505140963299521\tvalidation accuracy: 0.2903846153846154\tvalidation loss:0.1413596688172756\n",
            "Correct number of outputs in validation: 453\tTotal number of outputs in validation: 1560\tTotal validation loss 220.52108335494995\n",
            "Epoch 110:\n",
            "training accuracy: 0.33009404388714736\ttraining loss: 0.15076362851271435\tvalidation accuracy: 0.2724358974358974\tvalidation loss:0.15699735505458637\n",
            "Correct number of outputs in validation: 425\tTotal number of outputs in validation: 1560\tTotal validation loss 244.91587388515472\n",
            "Epoch 111:\n",
            "training accuracy: 0.33871473354231973\ttraining loss: 0.15482559429253903\tvalidation accuracy: 0.2724358974358974\tvalidation loss:0.18108442036005168\n",
            "Correct number of outputs in validation: 425\tTotal number of outputs in validation: 1560\tTotal validation loss 282.4916957616806\n",
            "Epoch 112:\n",
            "training accuracy: 0.34529780564263324\ttraining loss: 0.15684145911360237\tvalidation accuracy: 0.2673076923076923\tvalidation loss:0.2110306386764233\n",
            "Correct number of outputs in validation: 417\tTotal number of outputs in validation: 1560\tTotal validation loss 329.20779633522034\n",
            "Epoch 113:\n",
            "training accuracy: 0.3550156739811912\ttraining loss: 0.15900976812951617\tvalidation accuracy: 0.32243589743589746\tvalidation loss:0.21679296600512968\n",
            "Correct number of outputs in validation: 503\tTotal number of outputs in validation: 1560\tTotal validation loss 338.1970269680023\n",
            "Epoch 114:\n",
            "training accuracy: 0.3568965517241379\ttraining loss: 0.1633643236186437\tvalidation accuracy: 0.19038461538461537\tvalidation loss:0.2216605203273969\n",
            "Correct number of outputs in validation: 297\tTotal number of outputs in validation: 1560\tTotal validation loss 345.79041171073914\n",
            "Epoch 115:\n",
            "training accuracy: 0.3730407523510972\ttraining loss: 0.16561094435591683\tvalidation accuracy: 0.27307692307692305\tvalidation loss:0.22170789134808075\n",
            "Correct number of outputs in validation: 426\tTotal number of outputs in validation: 1560\tTotal validation loss 345.864310503006\n",
            "Epoch 116:\n",
            "training accuracy: 0.40188087774294673\ttraining loss: 0.14300442728035875\tvalidation accuracy: 0.26474358974358975\tvalidation loss:0.21397895369774256\n",
            "Correct number of outputs in validation: 413\tTotal number of outputs in validation: 1560\tTotal validation loss 333.8071677684784\n",
            "Epoch 117:\n",
            "training accuracy: 0.44122257053291536\ttraining loss: 0.1362227575345473\tvalidation accuracy: 0.3192307692307692\tvalidation loss:0.18929645526103483\n",
            "Correct number of outputs in validation: 498\tTotal number of outputs in validation: 1560\tTotal validation loss 295.30247020721436\n",
            "Epoch 118:\n",
            "training accuracy: 0.46927899686520375\ttraining loss: 0.1287781887573882\tvalidation accuracy: 0.3416666666666667\tvalidation loss:0.15916654093143268\n",
            "Correct number of outputs in validation: 533\tTotal number of outputs in validation: 1560\tTotal validation loss 248.29980385303497\n",
            "Epoch 119:\n",
            "training accuracy: 0.49043887147335424\ttraining loss: 0.12338036217005649\tvalidation accuracy: 0.38269230769230766\tvalidation loss:0.16232348787478912\n",
            "Correct number of outputs in validation: 597\tTotal number of outputs in validation: 1560\tTotal validation loss 253.22464108467102\n",
            "Epoch 120:\n",
            "training accuracy: 0.44404388714733545\ttraining loss: 0.1453414115038785\tvalidation accuracy: 0.37948717948717947\tvalidation loss:0.18847928177087736\n",
            "Correct number of outputs in validation: 592\tTotal number of outputs in validation: 1560\tTotal validation loss 294.02767956256866\n",
            "Epoch 121:\n",
            "training accuracy: 0.4369905956112853\ttraining loss: 0.13978008213088056\tvalidation accuracy: 0.37948717948717947\tvalidation loss:0.15566726930630512\n",
            "Correct number of outputs in validation: 592\tTotal number of outputs in validation: 1560\tTotal validation loss 242.840940117836\n",
            "Epoch 122:\n",
            "training accuracy: 0.4724137931034483\ttraining loss: 0.12445116920811256\tvalidation accuracy: 0.4307692307692308\tvalidation loss:0.11761152025980827\n",
            "Correct number of outputs in validation: 672\tTotal number of outputs in validation: 1560\tTotal validation loss 183.4739716053009\n",
            "Epoch 123:\n",
            "training accuracy: 0.5059561128526646\ttraining loss: 0.11557345694882742\tvalidation accuracy: 0.44551282051282054\tvalidation loss:0.11223847078971373\n",
            "Correct number of outputs in validation: 695\tTotal number of outputs in validation: 1560\tTotal validation loss 175.09201443195343\n",
            "Epoch 124:\n",
            "training accuracy: 0.4970219435736677\ttraining loss: 0.11238305890541465\tvalidation accuracy: 0.5301282051282051\tvalidation loss:0.11561141675099348\n",
            "Correct number of outputs in validation: 827\tTotal number of outputs in validation: 1560\tTotal validation loss 180.35381013154984\n",
            "Epoch 125:\n",
            "training accuracy: 0.5130094043887148\ttraining loss: 0.11004702426423099\tvalidation accuracy: 0.5551282051282052\tvalidation loss:0.12160832828436142\n",
            "Correct number of outputs in validation: 866\tTotal number of outputs in validation: 1560\tTotal validation loss 189.70899212360382\n",
            "Epoch 126:\n",
            "training accuracy: 0.518025078369906\ttraining loss: 0.10940083780071952\tvalidation accuracy: 0.5583333333333333\tvalidation loss:0.12343558581211628\n",
            "Correct number of outputs in validation: 871\tTotal number of outputs in validation: 1560\tTotal validation loss 192.5595138669014\n",
            "Epoch 127:\n",
            "training accuracy: 0.5352664576802508\ttraining loss: 0.10692463376585593\tvalidation accuracy: 0.5461538461538461\tvalidation loss:0.12404497762521108\n",
            "Correct number of outputs in validation: 852\tTotal number of outputs in validation: 1560\tTotal validation loss 193.51016509532928\n",
            "Epoch 128:\n",
            "training accuracy: 0.5478056426332288\ttraining loss: 0.10349091940725859\tvalidation accuracy: 0.5807692307692308\tvalidation loss:0.11276073027879764\n",
            "Correct number of outputs in validation: 906\tTotal number of outputs in validation: 1560\tTotal validation loss 175.90673923492432\n",
            "Epoch 129:\n",
            "training accuracy: 0.5612852664576803\ttraining loss: 0.10056238024025502\tvalidation accuracy: 0.5794871794871795\tvalidation loss:0.10868437542365147\n",
            "Correct number of outputs in validation: 904\tTotal number of outputs in validation: 1560\tTotal validation loss 169.5476256608963\n",
            "Epoch 130:\n",
            "training accuracy: 0.5622257053291536\ttraining loss: 0.10078405500579403\tvalidation accuracy: 0.5807692307692308\tvalidation loss:0.11073185025881498\n",
            "Correct number of outputs in validation: 906\tTotal number of outputs in validation: 1560\tTotal validation loss 172.74168640375137\n",
            "Epoch 131:\n",
            "training accuracy: 0.5772727272727273\ttraining loss: 0.09868835375693898\tvalidation accuracy: 0.6057692307692307\tvalidation loss:0.10271451599322833\n",
            "Correct number of outputs in validation: 945\tTotal number of outputs in validation: 1560\tTotal validation loss 160.2346449494362\n",
            "Epoch 132:\n",
            "training accuracy: 0.5890282131661442\ttraining loss: 0.0992078488102901\tvalidation accuracy: 0.610897435897436\tvalidation loss:0.10066936936898109\n",
            "Correct number of outputs in validation: 953\tTotal number of outputs in validation: 1560\tTotal validation loss 157.0442162156105\n",
            "Epoch 133:\n",
            "training accuracy: 0.5963949843260188\ttraining loss: 0.10113086624298724\tvalidation accuracy: 0.6288461538461538\tvalidation loss:0.09185559390447079\n",
            "Correct number of outputs in validation: 981\tTotal number of outputs in validation: 1560\tTotal validation loss 143.29472649097443\n",
            "Epoch 134:\n",
            "training accuracy: 0.5846394984326019\ttraining loss: 0.11100032047418218\tvalidation accuracy: 0.6326923076923077\tvalidation loss:0.09281384276273923\n",
            "Correct number of outputs in validation: 987\tTotal number of outputs in validation: 1560\tTotal validation loss 144.7895947098732\n",
            "Epoch 135:\n",
            "training accuracy: 0.5860501567398119\ttraining loss: 0.11354601551839924\tvalidation accuracy: 0.48525641025641025\tvalidation loss:0.15763048644249256\n",
            "Correct number of outputs in validation: 757\tTotal number of outputs in validation: 1560\tTotal validation loss 245.9035588502884\n",
            "Epoch 136:\n",
            "training accuracy: 0.5869905956112853\ttraining loss: 0.10890924976817493\tvalidation accuracy: 0.6397435897435897\tvalidation loss:0.09291548541723153\n",
            "Correct number of outputs in validation: 998\tTotal number of outputs in validation: 1560\tTotal validation loss 144.9481572508812\n",
            "Epoch 137:\n",
            "training accuracy: 0.6105015673981191\ttraining loss: 0.09366020038957507\tvalidation accuracy: 0.6064102564102564\tvalidation loss:0.09164872574500549\n",
            "Correct number of outputs in validation: 946\tTotal number of outputs in validation: 1560\tTotal validation loss 142.97201216220856\n",
            "Epoch 138:\n",
            "training accuracy: 0.6296238244514106\ttraining loss: 0.08877405657383342\tvalidation accuracy: 0.6442307692307693\tvalidation loss:0.08942099412282307\n",
            "Correct number of outputs in validation: 1005\tTotal number of outputs in validation: 1560\tTotal validation loss 139.496750831604\n",
            "Epoch 139:\n",
            "training accuracy: 0.6224137931034482\ttraining loss: 0.0959401866672181\tvalidation accuracy: 0.6294871794871795\tvalidation loss:0.09484526423307565\n",
            "Correct number of outputs in validation: 982\tTotal number of outputs in validation: 1560\tTotal validation loss 147.95861220359802\n",
            "Epoch 140:\n",
            "training accuracy: 0.6081504702194357\ttraining loss: 0.09828989700557296\tvalidation accuracy: 0.625\tvalidation loss:0.09922632586497526\n",
            "Correct number of outputs in validation: 975\tTotal number of outputs in validation: 1560\tTotal validation loss 154.79306834936142\n",
            "Epoch 141:\n",
            "training accuracy: 0.6278996865203762\ttraining loss: 0.09469040077308129\tvalidation accuracy: 0.6711538461538461\tvalidation loss:0.09065114305569576\n",
            "Correct number of outputs in validation: 1047\tTotal number of outputs in validation: 1560\tTotal validation loss 141.41578316688538\n",
            "Epoch 142:\n",
            "training accuracy: 0.653448275862069\ttraining loss: 0.08780621373354454\tvalidation accuracy: 0.7064102564102565\tvalidation loss:0.08289382648773683\n",
            "Correct number of outputs in validation: 1102\tTotal number of outputs in validation: 1560\tTotal validation loss 129.31436932086945\n",
            "Epoch 143:\n",
            "training accuracy: 0.6998432601880877\ttraining loss: 0.07609362872696969\tvalidation accuracy: 0.6782051282051282\tvalidation loss:0.08316062157734846\n",
            "Correct number of outputs in validation: 1058\tTotal number of outputs in validation: 1560\tTotal validation loss 129.7305696606636\n",
            "Epoch 144:\n",
            "training accuracy: 0.7109717868338558\ttraining loss: 0.07454975268870685\tvalidation accuracy: 0.6865384615384615\tvalidation loss:0.08333673389294209\n",
            "Correct number of outputs in validation: 1071\tTotal number of outputs in validation: 1560\tTotal validation loss 130.00530487298965\n",
            "Epoch 145:\n",
            "training accuracy: 0.713166144200627\ttraining loss: 0.07428743381485296\tvalidation accuracy: 0.6775641025641026\tvalidation loss:0.08615697423617046\n",
            "Correct number of outputs in validation: 1057\tTotal number of outputs in validation: 1560\tTotal validation loss 134.4048798084259\n",
            "Epoch 146:\n",
            "training accuracy: 0.7235109717868339\ttraining loss: 0.07296867055298767\tvalidation accuracy: 0.6871794871794872\tvalidation loss:0.08322656032366631\n",
            "Correct number of outputs in validation: 1072\tTotal number of outputs in validation: 1560\tTotal validation loss 129.83343410491943\n",
            "Epoch 147:\n",
            "training accuracy: 0.7249216300940439\ttraining loss: 0.07200551676012132\tvalidation accuracy: 0.7166666666666667\tvalidation loss:0.07988503659382845\n",
            "Correct number of outputs in validation: 1118\tTotal number of outputs in validation: 1560\tTotal validation loss 124.62065708637238\n",
            "Epoch 148:\n",
            "training accuracy: 0.733385579937304\ttraining loss: 0.070691293886743\tvalidation accuracy: 0.7282051282051282\tvalidation loss:0.0777407073439696\n",
            "Correct number of outputs in validation: 1136\tTotal number of outputs in validation: 1560\tTotal validation loss 121.27550345659256\n",
            "Epoch 149:\n",
            "training accuracy: 0.7449843260188088\ttraining loss: 0.06919563459144865\tvalidation accuracy: 0.7269230769230769\tvalidation loss:0.07799118440120648\n",
            "Correct number of outputs in validation: 1134\tTotal number of outputs in validation: 1560\tTotal validation loss 121.66624766588211\n",
            "Epoch 150:\n",
            "training accuracy: 0.7437304075235109\ttraining loss: 0.06916567762163366\tvalidation accuracy: 0.7198717948717949\tvalidation loss:0.07826164231086388\n",
            "Correct number of outputs in validation: 1123\tTotal number of outputs in validation: 1560\tTotal validation loss 122.08816200494766\n",
            "Epoch 151:\n",
            "training accuracy: 0.7515673981191222\ttraining loss: 0.0676612150916672\tvalidation accuracy: 0.7307692307692307\tvalidation loss:0.07486676287192565\n",
            "Correct number of outputs in validation: 1140\tTotal number of outputs in validation: 1560\tTotal validation loss 116.79215008020401\n",
            "Epoch 152:\n",
            "training accuracy: 0.7667711598746082\ttraining loss: 0.06591646593285952\tvalidation accuracy: 0.7519230769230769\tvalidation loss:0.07000543543925652\n",
            "Correct number of outputs in validation: 1173\tTotal number of outputs in validation: 1560\tTotal validation loss 109.20847928524017\n",
            "Epoch 153:\n",
            "training accuracy: 0.7652037617554859\ttraining loss: 0.06559024440784439\tvalidation accuracy: 0.7493589743589744\tvalidation loss:0.07245294692424628\n",
            "Correct number of outputs in validation: 1169\tTotal number of outputs in validation: 1560\tTotal validation loss 113.02659720182419\n",
            "Epoch 154:\n",
            "training accuracy: 0.7713166144200627\ttraining loss: 0.0679199317499388\tvalidation accuracy: 0.7634615384615384\tvalidation loss:0.07268095975502943\n",
            "Correct number of outputs in validation: 1191\tTotal number of outputs in validation: 1560\tTotal validation loss 113.38229721784592\n",
            "Epoch 155:\n",
            "training accuracy: 0.7623824451410658\ttraining loss: 0.07058617730732995\tvalidation accuracy: 0.725\tvalidation loss:0.08381753789308743\n",
            "Correct number of outputs in validation: 1131\tTotal number of outputs in validation: 1560\tTotal validation loss 130.7553591132164\n",
            "Epoch 156:\n",
            "training accuracy: 0.7705329153605016\ttraining loss: 0.06851865205224779\tvalidation accuracy: 0.7121794871794872\tvalidation loss:0.0853519198222038\n",
            "Correct number of outputs in validation: 1111\tTotal number of outputs in validation: 1560\tTotal validation loss 133.14899492263794\n",
            "Epoch 157:\n",
            "training accuracy: 0.7907523510971787\ttraining loss: 0.06371637640234819\tvalidation accuracy: 0.7275641025641025\tvalidation loss:0.0781227816755955\n",
            "Correct number of outputs in validation: 1135\tTotal number of outputs in validation: 1560\tTotal validation loss 121.87153941392899\n",
            "Epoch 158:\n",
            "training accuracy: 0.8042319749216301\ttraining loss: 0.06043932399359243\tvalidation accuracy: 0.7365384615384616\tvalidation loss:0.07941371447000749\n",
            "Correct number of outputs in validation: 1149\tTotal number of outputs in validation: 1560\tTotal validation loss 123.88539457321167\n",
            "Epoch 159:\n",
            "training accuracy: 0.7976489028213166\ttraining loss: 0.06223224796191278\tvalidation accuracy: 0.6961538461538461\tvalidation loss:0.08716881301922676\n",
            "Correct number of outputs in validation: 1086\tTotal number of outputs in validation: 1560\tTotal validation loss 135.98334830999374\n",
            "Epoch 160:\n",
            "training accuracy: 0.7968652037617555\ttraining loss: 0.06354332885071402\tvalidation accuracy: 0.7012820512820512\tvalidation loss:0.08767262345705278\n",
            "Correct number of outputs in validation: 1094\tTotal number of outputs in validation: 1560\tTotal validation loss 136.76929259300232\n",
            "Epoch 161:\n",
            "training accuracy: 0.7962382445141066\ttraining loss: 0.06317796342331787\tvalidation accuracy: 0.7346153846153847\tvalidation loss:0.08379883418480555\n",
            "Correct number of outputs in validation: 1146\tTotal number of outputs in validation: 1560\tTotal validation loss 130.72618132829666\n",
            "Epoch 162:\n",
            "training accuracy: 0.7910658307210031\ttraining loss: 0.06432686135126132\tvalidation accuracy: 0.75\tvalidation loss:0.08126918383133717\n",
            "Correct number of outputs in validation: 1170\tTotal number of outputs in validation: 1560\tTotal validation loss 126.77992677688599\n",
            "Epoch 163:\n",
            "training accuracy: 0.7865203761755486\ttraining loss: 0.06840549026583803\tvalidation accuracy: 0.6724358974358975\tvalidation loss:0.08953278316901281\n",
            "Correct number of outputs in validation: 1049\tTotal number of outputs in validation: 1560\tTotal validation loss 139.67114174365997\n",
            "Epoch 164:\n",
            "training accuracy: 0.779153605015674\ttraining loss: 0.07015647394436654\tvalidation accuracy: 0.7852564102564102\tvalidation loss:0.06686914952901693\n",
            "Correct number of outputs in validation: 1225\tTotal number of outputs in validation: 1560\tTotal validation loss 104.31587326526642\n",
            "Epoch 165:\n",
            "training accuracy: 0.8133228840125392\ttraining loss: 0.06086424888815252\tvalidation accuracy: 0.7916666666666666\tvalidation loss:0.058983716674340075\n",
            "Correct number of outputs in validation: 1235\tTotal number of outputs in validation: 1560\tTotal validation loss 92.01459801197052\n",
            "Epoch 166:\n",
            "training accuracy: 0.7959247648902821\ttraining loss: 0.060938770942927156\tvalidation accuracy: 0.75\tvalidation loss:0.06650688147697693\n",
            "Correct number of outputs in validation: 1170\tTotal number of outputs in validation: 1560\tTotal validation loss 103.75073510408401\n",
            "Epoch 167:\n",
            "training accuracy: 0.793730407523511\ttraining loss: 0.060544679820724416\tvalidation accuracy: 0.7878205128205128\tvalidation loss:0.06296498615008134\n",
            "Correct number of outputs in validation: 1229\tTotal number of outputs in validation: 1560\tTotal validation loss 98.22537839412689\n",
            "Epoch 168:\n",
            "training accuracy: 0.809717868338558\ttraining loss: 0.05707480397344009\tvalidation accuracy: 0.7929487179487179\tvalidation loss:0.06642442280665423\n",
            "Correct number of outputs in validation: 1237\tTotal number of outputs in validation: 1560\tTotal validation loss 103.62209957838058\n",
            "Epoch 169:\n",
            "training accuracy: 0.8192789968652038\ttraining loss: 0.05597640564869564\tvalidation accuracy: 0.775\tvalidation loss:0.0707446440290182\n",
            "Correct number of outputs in validation: 1209\tTotal number of outputs in validation: 1560\tTotal validation loss 110.3616446852684\n",
            "Epoch 170:\n",
            "training accuracy: 0.8214733542319749\ttraining loss: 0.05517121904929603\tvalidation accuracy: 0.7711538461538462\tvalidation loss:0.07035708519128653\n",
            "Correct number of outputs in validation: 1203\tTotal number of outputs in validation: 1560\tTotal validation loss 109.75705289840698\n",
            "Epoch 171:\n",
            "training accuracy: 0.8216300940438871\ttraining loss: 0.05629620827430842\tvalidation accuracy: 0.7891025641025641\tvalidation loss:0.05911580824699157\n",
            "Correct number of outputs in validation: 1231\tTotal number of outputs in validation: 1560\tTotal validation loss 92.22066086530685\n",
            "Epoch 172:\n",
            "training accuracy: 0.8177115987460815\ttraining loss: 0.05812273702137523\tvalidation accuracy: 0.7769230769230769\tvalidation loss:0.06661312010807868\n",
            "Correct number of outputs in validation: 1212\tTotal number of outputs in validation: 1560\tTotal validation loss 103.91646736860275\n",
            "Epoch 173:\n",
            "training accuracy: 0.829153605015674\ttraining loss: 0.05187496684234718\tvalidation accuracy: 0.7858974358974359\tvalidation loss:0.059170666795510515\n",
            "Correct number of outputs in validation: 1226\tTotal number of outputs in validation: 1560\tTotal validation loss 92.3062402009964\n",
            "Epoch 174:\n",
            "training accuracy: 0.8360501567398119\ttraining loss: 0.04975475817218096\tvalidation accuracy: 0.7903846153846154\tvalidation loss:0.05957914300453968\n",
            "Correct number of outputs in validation: 1233\tTotal number of outputs in validation: 1560\tTotal validation loss 92.94346308708191\n",
            "Epoch 175:\n",
            "training accuracy: 0.837460815047022\ttraining loss: 0.04852740975055949\tvalidation accuracy: 0.7967948717948717\tvalidation loss:0.057539479587322626\n",
            "Correct number of outputs in validation: 1243\tTotal number of outputs in validation: 1560\tTotal validation loss 89.7615881562233\n",
            "Epoch 176:\n",
            "training accuracy: 0.8412225705329154\ttraining loss: 0.0471936489721077\tvalidation accuracy: 0.7961538461538461\tvalidation loss:0.05587575458563291\n",
            "Correct number of outputs in validation: 1242\tTotal number of outputs in validation: 1560\tTotal validation loss 87.16617715358734\n",
            "Epoch 177:\n",
            "training accuracy: 0.8492163009404389\ttraining loss: 0.04549189266693256\tvalidation accuracy: 0.8\tvalidation loss:0.05610196372637382\n",
            "Correct number of outputs in validation: 1248\tTotal number of outputs in validation: 1560\tTotal validation loss 87.51906341314316\n",
            "Epoch 178:\n",
            "training accuracy: 0.8531347962382445\ttraining loss: 0.044758829240888635\tvalidation accuracy: 0.8044871794871795\tvalidation loss:0.056074423362047245\n",
            "Correct number of outputs in validation: 1255\tTotal number of outputs in validation: 1560\tTotal validation loss 87.4761004447937\n",
            "Epoch 179:\n",
            "training accuracy: 0.8526645768025078\ttraining loss: 0.04398105041500543\tvalidation accuracy: 0.7897435897435897\tvalidation loss:0.05785168703549948\n",
            "Correct number of outputs in validation: 1232\tTotal number of outputs in validation: 1560\tTotal validation loss 90.24863177537918\n",
            "Epoch 180:\n",
            "training accuracy: 0.8572100313479624\ttraining loss: 0.042920925561630616\tvalidation accuracy: 0.7993589743589744\tvalidation loss:0.056886114065463726\n",
            "Correct number of outputs in validation: 1247\tTotal number of outputs in validation: 1560\tTotal validation loss 88.74233794212341\n",
            "Epoch 181:\n",
            "training accuracy: 0.8586206896551725\ttraining loss: 0.042671661583420624\tvalidation accuracy: 0.8032051282051282\tvalidation loss:0.05790561170150072\n",
            "Correct number of outputs in validation: 1253\tTotal number of outputs in validation: 1560\tTotal validation loss 90.33275425434113\n",
            "Epoch 182:\n",
            "training accuracy: 0.8628526645768025\ttraining loss: 0.04237679334409932\tvalidation accuracy: 0.8\tvalidation loss:0.058712780322784035\n",
            "Correct number of outputs in validation: 1248\tTotal number of outputs in validation: 1560\tTotal validation loss 91.59193730354309\n",
            "Epoch 183:\n",
            "training accuracy: 0.8622257053291537\ttraining loss: 0.042796331924330855\tvalidation accuracy: 0.816025641025641\tvalidation loss:0.058649958975804155\n",
            "Correct number of outputs in validation: 1273\tTotal number of outputs in validation: 1560\tTotal validation loss 91.49393600225449\n",
            "Epoch 184:\n",
            "training accuracy: 0.8603448275862069\ttraining loss: 0.04403609008904909\tvalidation accuracy: 0.8006410256410257\tvalidation loss:0.06153309303216445\n",
            "Correct number of outputs in validation: 1249\tTotal number of outputs in validation: 1560\tTotal validation loss 95.99162513017654\n",
            "Epoch 185:\n",
            "training accuracy: 0.8706896551724138\ttraining loss: 0.0422459602332601\tvalidation accuracy: 0.7897435897435897\tvalidation loss:0.0601313183705012\n",
            "Correct number of outputs in validation: 1232\tTotal number of outputs in validation: 1560\tTotal validation loss 93.80485665798187\n",
            "Epoch 186:\n",
            "training accuracy: 0.8697492163009405\ttraining loss: 0.04175586161848893\tvalidation accuracy: 0.8070512820512821\tvalidation loss:0.05803310359135652\n",
            "Correct number of outputs in validation: 1259\tTotal number of outputs in validation: 1560\tTotal validation loss 90.53164160251617\n",
            "Epoch 187:\n",
            "training accuracy: 0.8713166144200627\ttraining loss: 0.04152005340752183\tvalidation accuracy: 0.8\tvalidation loss:0.05816024339351899\n",
            "Correct number of outputs in validation: 1248\tTotal number of outputs in validation: 1560\tTotal validation loss 90.72997969388962\n",
            "Epoch 188:\n",
            "training accuracy: 0.874294670846395\ttraining loss: 0.03981084794646894\tvalidation accuracy: 0.801923076923077\tvalidation loss:0.056753332836505695\n",
            "Correct number of outputs in validation: 1251\tTotal number of outputs in validation: 1560\tTotal validation loss 88.53519922494888\n",
            "Epoch 189:\n",
            "training accuracy: 0.8799373040752351\ttraining loss: 0.03874079515124003\tvalidation accuracy: 0.8070512820512821\tvalidation loss:0.05604091775722993\n",
            "Correct number of outputs in validation: 1259\tTotal number of outputs in validation: 1560\tTotal validation loss 87.42383170127869\n",
            "Epoch 190:\n",
            "training accuracy: 0.8706896551724138\ttraining loss: 0.04163886439931056\tvalidation accuracy: 0.7916666666666666\tvalidation loss:0.059339895385962266\n",
            "Correct number of outputs in validation: 1235\tTotal number of outputs in validation: 1560\tTotal validation loss 92.57023680210114\n",
            "Epoch 191:\n",
            "training accuracy: 0.8764890282131661\ttraining loss: 0.03985164992301068\tvalidation accuracy: 0.8012820512820513\tvalidation loss:0.05589792350163827\n",
            "Correct number of outputs in validation: 1250\tTotal number of outputs in validation: 1560\tTotal validation loss 87.2007606625557\n",
            "Epoch 192:\n",
            "training accuracy: 0.883385579937304\ttraining loss: 0.03767804960051674\tvalidation accuracy: 0.7897435897435897\tvalidation loss:0.05575327708935126\n",
            "Correct number of outputs in validation: 1232\tTotal number of outputs in validation: 1560\tTotal validation loss 86.97511225938797\n",
            "Epoch 193:\n",
            "training accuracy: 0.8827586206896552\ttraining loss: 0.03761898324384024\tvalidation accuracy: 0.8032051282051282\tvalidation loss:0.05641282521761381\n",
            "Correct number of outputs in validation: 1253\tTotal number of outputs in validation: 1560\tTotal validation loss 88.00400733947754\n",
            "Epoch 194:\n",
            "training accuracy: 0.8896551724137931\ttraining loss: 0.03704740288769563\tvalidation accuracy: 0.8076923076923077\tvalidation loss:0.05623493916713274\n",
            "Correct number of outputs in validation: 1260\tTotal number of outputs in validation: 1560\tTotal validation loss 87.72650510072708\n",
            "Epoch 195:\n",
            "training accuracy: 0.886833855799373\ttraining loss: 0.03654713410428699\tvalidation accuracy: 0.7993589743589744\tvalidation loss:0.05782518570239727\n",
            "Correct number of outputs in validation: 1247\tTotal number of outputs in validation: 1560\tTotal validation loss 90.20728969573975\n",
            "Epoch 196:\n",
            "training accuracy: 0.8860501567398119\ttraining loss: 0.03730153901193022\tvalidation accuracy: 0.7935897435897435\tvalidation loss:0.05974875317934232\n",
            "Correct number of outputs in validation: 1238\tTotal number of outputs in validation: 1560\tTotal validation loss 93.20805495977402\n",
            "Epoch 197:\n",
            "training accuracy: 0.885423197492163\ttraining loss: 0.038161392173610136\tvalidation accuracy: 0.791025641025641\tvalidation loss:0.05996967278994047\n",
            "Correct number of outputs in validation: 1234\tTotal number of outputs in validation: 1560\tTotal validation loss 93.55268955230713\n",
            "Epoch 198:\n",
            "training accuracy: 0.8835423197492163\ttraining loss: 0.038170730711477675\tvalidation accuracy: 0.7961538461538461\tvalidation loss:0.058042220924145134\n",
            "Correct number of outputs in validation: 1242\tTotal number of outputs in validation: 1560\tTotal validation loss 90.54586464166641\n",
            "Epoch 199:\n",
            "training accuracy: 0.8858934169278997\ttraining loss: 0.03733644611713094\tvalidation accuracy: 0.8012820512820513\tvalidation loss:0.05776200986061341\n",
            "Correct number of outputs in validation: 1250\tTotal number of outputs in validation: 1560\tTotal validation loss 90.10873538255692\n",
            "Epoch 200:\n",
            "training accuracy: 0.8940438871473354\ttraining loss: 0.03525091880074115\tvalidation accuracy: 0.8\tvalidation loss:0.056275673287037094\n",
            "Correct number of outputs in validation: 1248\tTotal number of outputs in validation: 1560\tTotal validation loss 87.79005032777786\n",
            "Epoch 201:\n",
            "training accuracy: 0.893730407523511\ttraining loss: 0.03482550416830752\tvalidation accuracy: 0.7923076923076923\tvalidation loss:0.05857624426866189\n",
            "Correct number of outputs in validation: 1236\tTotal number of outputs in validation: 1560\tTotal validation loss 91.37894105911255\n",
            "Epoch 202:\n",
            "training accuracy: 0.8896551724137931\ttraining loss: 0.036210083841203146\tvalidation accuracy: 0.8025641025641026\tvalidation loss:0.05579716845964774\n",
            "Correct number of outputs in validation: 1252\tTotal number of outputs in validation: 1560\tTotal validation loss 87.04358279705048\n",
            "Epoch 203:\n",
            "training accuracy: 0.8960815047021944\ttraining loss: 0.034247034275466375\tvalidation accuracy: 0.8076923076923077\tvalidation loss:0.05391750393005518\n",
            "Correct number of outputs in validation: 1260\tTotal number of outputs in validation: 1560\tTotal validation loss 84.11130613088608\n",
            "Epoch 204:\n",
            "training accuracy: 0.8948275862068965\ttraining loss: 0.03353835032628061\tvalidation accuracy: 0.8070512820512821\tvalidation loss:0.05440459427161094\n",
            "Correct number of outputs in validation: 1259\tTotal number of outputs in validation: 1560\tTotal validation loss 84.87116706371307\n",
            "Epoch 205:\n",
            "training accuracy: 0.8992163009404389\ttraining loss: 0.03345500828470556\tvalidation accuracy: 0.8038461538461539\tvalidation loss:0.05423021308886699\n",
            "Correct number of outputs in validation: 1254\tTotal number of outputs in validation: 1560\tTotal validation loss 84.59913241863251\n",
            "Epoch 206:\n",
            "training accuracy: 0.8974921630094044\ttraining loss: 0.03378432019026863\tvalidation accuracy: 0.8096153846153846\tvalidation loss:0.0546079603716349\n",
            "Correct number of outputs in validation: 1263\tTotal number of outputs in validation: 1560\tTotal validation loss 85.18841817975044\n",
            "Epoch 207:\n",
            "training accuracy: 0.8962382445141066\ttraining loss: 0.03481231780845356\tvalidation accuracy: 0.8012820512820513\tvalidation loss:0.05537165269637719\n",
            "Correct number of outputs in validation: 1250\tTotal number of outputs in validation: 1560\tTotal validation loss 86.37977820634842\n",
            "Epoch 208:\n",
            "training accuracy: 0.9006269592476489\ttraining loss: 0.03226548255914618\tvalidation accuracy: 0.7987179487179488\tvalidation loss:0.05408858630137566\n",
            "Correct number of outputs in validation: 1246\tTotal number of outputs in validation: 1560\tTotal validation loss 84.37819463014603\n",
            "Epoch 209:\n",
            "training accuracy: 0.8990595611285267\ttraining loss: 0.03238413924450598\tvalidation accuracy: 0.8147435897435897\tvalidation loss:0.05107851299719933\n",
            "Correct number of outputs in validation: 1271\tTotal number of outputs in validation: 1560\tTotal validation loss 79.68248027563095\n",
            "Epoch 210:\n",
            "training accuracy: 0.9026645768025079\ttraining loss: 0.03161670037408047\tvalidation accuracy: 0.8083333333333333\tvalidation loss:0.05466984653702149\n",
            "Correct number of outputs in validation: 1261\tTotal number of outputs in validation: 1560\tTotal validation loss 85.28496059775352\n",
            "Epoch 211:\n",
            "training accuracy: 0.9032915360501568\ttraining loss: 0.03101525957167709\tvalidation accuracy: 0.8141025641025641\tvalidation loss:0.054998451203872\n",
            "Correct number of outputs in validation: 1270\tTotal number of outputs in validation: 1560\tTotal validation loss 85.79758387804031\n",
            "Epoch 212:\n",
            "training accuracy: 0.9105015673981192\ttraining loss: 0.030327337882174968\tvalidation accuracy: 0.8102564102564103\tvalidation loss:0.05734543490868348\n",
            "Correct number of outputs in validation: 1264\tTotal number of outputs in validation: 1560\tTotal validation loss 89.45887845754623\n",
            "Epoch 213:\n",
            "training accuracy: 0.9021943573667711\ttraining loss: 0.03167050061951797\tvalidation accuracy: 0.8083333333333333\tvalidation loss:0.05710684886345496\n",
            "Correct number of outputs in validation: 1261\tTotal number of outputs in validation: 1560\tTotal validation loss 89.08668422698975\n",
            "Epoch 214:\n",
            "training accuracy: 0.9056426332288401\ttraining loss: 0.03150829506985446\tvalidation accuracy: 0.816025641025641\tvalidation loss:0.05623771227323092\n",
            "Correct number of outputs in validation: 1273\tTotal number of outputs in validation: 1560\tTotal validation loss 87.73083114624023\n",
            "Epoch 215:\n",
            "training accuracy: 0.9051724137931034\ttraining loss: 0.031709552983692074\tvalidation accuracy: 0.8064102564102564\tvalidation loss:0.05583525928549277\n",
            "Correct number of outputs in validation: 1258\tTotal number of outputs in validation: 1560\tTotal validation loss 87.10300448536873\n",
            "Epoch 216:\n",
            "training accuracy: 0.9050156739811912\ttraining loss: 0.03223761703270169\tvalidation accuracy: 0.7961538461538461\tvalidation loss:0.05656569689894334\n",
            "Correct number of outputs in validation: 1242\tTotal number of outputs in validation: 1560\tTotal validation loss 88.24248716235161\n",
            "Epoch 217:\n",
            "training accuracy: 0.9028213166144201\ttraining loss: 0.03146104867508793\tvalidation accuracy: 0.8051282051282052\tvalidation loss:0.05892956470831846\n",
            "Correct number of outputs in validation: 1256\tTotal number of outputs in validation: 1560\tTotal validation loss 91.9301209449768\n",
            "Epoch 218:\n",
            "training accuracy: 0.9023510971786833\ttraining loss: 0.03413116092265213\tvalidation accuracy: 0.8044871794871795\tvalidation loss:0.058115196992189457\n",
            "Correct number of outputs in validation: 1255\tTotal number of outputs in validation: 1560\tTotal validation loss 90.65970730781555\n",
            "Epoch 219:\n",
            "training accuracy: 0.904858934169279\ttraining loss: 0.03284582779115083\tvalidation accuracy: 0.8192307692307692\tvalidation loss:0.054313769325231895\n",
            "Correct number of outputs in validation: 1278\tTotal number of outputs in validation: 1560\tTotal validation loss 84.72948014736176\n",
            "Epoch 220:\n",
            "training accuracy: 0.90141065830721\ttraining loss: 0.03331950766305938\tvalidation accuracy: 0.8217948717948718\tvalidation loss:0.05493723830351463\n",
            "Correct number of outputs in validation: 1282\tTotal number of outputs in validation: 1560\tTotal validation loss 85.70209175348282\n",
            "Epoch 221:\n",
            "training accuracy: 0.8995297805642634\ttraining loss: 0.03522798907840887\tvalidation accuracy: 0.7987179487179488\tvalidation loss:0.056619730438941564\n",
            "Correct number of outputs in validation: 1246\tTotal number of outputs in validation: 1560\tTotal validation loss 88.32677948474884\n",
            "Epoch 222:\n",
            "training accuracy: 0.9010971786833856\ttraining loss: 0.033235822790842445\tvalidation accuracy: 0.8006410256410257\tvalidation loss:0.058203833340070184\n",
            "Correct number of outputs in validation: 1249\tTotal number of outputs in validation: 1560\tTotal validation loss 90.79798001050949\n",
            "Epoch 223:\n",
            "training accuracy: 0.9042319749216301\ttraining loss: 0.03221334561028264\tvalidation accuracy: 0.791025641025641\tvalidation loss:0.05522233855265837\n",
            "Correct number of outputs in validation: 1234\tTotal number of outputs in validation: 1560\tTotal validation loss 86.14684814214706\n",
            "Epoch 224:\n",
            "training accuracy: 0.9045454545454545\ttraining loss: 0.03224454912412503\tvalidation accuracy: 0.7948717948717948\tvalidation loss:0.0554923211534818\n",
            "Correct number of outputs in validation: 1240\tTotal number of outputs in validation: 1560\tTotal validation loss 86.56802099943161\n",
            "Epoch 225:\n",
            "training accuracy: 0.9065830721003135\ttraining loss: 0.031868397797163\tvalidation accuracy: 0.8032051282051282\tvalidation loss:0.05497277661775931\n",
            "Correct number of outputs in validation: 1253\tTotal number of outputs in validation: 1560\tTotal validation loss 85.75753152370453\n",
            "Epoch 226:\n",
            "training accuracy: 0.9112852664576803\ttraining loss: 0.030595551647222528\tvalidation accuracy: 0.8256410256410256\tvalidation loss:0.05078856597344081\n",
            "Correct number of outputs in validation: 1288\tTotal number of outputs in validation: 1560\tTotal validation loss 79.23016291856766\n",
            "Epoch 227:\n",
            "training accuracy: 0.9122257053291536\ttraining loss: 0.03039485617397721\tvalidation accuracy: 0.8038461538461539\tvalidation loss:0.05396569768587748\n",
            "Correct number of outputs in validation: 1254\tTotal number of outputs in validation: 1560\tTotal validation loss 84.18648838996887\n",
            "Epoch 228:\n",
            "training accuracy: 0.9172413793103448\ttraining loss: 0.029071954237209593\tvalidation accuracy: 0.8173076923076923\tvalidation loss:0.051537530850141476\n",
            "Correct number of outputs in validation: 1275\tTotal number of outputs in validation: 1560\tTotal validation loss 80.3985481262207\n",
            "Epoch 229:\n",
            "training accuracy: 0.9181818181818182\ttraining loss: 0.028471703110350337\tvalidation accuracy: 0.8108974358974359\tvalidation loss:0.051055558369709896\n",
            "Correct number of outputs in validation: 1265\tTotal number of outputs in validation: 1560\tTotal validation loss 79.64667105674744\n",
            "Epoch 230:\n",
            "training accuracy: 0.9233542319749216\ttraining loss: 0.027203105011703827\tvalidation accuracy: 0.8108974358974359\tvalidation loss:0.054075827048375054\n",
            "Correct number of outputs in validation: 1265\tTotal number of outputs in validation: 1560\tTotal validation loss 84.35829019546509\n",
            "Epoch 231:\n",
            "training accuracy: 0.9233542319749216\ttraining loss: 0.027787934764519007\tvalidation accuracy: 0.808974358974359\tvalidation loss:0.05290914720449692\n",
            "Correct number of outputs in validation: 1262\tTotal number of outputs in validation: 1560\tTotal validation loss 82.5382696390152\n",
            "Epoch 232:\n",
            "training accuracy: 0.9197492163009404\ttraining loss: 0.02795370352515793\tvalidation accuracy: 0.8108974358974359\tvalidation loss:0.05253683187258549\n",
            "Correct number of outputs in validation: 1265\tTotal number of outputs in validation: 1560\tTotal validation loss 81.95745772123337\n",
            "Epoch 233:\n",
            "training accuracy: 0.9241379310344827\ttraining loss: 0.026410596498921746\tvalidation accuracy: 0.8128205128205128\tvalidation loss:0.050405432474918854\n",
            "Correct number of outputs in validation: 1268\tTotal number of outputs in validation: 1560\tTotal validation loss 78.63247466087341\n",
            "Epoch 234:\n",
            "training accuracy: 0.9239811912225705\ttraining loss: 0.026986381409216824\tvalidation accuracy: 0.8044871794871795\tvalidation loss:0.0530020330960934\n",
            "Correct number of outputs in validation: 1255\tTotal number of outputs in validation: 1560\tTotal validation loss 82.6831716299057\n",
            "Epoch 235:\n",
            "training accuracy: 0.9217868338557994\ttraining loss: 0.0277639342828137\tvalidation accuracy: 0.8044871794871795\tvalidation loss:0.05155454117518205\n",
            "Correct number of outputs in validation: 1255\tTotal number of outputs in validation: 1560\tTotal validation loss 80.425084233284\n",
            "Epoch 236:\n",
            "training accuracy: 0.9219435736677116\ttraining loss: 0.028332012944320525\tvalidation accuracy: 0.8115384615384615\tvalidation loss:0.05103199145732782\n",
            "Correct number of outputs in validation: 1266\tTotal number of outputs in validation: 1560\tTotal validation loss 79.6099066734314\n",
            "Epoch 237:\n",
            "training accuracy: 0.9241379310344827\ttraining loss: 0.026656967692287363\tvalidation accuracy: 0.8211538461538461\tvalidation loss:0.047690998972990575\n",
            "Correct number of outputs in validation: 1281\tTotal number of outputs in validation: 1560\tTotal validation loss 74.3979583978653\n",
            "Epoch 238:\n",
            "training accuracy: 0.9258620689655173\ttraining loss: 0.02647464825979034\tvalidation accuracy: 0.823076923076923\tvalidation loss:0.04706548914695397\n",
            "Correct number of outputs in validation: 1284\tTotal number of outputs in validation: 1560\tTotal validation loss 73.4221630692482\n",
            "Epoch 239:\n",
            "training accuracy: 0.9210031347962383\ttraining loss: 0.027830116080593166\tvalidation accuracy: 0.8211538461538461\tvalidation loss:0.050435172556302484\n",
            "Correct number of outputs in validation: 1281\tTotal number of outputs in validation: 1560\tTotal validation loss 78.67886918783188\n",
            "Epoch 240:\n",
            "training accuracy: 0.9249216300940439\ttraining loss: 0.027253925551581532\tvalidation accuracy: 0.8128205128205128\tvalidation loss:0.0496095115557695\n",
            "Correct number of outputs in validation: 1268\tTotal number of outputs in validation: 1560\tTotal validation loss 77.39083802700043\n",
            "Epoch 241:\n",
            "training accuracy: 0.9264890282131661\ttraining loss: 0.02716404743913012\tvalidation accuracy: 0.8083333333333333\tvalidation loss:0.049450526061730504\n",
            "Correct number of outputs in validation: 1261\tTotal number of outputs in validation: 1560\tTotal validation loss 77.14282065629959\n",
            "Epoch 242:\n",
            "training accuracy: 0.9278996865203761\ttraining loss: 0.02662396273199107\tvalidation accuracy: 0.8006410256410257\tvalidation loss:0.05567524543939493\n",
            "Correct number of outputs in validation: 1249\tTotal number of outputs in validation: 1560\tTotal validation loss 86.85338288545609\n",
            "Epoch 243:\n",
            "training accuracy: 0.9252351097178684\ttraining loss: 0.02756112962961197\tvalidation accuracy: 0.8064102564102564\tvalidation loss:0.050101509193579356\n",
            "Correct number of outputs in validation: 1258\tTotal number of outputs in validation: 1560\tTotal validation loss 78.1583543419838\n",
            "Epoch 244:\n",
            "training accuracy: 0.9293103448275862\ttraining loss: 0.025113405685486465\tvalidation accuracy: 0.8185897435897436\tvalidation loss:0.050555747976669896\n",
            "Correct number of outputs in validation: 1277\tTotal number of outputs in validation: 1560\tTotal validation loss 78.86696684360504\n",
            "Epoch 245:\n",
            "training accuracy: 0.9297805642633229\ttraining loss: 0.025620390182845645\tvalidation accuracy: 0.8147435897435897\tvalidation loss:0.05170897367673043\n",
            "Correct number of outputs in validation: 1271\tTotal number of outputs in validation: 1560\tTotal validation loss 80.66599893569946\n",
            "Epoch 246:\n",
            "training accuracy: 0.9268025078369906\ttraining loss: 0.027483247353645702\tvalidation accuracy: 0.8006410256410257\tvalidation loss:0.04970222784158511\n",
            "Correct number of outputs in validation: 1249\tTotal number of outputs in validation: 1560\tTotal validation loss 77.53547543287277\n",
            "Epoch 247:\n",
            "training accuracy: 0.9300940438871473\ttraining loss: 0.02507245282768082\tvalidation accuracy: 0.8179487179487179\tvalidation loss:0.05010338265162248\n",
            "Correct number of outputs in validation: 1276\tTotal number of outputs in validation: 1560\tTotal validation loss 78.16127693653107\n",
            "Epoch 248:\n",
            "training accuracy: 0.9299373040752351\ttraining loss: 0.025453662715828905\tvalidation accuracy: 0.8217948717948718\tvalidation loss:0.05071804454693427\n",
            "Correct number of outputs in validation: 1282\tTotal number of outputs in validation: 1560\tTotal validation loss 79.12014949321747\n",
            "Epoch 249:\n",
            "training accuracy: 0.9264890282131661\ttraining loss: 0.026856180725379798\tvalidation accuracy: 0.7929487179487179\tvalidation loss:0.052907319175891386\n",
            "Correct number of outputs in validation: 1237\tTotal number of outputs in validation: 1560\tTotal validation loss 82.53541791439056\n",
            "Epoch 250:\n",
            "training accuracy: 0.9277429467084639\ttraining loss: 0.02602493227065357\tvalidation accuracy: 0.8166666666666667\tvalidation loss:0.0521521575939961\n",
            "Correct number of outputs in validation: 1274\tTotal number of outputs in validation: 1560\tTotal validation loss 81.35736584663391\n",
            "Epoch 251:\n",
            "training accuracy: 0.9316614420062695\ttraining loss: 0.02532161039104656\tvalidation accuracy: 0.8070512820512821\tvalidation loss:0.054706821991847114\n",
            "Correct number of outputs in validation: 1259\tTotal number of outputs in validation: 1560\tTotal validation loss 85.3426423072815\n",
            "Epoch 252:\n",
            "training accuracy: 0.9304075235109718\ttraining loss: 0.025665918278703494\tvalidation accuracy: 0.8198717948717948\tvalidation loss:0.05098968942960103\n",
            "Correct number of outputs in validation: 1279\tTotal number of outputs in validation: 1560\tTotal validation loss 79.54391551017761\n",
            "Epoch 253:\n",
            "training accuracy: 0.9333855799373041\ttraining loss: 0.023938858649200034\tvalidation accuracy: 0.8108974358974359\tvalidation loss:0.04962621587209212\n",
            "Correct number of outputs in validation: 1265\tTotal number of outputs in validation: 1560\tTotal validation loss 77.41689676046371\n",
            "Epoch 254:\n",
            "training accuracy: 0.9336990595611285\ttraining loss: 0.02464262953139024\tvalidation accuracy: 0.8070512820512821\tvalidation loss:0.04992571094861398\n",
            "Correct number of outputs in validation: 1259\tTotal number of outputs in validation: 1560\tTotal validation loss 77.8841090798378\n",
            "Epoch 255:\n",
            "training accuracy: 0.9315047021943573\ttraining loss: 0.02534920655331081\tvalidation accuracy: 0.8115384615384615\tvalidation loss:0.0490708942596729\n",
            "Correct number of outputs in validation: 1266\tTotal number of outputs in validation: 1560\tTotal validation loss 76.55059504508972\n",
            "Epoch 256:\n",
            "training accuracy: 0.9369905956112853\ttraining loss: 0.023415369072164113\tvalidation accuracy: 0.8083333333333333\tvalidation loss:0.049103093720399414\n",
            "Correct number of outputs in validation: 1261\tTotal number of outputs in validation: 1560\tTotal validation loss 76.60082620382309\n",
            "Epoch 257:\n",
            "training accuracy: 0.9369905956112853\ttraining loss: 0.02387388530990173\tvalidation accuracy: 0.8185897435897436\tvalidation loss:0.04859576851893694\n",
            "Correct number of outputs in validation: 1277\tTotal number of outputs in validation: 1560\tTotal validation loss 75.80939888954163\n",
            "Epoch 258:\n",
            "training accuracy: 0.9388714733542319\ttraining loss: 0.02300459361959214\tvalidation accuracy: 0.7974358974358975\tvalidation loss:0.05063821872075399\n",
            "Correct number of outputs in validation: 1244\tTotal number of outputs in validation: 1560\tTotal validation loss 78.99562120437622\n",
            "Epoch 259:\n",
            "training accuracy: 0.9363636363636364\ttraining loss: 0.024539743846159742\tvalidation accuracy: 0.801923076923077\tvalidation loss:0.04828790708994254\n",
            "Correct number of outputs in validation: 1251\tTotal number of outputs in validation: 1560\tTotal validation loss 75.32913506031036\n",
            "Epoch 260:\n",
            "training accuracy: 0.9355799373040752\ttraining loss: 0.02303306173918576\tvalidation accuracy: 0.8121794871794872\tvalidation loss:0.04948859753517004\n",
            "Correct number of outputs in validation: 1267\tTotal number of outputs in validation: 1560\tTotal validation loss 77.20221215486526\n",
            "Epoch 261:\n",
            "training accuracy: 0.9369905956112853\ttraining loss: 0.02331241118053097\tvalidation accuracy: 0.8153846153846154\tvalidation loss:0.04862541044369722\n",
            "Correct number of outputs in validation: 1272\tTotal number of outputs in validation: 1560\tTotal validation loss 75.85564029216766\n",
            "Epoch 262:\n",
            "training accuracy: 0.9380877742946708\ttraining loss: 0.023035851319475234\tvalidation accuracy: 0.7980769230769231\tvalidation loss:0.049591052455779834\n",
            "Correct number of outputs in validation: 1245\tTotal number of outputs in validation: 1560\tTotal validation loss 77.36204183101654\n",
            "Epoch 263:\n",
            "training accuracy: 0.9394984326018809\ttraining loss: 0.022904608211827503\tvalidation accuracy: 0.8044871794871795\tvalidation loss:0.04756496541011028\n",
            "Correct number of outputs in validation: 1255\tTotal number of outputs in validation: 1560\tTotal validation loss 74.20134603977203\n",
            "Epoch 264:\n",
            "training accuracy: 0.9379310344827586\ttraining loss: 0.022584132141313957\tvalidation accuracy: 0.8198717948717948\tvalidation loss:0.04855730151518797\n",
            "Correct number of outputs in validation: 1279\tTotal number of outputs in validation: 1560\tTotal validation loss 75.74939036369324\n",
            "Epoch 265:\n",
            "training accuracy: 0.9427899686520376\ttraining loss: 0.022000240541550805\tvalidation accuracy: 0.8153846153846154\tvalidation loss:0.048005670385482986\n",
            "Correct number of outputs in validation: 1272\tTotal number of outputs in validation: 1560\tTotal validation loss 74.88884580135345\n",
            "Epoch 266:\n",
            "training accuracy: 0.9396551724137931\ttraining loss: 0.022590169274367883\tvalidation accuracy: 0.8346153846153846\tvalidation loss:0.04760217475585449\n",
            "Correct number of outputs in validation: 1302\tTotal number of outputs in validation: 1560\tTotal validation loss 74.259392619133\n",
            "Epoch 267:\n",
            "training accuracy: 0.9153605015673981\ttraining loss: 0.03347788639249846\tvalidation accuracy: 0.7833333333333333\tvalidation loss:0.07191408314766028\n",
            "Correct number of outputs in validation: 1222\tTotal number of outputs in validation: 1560\tTotal validation loss 112.18596971035004\n",
            "Epoch 268:\n",
            "training accuracy: 0.24294670846394983\ttraining loss: 434.7400985769344\tvalidation accuracy: 0.12371794871794872\tvalidation loss:16.792968109326484\n",
            "Correct number of outputs in validation: 193\tTotal number of outputs in validation: 1560\tTotal validation loss 26197.030250549316\n",
            "Epoch 269:\n",
            "training accuracy: 0.1523510971786834\ttraining loss: 2.3719100706909892\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.6822941639484503\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 1064.3788957595825\n",
            "Epoch 270:\n",
            "training accuracy: 0.14764890282131662\ttraining loss: 0.2627419267515404\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.33914073965488334\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 529.059553861618\n",
            "Epoch 271:\n",
            "training accuracy: 0.14890282131661442\ttraining loss: 0.2648497885671155\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.2914898972480725\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 454.7242397069931\n",
            "Epoch 272:\n",
            "training accuracy: 0.16050156739811913\ttraining loss: 0.19391460369186342\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.3262496204712452\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 508.9494079351425\n",
            "Epoch 273:\n",
            "training accuracy: 0.16269592476489028\ttraining loss: 0.18087716677158977\tvalidation accuracy: 0.14038461538461539\tvalidation loss:0.30704932312170663\n",
            "Correct number of outputs in validation: 219\tTotal number of outputs in validation: 1560\tTotal validation loss 478.99694406986237\n",
            "Epoch 274:\n",
            "training accuracy: 0.16739811912225705\ttraining loss: 0.17121221157824357\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.301878673908038\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 470.9307312965393\n",
            "Epoch 275:\n",
            "training accuracy: 0.17304075235109717\ttraining loss: 0.16593572382456082\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.29974585656936353\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 467.6035362482071\n",
            "Epoch 276:\n",
            "training accuracy: 0.17366771159874608\ttraining loss: 0.16423525853216836\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.30153302878905563\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 470.3915249109268\n",
            "Epoch 277:\n",
            "training accuracy: 0.16551724137931034\ttraining loss: 0.16541510878311802\tvalidation accuracy: 0.14166666666666666\tvalidation loss:0.32014702069453704\n",
            "Correct number of outputs in validation: 221\tTotal number of outputs in validation: 1560\tTotal validation loss 499.4293522834778\n",
            "Epoch 278:\n",
            "training accuracy: 0.1647335423197492\ttraining loss: 0.16963775138309384\tvalidation accuracy: 0.13846153846153847\tvalidation loss:0.33673070791440135\n",
            "Correct number of outputs in validation: 216\tTotal number of outputs in validation: 1560\tTotal validation loss 525.2999043464661\n",
            "Epoch 279:\n",
            "training accuracy: 0.16253918495297806\ttraining loss: 0.17576352557792185\tvalidation accuracy: 0.13846153846153847\tvalidation loss:0.3418688599115763\n",
            "Correct number of outputs in validation: 216\tTotal number of outputs in validation: 1560\tTotal validation loss 533.315421462059\n",
            "Epoch 280:\n",
            "training accuracy: 0.17084639498432602\ttraining loss: 0.18419585523186807\tvalidation accuracy: 0.14166666666666666\tvalidation loss:0.31923809823317406\n",
            "Correct number of outputs in validation: 221\tTotal number of outputs in validation: 1560\tTotal validation loss 498.0114332437515\n",
            "Epoch 281:\n",
            "training accuracy: 0.19012539184952978\ttraining loss: 0.18080254709085328\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.23649456684405987\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 368.9315242767334\n",
            "Epoch 282:\n",
            "training accuracy: 0.18855799373040752\ttraining loss: 0.17588005962790368\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.19555572683994588\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 305.06693387031555\n",
            "Epoch 283:\n",
            "training accuracy: 0.18871473354231974\ttraining loss: 0.17533413579097737\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.1619943760144405\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 252.71122658252716\n",
            "Epoch 284:\n",
            "training accuracy: 0.17351097178683386\ttraining loss: 0.17991903650349583\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.14349636072531724\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 223.8543227314949\n",
            "Epoch 285:\n",
            "training accuracy: 0.15987460815047022\ttraining loss: 0.18943618980694715\tvalidation accuracy: 0.17884615384615385\tvalidation loss:0.133646987646054\n",
            "Correct number of outputs in validation: 279\tTotal number of outputs in validation: 1560\tTotal validation loss 208.48930072784424\n",
            "Epoch 286:\n",
            "training accuracy: 0.15705329153605016\ttraining loss: 0.20280448091814884\tvalidation accuracy: 0.16538461538461538\tvalidation loss:0.14503898009275779\n",
            "Correct number of outputs in validation: 258\tTotal number of outputs in validation: 1560\tTotal validation loss 226.26080894470215\n",
            "Epoch 287:\n",
            "training accuracy: 0.1652037617554859\ttraining loss: 0.20552785370417148\tvalidation accuracy: 0.1641025641025641\tvalidation loss:0.1643793060229375\n",
            "Correct number of outputs in validation: 256\tTotal number of outputs in validation: 1560\tTotal validation loss 256.43171739578247\n",
            "Epoch 288:\n",
            "training accuracy: 0.16567398119122256\ttraining loss: 0.20245943992489185\tvalidation accuracy: 0.1641025641025641\tvalidation loss:0.16538593173027039\n",
            "Correct number of outputs in validation: 256\tTotal number of outputs in validation: 1560\tTotal validation loss 258.0020534992218\n",
            "Epoch 289:\n",
            "training accuracy: 0.17335423197492164\ttraining loss: 0.2011149786482784\tvalidation accuracy: 0.15833333333333333\tvalidation loss:0.16783076631717192\n",
            "Correct number of outputs in validation: 247\tTotal number of outputs in validation: 1560\tTotal validation loss 261.8159954547882\n",
            "Epoch 290:\n",
            "training accuracy: 0.16849529780564262\ttraining loss: 0.207703479778804\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.18433566292126974\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 287.5636341571808\n",
            "Epoch 291:\n",
            "training accuracy: 0.1633228840125392\ttraining loss: 0.2339105667365382\tvalidation accuracy: 0.16153846153846155\tvalidation loss:0.2136447189710079\n",
            "Correct number of outputs in validation: 252\tTotal number of outputs in validation: 1560\tTotal validation loss 333.28576159477234\n",
            "Epoch 292:\n",
            "training accuracy: 0.16598746081504703\ttraining loss: 0.27518196763663455\tvalidation accuracy: 0.15128205128205127\tvalidation loss:0.2667693190085582\n",
            "Correct number of outputs in validation: 236\tTotal number of outputs in validation: 1560\tTotal validation loss 416.16013765335083\n",
            "Epoch 293:\n",
            "training accuracy: 0.1609717868338558\ttraining loss: 0.2967220248847172\tvalidation accuracy: 0.14743589743589744\tvalidation loss:0.2897198180357615\n",
            "Correct number of outputs in validation: 230\tTotal number of outputs in validation: 1560\tTotal validation loss 451.96291613578796\n",
            "Epoch 294:\n",
            "training accuracy: 0.16442006269592477\ttraining loss: 0.2742222172526357\tvalidation accuracy: 0.15\tvalidation loss:0.28787069549927347\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 449.0782849788666\n",
            "Epoch 295:\n",
            "training accuracy: 0.16630094043887148\ttraining loss: 0.2720238976904591\tvalidation accuracy: 0.15128205128205127\tvalidation loss:0.22112659460459\n",
            "Correct number of outputs in validation: 236\tTotal number of outputs in validation: 1560\tTotal validation loss 344.9574875831604\n",
            "Epoch 296:\n",
            "training accuracy: 0.1700626959247649\ttraining loss: 0.251278499179873\tvalidation accuracy: 0.15384615384615385\tvalidation loss:0.17905537409660144\n",
            "Correct number of outputs in validation: 240\tTotal number of outputs in validation: 1560\tTotal validation loss 279.32638359069824\n",
            "Epoch 297:\n",
            "training accuracy: 0.1724137931034483\ttraining loss: 0.2327503975936238\tvalidation accuracy: 0.15897435897435896\tvalidation loss:0.1411154818840516\n",
            "Correct number of outputs in validation: 248\tTotal number of outputs in validation: 1560\tTotal validation loss 220.14015173912048\n",
            "Epoch 298:\n",
            "training accuracy: 0.16865203761755485\ttraining loss: 0.22829952629569183\tvalidation accuracy: 0.18782051282051282\tvalidation loss:0.13784541212595425\n",
            "Correct number of outputs in validation: 293\tTotal number of outputs in validation: 1560\tTotal validation loss 215.03884291648865\n",
            "Epoch 299:\n",
            "training accuracy: 0.17037617554858933\ttraining loss: 0.21723253012264038\tvalidation accuracy: 0.1641025641025641\tvalidation loss:0.13341365448939493\n",
            "Correct number of outputs in validation: 256\tTotal number of outputs in validation: 1560\tTotal validation loss 208.12530100345612\n",
            "Epoch 300:\n",
            "training accuracy: 0.1677115987460815\ttraining loss: 0.21809876474280343\tvalidation accuracy: 0.16346153846153846\tvalidation loss:0.16372539874834893\n",
            "Correct number of outputs in validation: 255\tTotal number of outputs in validation: 1560\tTotal validation loss 255.41162204742432\n",
            "Epoch 301:\n",
            "training accuracy: 0.16990595611285267\ttraining loss: 0.2059668822441729\tvalidation accuracy: 0.15384615384615385\tvalidation loss:0.2007606219022702\n",
            "Correct number of outputs in validation: 240\tTotal number of outputs in validation: 1560\tTotal validation loss 313.1865701675415\n",
            "Epoch 302:\n",
            "training accuracy: 0.16912225705329154\ttraining loss: 0.19135199320914228\tvalidation accuracy: 0.1576923076923077\tvalidation loss:0.21134979724884034\n",
            "Correct number of outputs in validation: 246\tTotal number of outputs in validation: 1560\tTotal validation loss 329.7056837081909\n",
            "Epoch 303:\n",
            "training accuracy: 0.16896551724137931\ttraining loss: 0.18242870219822588\tvalidation accuracy: 0.1576923076923077\tvalidation loss:0.21336409449577332\n",
            "Correct number of outputs in validation: 246\tTotal number of outputs in validation: 1560\tTotal validation loss 332.8479874134064\n",
            "Epoch 304:\n",
            "training accuracy: 0.16238244514106584\ttraining loss: 0.18743790824865472\tvalidation accuracy: 0.1621794871794872\tvalidation loss:0.20874455922689195\n",
            "Correct number of outputs in validation: 253\tTotal number of outputs in validation: 1560\tTotal validation loss 325.6415123939514\n",
            "Epoch 305:\n",
            "training accuracy: 0.15862068965517243\ttraining loss: 0.19486472701951627\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.17086013662509428\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 266.5418131351471\n",
            "Epoch 306:\n",
            "training accuracy: 0.15219435736677117\ttraining loss: 0.2003514442043992\tvalidation accuracy: 0.17307692307692307\tvalidation loss:0.13368133680942731\n",
            "Correct number of outputs in validation: 270\tTotal number of outputs in validation: 1560\tTotal validation loss 208.5428854227066\n",
            "Epoch 307:\n",
            "training accuracy: 0.14780564263322885\ttraining loss: 0.2238552964593176\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.1368018362002495\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 213.41086447238922\n",
            "Epoch 308:\n",
            "training accuracy: 0.14028213166144202\ttraining loss: 0.2694449764434073\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.24545402438976827\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 382.9082780480385\n",
            "Epoch 309:\n",
            "training accuracy: 0.15047021943573669\ttraining loss: 0.268860278327637\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.26099721628886\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 407.15565741062164\n",
            "Epoch 310:\n",
            "training accuracy: 0.15109717868338557\ttraining loss: 0.267735073717784\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.25253657599290213\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 393.9570585489273\n",
            "Epoch 311:\n",
            "training accuracy: 0.15\ttraining loss: 0.2698710228301888\tvalidation accuracy: 0.14423076923076922\tvalidation loss:0.2251246786652467\n",
            "Correct number of outputs in validation: 225\tTotal number of outputs in validation: 1560\tTotal validation loss 351.1944987177849\n",
            "Epoch 312:\n",
            "training accuracy: 0.1506269592476489\ttraining loss: 0.27499649706865925\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.21259379104161874\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 331.64631402492523\n",
            "Epoch 313:\n",
            "training accuracy: 0.1523510971786834\ttraining loss: 0.282403723633962\tvalidation accuracy: 0.14551282051282052\tvalidation loss:0.20629709913180425\n",
            "Correct number of outputs in validation: 227\tTotal number of outputs in validation: 1560\tTotal validation loss 321.8234746456146\n",
            "Epoch 314:\n",
            "training accuracy: 0.14952978056426333\ttraining loss: 0.28388974840364484\tvalidation accuracy: 0.14038461538461539\tvalidation loss:0.17614004019743357\n",
            "Correct number of outputs in validation: 219\tTotal number of outputs in validation: 1560\tTotal validation loss 274.77846270799637\n",
            "Epoch 315:\n",
            "training accuracy: 0.14733542319749215\ttraining loss: 0.28617292148379325\tvalidation accuracy: 0.14166666666666666\tvalidation loss:0.17932281667987507\n",
            "Correct number of outputs in validation: 221\tTotal number of outputs in validation: 1560\tTotal validation loss 279.7435940206051\n",
            "Epoch 316:\n",
            "training accuracy: 0.14843260188087773\ttraining loss: 0.2898301663023177\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.17806611340015363\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 277.78313690423965\n",
            "Epoch 317:\n",
            "training accuracy: 0.14843260188087773\ttraining loss: 0.2949630653409749\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.18671227970566506\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 291.2711563408375\n",
            "Epoch 318:\n",
            "training accuracy: 0.14733542319749215\ttraining loss: 0.29070989972091393\tvalidation accuracy: 0.14038461538461539\tvalidation loss:0.1965555264399602\n",
            "Correct number of outputs in validation: 219\tTotal number of outputs in validation: 1560\tTotal validation loss 306.6266212463379\n",
            "Epoch 319:\n",
            "training accuracy: 0.14890282131661442\ttraining loss: 0.28508150192637427\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.17433515959061108\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 271.9628489613533\n",
            "Epoch 320:\n",
            "training accuracy: 0.14749216300940438\ttraining loss: 0.29667295798145493\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.20629252688242838\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 321.8163419365883\n",
            "Epoch 321:\n",
            "training accuracy: 0.14749216300940438\ttraining loss: 0.2809365250567284\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.18074567035222666\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 281.9632457494736\n",
            "Epoch 322:\n",
            "training accuracy: 0.1487460815047022\ttraining loss: 0.27234275074774944\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.20433418223491082\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 318.7613242864609\n",
            "Epoch 323:\n",
            "training accuracy: 0.15\ttraining loss: 0.2641052203866008\tvalidation accuracy: 0.14038461538461539\tvalidation loss:0.17790865634496394\n",
            "Correct number of outputs in validation: 219\tTotal number of outputs in validation: 1560\tTotal validation loss 277.53750389814377\n",
            "Epoch 324:\n",
            "training accuracy: 0.14498432601880878\ttraining loss: 0.2770004438055346\tvalidation accuracy: 0.1423076923076923\tvalidation loss:0.19204505212031878\n",
            "Correct number of outputs in validation: 222\tTotal number of outputs in validation: 1560\tTotal validation loss 299.5902813076973\n",
            "Epoch 325:\n",
            "training accuracy: 0.14576802507836992\ttraining loss: 0.26931407134921576\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.19402725795904796\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 302.6825224161148\n",
            "Epoch 326:\n",
            "training accuracy: 0.14482758620689656\ttraining loss: 0.2658795331899649\tvalidation accuracy: 0.13846153846153847\tvalidation loss:0.19714001478293003\n",
            "Correct number of outputs in validation: 216\tTotal number of outputs in validation: 1560\tTotal validation loss 307.53842306137085\n",
            "Epoch 327:\n",
            "training accuracy: 0.14655172413793102\ttraining loss: 0.2617813498435723\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.19196670288458847\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 299.46805649995804\n",
            "Epoch 328:\n",
            "training accuracy: 0.1463949843260188\ttraining loss: 0.2622982092785611\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.19466733500743524\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 303.68104261159897\n",
            "Epoch 329:\n",
            "training accuracy: 0.15109717868338557\ttraining loss: 0.2605750937353481\tvalidation accuracy: 0.14102564102564102\tvalidation loss:0.1958036531240512\n",
            "Correct number of outputs in validation: 220\tTotal number of outputs in validation: 1560\tTotal validation loss 305.4536988735199\n",
            "Epoch 330:\n",
            "training accuracy: 0.15689655172413794\ttraining loss: 0.25766799895554127\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.19759437143802644\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 308.2472194433212\n",
            "Epoch 331:\n",
            "training accuracy: 0.1561128526645768\ttraining loss: 0.2552095146575318\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.19917337210514607\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 310.71046048402786\n",
            "Epoch 332:\n",
            "training accuracy: 0.15689655172413794\ttraining loss: 0.25273607064003484\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.20269530316193898\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 316.2046729326248\n",
            "Epoch 333:\n",
            "training accuracy: 0.15642633228840125\ttraining loss: 0.253061068992256\tvalidation accuracy: 0.13974358974358975\tvalidation loss:0.20757356492372658\n",
            "Correct number of outputs in validation: 218\tTotal number of outputs in validation: 1560\tTotal validation loss 323.8147612810135\n",
            "Epoch 334:\n",
            "training accuracy: 0.15595611285266459\ttraining loss: 0.25302977616136724\tvalidation accuracy: 0.14358974358974358\tvalidation loss:0.2152951464821131\n",
            "Correct number of outputs in validation: 224\tTotal number of outputs in validation: 1560\tTotal validation loss 335.8604285120964\n",
            "Epoch 335:\n",
            "training accuracy: 0.15313479623824452\ttraining loss: 0.24482535721740006\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.21119218457203645\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 329.45980793237686\n",
            "Epoch 336:\n",
            "training accuracy: 0.15282131661442006\ttraining loss: 0.2479098454538184\tvalidation accuracy: 0.1423076923076923\tvalidation loss:0.22619483226384873\n",
            "Correct number of outputs in validation: 222\tTotal number of outputs in validation: 1560\tTotal validation loss 352.863938331604\n",
            "Epoch 337:\n",
            "training accuracy: 0.16379310344827586\ttraining loss: 0.24543286895490365\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.22439541243589842\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 350.0568434000015\n",
            "Epoch 338:\n",
            "training accuracy: 0.16065830721003135\ttraining loss: 0.24471503824089014\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.23291913519303004\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 363.35385090112686\n",
            "Epoch 339:\n",
            "training accuracy: 0.16018808777429466\ttraining loss: 0.24713769639173644\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.2448962457669087\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 382.03814339637756\n",
            "Epoch 340:\n",
            "training accuracy: 0.15940438871473353\ttraining loss: 0.2486295789760482\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.23977251557203438\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 374.04512429237366\n",
            "Epoch 341:\n",
            "training accuracy: 0.15\ttraining loss: 0.2517330548232626\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.21245093089647782\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 331.4234521985054\n",
            "Epoch 342:\n",
            "training accuracy: 0.14733542319749215\ttraining loss: 0.25042928434838324\tvalidation accuracy: 0.1391025641025641\tvalidation loss:0.16981609475154144\n",
            "Correct number of outputs in validation: 217\tTotal number of outputs in validation: 1560\tTotal validation loss 264.91310781240463\n",
            "Epoch 343:\n",
            "training accuracy: 0.1445141065830721\ttraining loss: 0.26616409054744206\tvalidation accuracy: 0.1596153846153846\tvalidation loss:0.12854494051291393\n",
            "Correct number of outputs in validation: 249\tTotal number of outputs in validation: 1560\tTotal validation loss 200.53010720014572\n",
            "Epoch 344:\n",
            "training accuracy: 0.14796238244514107\ttraining loss: 0.23942646621536687\tvalidation accuracy: 0.15320512820512822\tvalidation loss:0.14430294342530078\n",
            "Correct number of outputs in validation: 239\tTotal number of outputs in validation: 1560\tTotal validation loss 225.11259174346924\n",
            "Epoch 345:\n",
            "training accuracy: 0.1413793103448276\ttraining loss: 0.215323756434327\tvalidation accuracy: 0.15256410256410258\tvalidation loss:0.15351147957337208\n",
            "Correct number of outputs in validation: 238\tTotal number of outputs in validation: 1560\tTotal validation loss 239.47790813446045\n",
            "Epoch 346:\n",
            "training accuracy: 0.1432601880877743\ttraining loss: 0.21116314867634012\tvalidation accuracy: 0.1519230769230769\tvalidation loss:0.15108410884172488\n",
            "Correct number of outputs in validation: 237\tTotal number of outputs in validation: 1560\tTotal validation loss 235.69120979309082\n",
            "Epoch 347:\n",
            "training accuracy: 0.1413793103448276\ttraining loss: 0.21458093083951166\tvalidation accuracy: 0.1544871794871795\tvalidation loss:0.14574261353566095\n",
            "Correct number of outputs in validation: 241\tTotal number of outputs in validation: 1560\tTotal validation loss 227.3584771156311\n",
            "Epoch 348:\n",
            "training accuracy: 0.1426332288401254\ttraining loss: 0.21367209596693704\tvalidation accuracy: 0.15384615384615385\tvalidation loss:0.15221476959876526\n",
            "Correct number of outputs in validation: 240\tTotal number of outputs in validation: 1560\tTotal validation loss 237.4550405740738\n",
            "Epoch 349:\n",
            "training accuracy: 0.1438871473354232\ttraining loss: 0.21147754245604095\tvalidation accuracy: 0.15384615384615385\tvalidation loss:0.15811816392800745\n",
            "Correct number of outputs in validation: 240\tTotal number of outputs in validation: 1560\tTotal validation loss 246.66433572769165\n",
            "Epoch 350:\n",
            "training accuracy: 0.145141065830721\ttraining loss: 0.21053405102330688\tvalidation accuracy: 0.1519230769230769\tvalidation loss:0.16162937604464017\n",
            "Correct number of outputs in validation: 237\tTotal number of outputs in validation: 1560\tTotal validation loss 252.14182662963867\n",
            "Epoch 351:\n",
            "training accuracy: 0.1487460815047022\ttraining loss: 0.20467492208398622\tvalidation accuracy: 0.15\tvalidation loss:0.16390876601903867\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 255.69767498970032\n",
            "Epoch 352:\n",
            "training accuracy: 0.14623824451410658\ttraining loss: 0.20265123082739434\tvalidation accuracy: 0.14935897435897436\tvalidation loss:0.16210431999120956\n",
            "Correct number of outputs in validation: 233\tTotal number of outputs in validation: 1560\tTotal validation loss 252.88273918628693\n",
            "Epoch 353:\n",
            "training accuracy: 0.14545454545454545\ttraining loss: 0.20237975426975835\tvalidation accuracy: 0.15320512820512822\tvalidation loss:0.16211786361841055\n",
            "Correct number of outputs in validation: 239\tTotal number of outputs in validation: 1560\tTotal validation loss 252.90386724472046\n",
            "Epoch 354:\n",
            "training accuracy: 0.14576802507836992\ttraining loss: 0.20143997899043523\tvalidation accuracy: 0.15256410256410258\tvalidation loss:0.16296172929115785\n",
            "Correct number of outputs in validation: 238\tTotal number of outputs in validation: 1560\tTotal validation loss 254.22029769420624\n",
            "Epoch 355:\n",
            "training accuracy: 0.1487460815047022\ttraining loss: 0.1982781811847956\tvalidation accuracy: 0.15384615384615385\tvalidation loss:0.1637232007124485\n",
            "Correct number of outputs in validation: 240\tTotal number of outputs in validation: 1560\tTotal validation loss 255.40819311141968\n",
            "Epoch 356:\n",
            "training accuracy: 0.15156739811912226\ttraining loss: 0.19285740809380822\tvalidation accuracy: 0.15384615384615385\tvalidation loss:0.15909443719264788\n",
            "Correct number of outputs in validation: 240\tTotal number of outputs in validation: 1560\tTotal validation loss 248.1873220205307\n",
            "Epoch 357:\n",
            "training accuracy: 0.14670846394984327\ttraining loss: 0.20156076770030593\tvalidation accuracy: 0.15\tvalidation loss:0.16836783106510456\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 262.6538164615631\n",
            "Epoch 358:\n",
            "training accuracy: 0.15203761755485892\ttraining loss: 0.19638708023628845\tvalidation accuracy: 0.15\tvalidation loss:0.18320770538770237\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 285.8040204048157\n",
            "Epoch 359:\n",
            "training accuracy: 0.15768025078369907\ttraining loss: 0.19616237545275014\tvalidation accuracy: 0.1467948717948718\tvalidation loss:0.18330712776917676\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 285.95911931991577\n",
            "Epoch 360:\n",
            "training accuracy: 0.15015673981191222\ttraining loss: 0.20617051355330548\tvalidation accuracy: 0.1467948717948718\tvalidation loss:0.21181631027123868\n",
            "Correct number of outputs in validation: 229\tTotal number of outputs in validation: 1560\tTotal validation loss 330.4334440231323\n",
            "Epoch 361:\n",
            "training accuracy: 0.1523510971786834\ttraining loss: 0.20210841286892428\tvalidation accuracy: 0.14743589743589744\tvalidation loss:0.23597739033209972\n",
            "Correct number of outputs in validation: 230\tTotal number of outputs in validation: 1560\tTotal validation loss 368.12472891807556\n",
            "Epoch 362:\n",
            "training accuracy: 0.15266457680250783\ttraining loss: 0.20804641270151705\tvalidation accuracy: 0.15256410256410258\tvalidation loss:0.28846197388111017\n",
            "Correct number of outputs in validation: 238\tTotal number of outputs in validation: 1560\tTotal validation loss 450.00067925453186\n",
            "Epoch 363:\n",
            "training accuracy: 0.14247648902821317\ttraining loss: 0.20501040662157125\tvalidation accuracy: 0.14807692307692308\tvalidation loss:0.31781213466937724\n",
            "Correct number of outputs in validation: 231\tTotal number of outputs in validation: 1560\tTotal validation loss 495.7869300842285\n",
            "Epoch 364:\n",
            "training accuracy: 0.14952978056426333\ttraining loss: 0.20232685198043954\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.3392504264146854\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 529.2306652069092\n",
            "Epoch 365:\n",
            "training accuracy: 0.15407523510971788\ttraining loss: 0.20188285361823616\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.35375286310147014\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 551.8544664382935\n",
            "Epoch 366:\n",
            "training accuracy: 0.15391849529780563\ttraining loss: 0.1995318315526161\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.3399152060349782\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 530.267721414566\n",
            "Epoch 367:\n",
            "training accuracy: 0.15815047021943573\ttraining loss: 0.19833160154871807\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.332055764626234\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 518.006992816925\n",
            "Epoch 368:\n",
            "training accuracy: 0.159717868338558\ttraining loss: 0.19654390660572948\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.3141134873414651\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 490.01704025268555\n",
            "Epoch 369:\n",
            "training accuracy: 0.16583072100313478\ttraining loss: 0.19594686566662264\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.3115930424286769\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 486.08514618873596\n",
            "Epoch 370:\n",
            "training accuracy: 0.16849529780564262\ttraining loss: 0.19732550565725585\tvalidation accuracy: 0.14871794871794872\tvalidation loss:0.3049425603487553\n",
            "Correct number of outputs in validation: 232\tTotal number of outputs in validation: 1560\tTotal validation loss 475.7103941440582\n",
            "Epoch 371:\n",
            "training accuracy: 0.1700626959247649\ttraining loss: 0.20296692692187138\tvalidation accuracy: 0.14871794871794872\tvalidation loss:0.2998630097279182\n",
            "Correct number of outputs in validation: 232\tTotal number of outputs in validation: 1560\tTotal validation loss 467.78629517555237\n",
            "Epoch 372:\n",
            "training accuracy: 0.17037617554858933\ttraining loss: 0.21767022027677876\tvalidation accuracy: 0.15\tvalidation loss:0.261432463542009\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 407.83464312553406\n",
            "Epoch 373:\n",
            "training accuracy: 0.16567398119122256\ttraining loss: 0.2440529133832567\tvalidation accuracy: 0.15\tvalidation loss:0.22659258613219627\n",
            "Correct number of outputs in validation: 234\tTotal number of outputs in validation: 1560\tTotal validation loss 353.4844343662262\n",
            "Epoch 374:\n",
            "training accuracy: 0.1664576802507837\ttraining loss: 0.24292946008492414\tvalidation accuracy: 0.14615384615384616\tvalidation loss:0.34212432885781313\n",
            "Correct number of outputs in validation: 228\tTotal number of outputs in validation: 1560\tTotal validation loss 533.7139530181885\n",
            "Epoch 375:\n",
            "training accuracy: 0.15532915360501567\ttraining loss: 0.25483543586955176\tvalidation accuracy: 0.1544871794871795\tvalidation loss:0.20826988418896994\n",
            "Correct number of outputs in validation: 241\tTotal number of outputs in validation: 1560\tTotal validation loss 324.9010193347931\n",
            "Epoch 376:\n",
            "training accuracy: 0.13808777429467084\ttraining loss: 0.24093595040629276\tvalidation accuracy: 0.1564102564102564\tvalidation loss:0.17585262190072964\n",
            "Correct number of outputs in validation: 244\tTotal number of outputs in validation: 1560\tTotal validation loss 274.33009016513824\n",
            "Epoch 377:\n",
            "training accuracy: 0.15893416927899687\ttraining loss: 0.21474700400074448\tvalidation accuracy: 0.14487179487179488\tvalidation loss:0.24398664152010893\n",
            "Correct number of outputs in validation: 226\tTotal number of outputs in validation: 1560\tTotal validation loss 380.61916077136993\n",
            "Epoch 378:\n",
            "training accuracy: 0.16786833855799374\ttraining loss: 0.2003614924544451\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.31709024141996334\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 494.6607766151428\n",
            "Epoch 379:\n",
            "training accuracy: 0.1669278996865204\ttraining loss: 0.19658682251051302\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.38530441629580964\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 601.074889421463\n",
            "Epoch 380:\n",
            "training accuracy: 0.16394984326018808\ttraining loss: 0.1978191915817769\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.42325149591152483\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 660.2723336219788\n",
            "Epoch 381:\n",
            "training accuracy: 0.15501567398119123\ttraining loss: 0.18437707211156623\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2841118775117092\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 443.2145289182663\n",
            "Epoch 382:\n",
            "training accuracy: 0.17476489028213166\ttraining loss: 0.16970802538073548\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.22722831601515794\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 354.4761729836464\n",
            "Epoch 383:\n",
            "training accuracy: 0.174294670846395\ttraining loss: 0.1701982661474461\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2140485037595798\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 333.91566586494446\n",
            "Epoch 384:\n",
            "training accuracy: 0.18871473354231974\ttraining loss: 0.17426852032682366\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.23606261333976036\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 368.25767681002617\n",
            "Epoch 385:\n",
            "training accuracy: 0.16802507836990596\ttraining loss: 0.17869237395102702\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.3028833373234822\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 472.49800622463226\n",
            "Epoch 386:\n",
            "training accuracy: 0.15564263322884012\ttraining loss: 0.1723996717821468\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.31625390943044274\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 493.35609871149063\n",
            "Epoch 387:\n",
            "training accuracy: 0.15344827586206897\ttraining loss: 0.16038774880682788\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.28581719474914746\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 445.87482380867004\n",
            "Epoch 388:\n",
            "training accuracy: 0.15768025078369907\ttraining loss: 0.1562002944348374\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.27716732307886466\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 432.38102400302887\n",
            "Epoch 389:\n",
            "training accuracy: 0.16081504702194357\ttraining loss: 0.15514026642966794\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.27125264337429633\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 423.1541236639023\n",
            "Epoch 390:\n",
            "training accuracy: 0.16238244514106584\ttraining loss: 0.15466132347112913\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.26247329177000583\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 409.4583351612091\n",
            "Epoch 391:\n",
            "training accuracy: 0.16818181818181818\ttraining loss: 0.1536623012870083\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.25987826727139646\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 405.41009694337845\n",
            "Epoch 392:\n",
            "training accuracy: 0.16943573667711598\ttraining loss: 0.1544146008158926\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.26117272759095217\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 407.4294550418854\n",
            "Epoch 393:\n",
            "training accuracy: 0.1719435736677116\ttraining loss: 0.15411988564980067\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2567954230002868\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 400.6008598804474\n",
            "Epoch 394:\n",
            "training accuracy: 0.1719435736677116\ttraining loss: 0.1530935947424192\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2525362713214679\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 393.95658326148987\n",
            "Epoch 395:\n",
            "training accuracy: 0.17178683385579938\ttraining loss: 0.15212605076150088\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.24664274471310468\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 384.7626817524433\n",
            "Epoch 396:\n",
            "training accuracy: 0.17288401253918495\ttraining loss: 0.1508751092005673\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2414533819907751\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 376.66727590560913\n",
            "Epoch 397:\n",
            "training accuracy: 0.17163009404388715\ttraining loss: 0.1496518037349079\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.23634117583815867\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 368.69223430752754\n",
            "Epoch 398:\n",
            "training accuracy: 0.16865203761755485\ttraining loss: 0.1487565428952812\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.2309998376438251\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 360.35974672436714\n",
            "Epoch 399:\n",
            "training accuracy: 0.16755485893416927\ttraining loss: 0.1478796633153126\tvalidation accuracy: 0.14294871794871794\tvalidation loss:0.22326192995294547\n",
            "Correct number of outputs in validation: 223\tTotal number of outputs in validation: 1560\tTotal validation loss 348.2886107265949\n",
            "Total time:   240.84 s  Time per Epoch:   0.60 s \n",
            "The best epoch: 266\tAccuracy:0.8346153846153846\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = (50, 256, 7) # (input size, hidden size, number of classes)\n",
        "model_path = get_model_path(\"Transformer_news_classifier_2\", 128, 0.01, 226, \"Aug_13_00_28_hidden_size_256\")\n",
        "test_result = test_model(Transformer_news_classifier_2, parameters, True, model_path, test_loader, nn.MSELoss())\n",
        "print(\"Correct: {0}\\tTotal: {1}\\tAccuracy: {2}\\tLoss: {3}\".format(test_result[0], test_result[1], test_result[2], test_result[3]))"
      ],
      "metadata": {
        "id": "gEeaAPkuKYEL",
        "outputId": "adc833ef-6f10-4dd2-e780-ba120420448d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Correct: 1218\tTotal: 1560\tAccuracy: 0.7807692307692308\tLoss: 0.05317903569875619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"Correct: 1218\tTotal: 1560\tAccuracy: 0.7807692307692308\tLoss: 0.05317903569875619\" >> /model/test_result.txt"
      ],
      "metadata": {
        "id": "7NcvTFK-3IH0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /model /content/drive/MyDrive/ -r"
      ],
      "metadata": {
        "id": "7BTvmlw9MO6o"
      },
      "execution_count": 32,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "all_code.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NENROZ0T0m9D",
        "outputId": "0277516d-ecdb-4fb7-a6c4-02d8e978bb92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp '/content/drive/MyDrive/data' '/' -r"
      ],
      "metadata": {
        "id": "PSHfppoAE7Bj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm /model -r\n",
        "! mkdir /model"
      ],
      "metadata": {
        "id": "OssqkfxpGApJ",
        "outputId": "f1a4572a-0d24-4e7e-8a09-402a2efca87a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/model': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "k4paDiag0lNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torchtext\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "BIhi0eyZq9HY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileNn = ''"
      ],
      "metadata": {
        "id": "jDZFsrDrtNe6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def skipFromHere(index):\n",
        "\n",
        "    if index > 50:\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "metadata": {
        "id": "7lz_LlH58PLv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YWA4tXeB0lNh"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import torchtext\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "def data_loader(batch_size=128):\n",
        "    # load data from csv file\n",
        "    fields = ['news_article', 'news_category']\n",
        "\n",
        "    train_data = pd.read_csv(fileNn + '/data/inshort_news_data-train.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    val_data = pd.read_csv(fileNn +'/data/inshort_news_data-val.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    test_data = pd.read_csv(fileNn +'/data/inshort_news_data-test.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)\n",
        "    new_data = pd.read_csv(fileNn +'/data/new_news_articles.csv',header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True, skiprows=lambda x: skipFromHere(x))\n",
        "    # read_csv seems have bugs for skip_blank_lines accoring to return value of what i tried for \n",
        "    # new_data before and online forum, so i use skirows instead of skip_blank_lines\n",
        "\n",
        "\n",
        "    # Creating training and testing data\n",
        "    X_train = train_data['news_article']\n",
        "    Y_train = train_data['news_category']\n",
        "\n",
        "    X_test = test_data['news_article']\n",
        "    Y_test = test_data['news_category']\n",
        "\n",
        "    X_val = val_data['news_article']\n",
        "    Y_val = val_data['news_category']\n",
        "    \n",
        "    X_new = new_data['news_article']\n",
        "    Y_new = new_data['news_category']\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      X_train[i] = X_train[i].split()\n",
        "\n",
        "    for j in range(X_val.shape[0]):\n",
        "      X_val[j] = X_val[j].split()\n",
        "\n",
        "    for k in range(X_test.shape[0]):\n",
        "      X_test[k] = X_test[k].split()\n",
        "\n",
        "    for m in range(X_new.shape[0]):\n",
        "      X_new[m] = X_new[m].split()\n",
        "    # fixing bugs for interating out of range in above loop about new data\n",
        "\n",
        "\n",
        "    Y_train = pd.get_dummies(Y_train).to_numpy()\n",
        "    Y_val = pd.get_dummies(Y_val).to_numpy()\n",
        "    Y_test = pd.get_dummies(Y_test).to_numpy()\n",
        "    Y_new = pd.get_dummies(Y_new).to_numpy()\n",
        "\n",
        "    # stopwords to eliminate useless words\n",
        "    stopwords = []\n",
        "    stop = open(fileNn + '/data/stopwords.txt', encoding=\"utf-8\")\n",
        "    for line in stop:\n",
        "      stopwords.append(line.strip())\n",
        "    stop.close()\n",
        "\n",
        "    # choose first 61 words\n",
        "    for ix in X_train:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_val:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    for ix in X_test:\n",
        "      if (len(ix) > 61):\n",
        "        ix = ix[0:61]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      if (len(X_new[i]) > 61):\n",
        "        X_new[i] = X_new[i][0:61]\n",
        "    # somehow above loops don't change len of each entry, now they are fine\n",
        "\n",
        "    # utilize Glove6B for embedding\n",
        "    glove = torchtext.vocab.GloVe(name='6B', dim=50)\n",
        "\n",
        "    # Filling the embedding matrix\n",
        "    embedding_matrix_train = np.zeros((X_train.shape[0], 61, 50))\n",
        "    embedding_matrix_val = np.zeros((X_val.shape[0], 61, 50))\n",
        "    embedding_matrix_test = np.zeros((X_test.shape[0], 61, 50))\n",
        "    embedding_matrix_new = np.zeros((X_new.shape[0], 61, 50))\n",
        "\n",
        "    for i in range(X_train.shape[0]):\n",
        "      for j in range(len(X_train[i])):\n",
        "        if not (X_train[i][j].lower() in stopwords):\n",
        "          embedding_matrix_train[i][j] = glove[X_train[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_val.shape[0]):\n",
        "      for j in range(len(X_val[i])):\n",
        "        if not (X_val[i][j].lower() in stopwords):\n",
        "          embedding_matrix_val[i][j] = glove[X_val[i][j].lower()]\n",
        "\n",
        "    for i in range(X_test.shape[0]):\n",
        "      for j in range(len(X_test[i])):\n",
        "        if not (X_test[i][j].lower() in stopwords):\n",
        "          embedding_matrix_test[i][j] = glove[X_test[i][j].lower()]\n",
        "    \n",
        "    for i in range(X_new.shape[0]):\n",
        "      for j in range(len(X_new[i])):\n",
        "        if not (X_new[i][j].lower() in stopwords):\n",
        "          embedding_matrix_new[i][j] = glove[X_new[i][j].lower()]\n",
        "\n",
        "    X_train_t = torch.from_numpy(embedding_matrix_train).to(torch.float32)\n",
        "    Y_train_t = torch.from_numpy(Y_train).to(torch.float32)\n",
        "    X_val_t = torch.from_numpy(embedding_matrix_val).to(torch.float32)\n",
        "    Y_val_t = torch.from_numpy(Y_val).to(torch.float32)\n",
        "    X_test_t = torch.from_numpy(embedding_matrix_test).to(torch.float32)\n",
        "    Y_test_t = torch.from_numpy(Y_test).to(torch.float32)\n",
        "    X_new_t = torch.from_numpy(embedding_matrix_new).to(torch.float32)\n",
        "    Y_new_t = torch.from_numpy(Y_new).to(torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
        "    val_dataset = TensorDataset(X_val_t, Y_val_t)\n",
        "    test_dataset = TensorDataset(X_test_t, Y_test_t)\n",
        "    new_dataset = TensorDataset(X_new_t, Y_new_t)\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "    new_dataloader = DataLoader(new_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader, new_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader, new_loader = data_loader()"
      ],
      "metadata": {
        "id": "6RmVocW5sOcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33cdc21-703a-47ec-8e1b-fd41f51d3644"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.40MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:14<00:00, 28335.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num training articles:',len(train_loader.dataset))\n",
        "print('Num validation articles:',len(val_loader.dataset))\n",
        "print('Num test articles:',len(test_loader.dataset))\n",
        "print('Num new articles:',len(new_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Qt_1IlP7Lu",
        "outputId": "8200a6f1-398d-4fa6-e2b1-b7065a80cc51"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training articles: 6380\n",
            "Num validation articles: 1560\n",
            "Num test articles: 1560\n",
            "Num new articles: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NBx-LLzS0lNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from math import sin, cos\n",
        "use_cuda = True\n",
        "\n",
        "# I made this a bidirectional LSTM.\n",
        "class LSTM_news_classifier_3(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_3, self).__init__()\n",
        "        self.name = \"LSTM_3\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(2, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(out[:,-1,:])\n",
        "\n",
        "\n",
        "# LSTM model\n",
        "class LSTM_news_classifier_4(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(LSTM_news_classifier_4, self).__init__()\n",
        "        self.name = \"LSTM_4\"\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True, num_layers=2, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(4, x.size(0), self.hidden_size)\n",
        "        c0 = torch.zeros(4, x.size(0), self.hidden_size)\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            h0 = h0.cuda()\n",
        "            c0 = c0.cuda()\n",
        "        out, (h_n, c_n) = self.rnn(x, (h0, c0))\n",
        "        return self.fc(out[:,-1,:])\n",
        "\n",
        "class Transformer_news_classifier_2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_class):\n",
        "        super(Transformer_news_classifier_2, self).__init__()\n",
        "        self.name = \"Transformer_news_classifier_2\"\n",
        "        self.linear_q = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_k = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_v = nn.Linear(input_size, hidden_size)\n",
        "        self.linear_x = nn.Linear(input_size, hidden_size)\n",
        "        self.attention = nn.MultiheadAttention(hidden_size, num_heads=4, batch_first=True)\n",
        "        self.fc1 = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size))\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        for batch in range(x.shape[0]):\n",
        "            for pos in range(x.shape[1]):\n",
        "                for i in range(x.shape[2]):\n",
        "                    if i % 2 == 0:\n",
        "                        pe = sin(pos / pow(10000, (2 * i / (x.shape[2]))))\n",
        "                    else:\n",
        "                        pe = cos(pos / pow(10000, (2 * (i - 1) / (x.shape[2]))))\n",
        "                    x[batch][pos][i] = x[batch][pos][i] + pe\n",
        "        q, k, v = self.linear_q(x), self.linear_k(x), self.linear_v(x)\n",
        "        x = self.norm(self.linear_x(x) + self.attention(q, k, v)[0])\n",
        "        x = self.norm(x + self.fc1(x))\n",
        "        x = torch.sum(x, 1)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r97Hm3-x0lNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Testing Code"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JgVHyyl30lNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_model_path(name, batch_size, learning_rate, epoch, exercise_code):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}_exercise_{4}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_csv_path(name, batch_size, learning_rate, exercise_code):\n",
        "    \"\"\" Generate a name for the csv file consisting of all training and validation data\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"data_{0}_bs{1}_lr{2}_exercise_{3}.csv\".format(name,batch_size, learning_rate, exercise_code)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_fig_path(name1, name2, batch_size, learning_rate, exercise_code):\n",
        "    path = \"fig_{0}_bs{1}_lr{2}_exercise_{3}_{4}.png\".format(name1, batch_size, learning_rate, exercise_code, name2)\n",
        "    path = \"/model/\" + path\n",
        "    return path\n",
        "\n",
        "def find_the_best_model(val_acc):\n",
        "    \"\"\" Find the model with the best validation accuracy\n",
        "\n",
        "    Args:\n",
        "        validation accuracy list\n",
        "    Returns:\n",
        "        The epoch with the greatest accuracy and its accuracy\n",
        "    \"\"\"\n",
        "    cur_largest = -1\n",
        "    cur_largest_epoch = -1\n",
        "    for epoch in range(len(val_acc)):\n",
        "        if(val_acc[epoch] > cur_largest):\n",
        "            cur_largest = val_acc[epoch]\n",
        "            cur_largest_epoch = epoch\n",
        "    return cur_largest_epoch, cur_largest\n",
        "\n",
        "\n",
        "def save_to_csv(path, epochs, train_losses, train_acc, val_losses, val_acc, header):\n",
        "    organized_data = []\n",
        "    organized_data.append(header)\n",
        "    for i in range(len(epochs)):\n",
        "        organized_data.append([epochs[i], train_losses[i], train_acc[i], val_losses[i], val_acc[i]])\n",
        "    f = open(path,'w+')\n",
        "    write_csv = csv.writer(f)\n",
        "    write_csv.writerows(organized_data)\n",
        "\n",
        "\n",
        "def train_net(net, batch_size, learning_rate, num_epochs, train_loader, val_loader, exercise_code):\n",
        "    assert num_epochs > 0, \"num_epochs must be an integer that is greater than 0\"\n",
        "    assert learning_rate > 0, \"learning_rate must be greater than 0\"\n",
        "    torch.manual_seed(1000)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(),\n",
        "                                 lr=learning_rate,\n",
        "                                 weight_decay=1e-5)\n",
        "    epochs, train_losses, train_acc, val_losses, val_acc = [], [], [], [], []\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        epochs.append(epoch)\n",
        "        total, correct = 0, 0\n",
        "        total_loss = 0\n",
        "        for articles, labels in train_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                articles = articles.cuda()\n",
        "                labels = labels.cuda()\n",
        "            out = net(articles)\n",
        "            loss = criterion(out, labels)\n",
        "            total_loss = total_loss + loss.item() * articles.shape[0]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            # print(out.shape)\n",
        "            pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "            # print(pred)\n",
        "            # print(torch.argmax(labels, dim=1))\n",
        "            correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "            total = total + articles.shape[0]\n",
        "            # print(correct, total)\n",
        "        train_acc.append(correct/total)\n",
        "        train_losses.append(total_loss/total)\n",
        "\n",
        "        val_correct = 0\n",
        "        val_total_loss = 0\n",
        "        val_total = 0\n",
        "        for val_articles, val_labels in val_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                val_articles = val_articles.cuda()\n",
        "                val_labels = val_labels.cuda()\n",
        "            val_out = net(val_articles)\n",
        "            # print(val_imgs)\n",
        "            val_pred = torch.squeeze(val_out.max(1, keepdim=True)[1], 1)\n",
        "            val_correct = val_correct + val_pred.eq(torch.argmax(val_labels, dim=1)).sum().item()\n",
        "            val_total = val_total + val_articles.shape[0]\n",
        "            val_total_loss = val_total_loss + (criterion(val_out, val_labels)).item() * val_articles.shape[0]\n",
        "        val_losses.append(val_total_loss/val_total) # Append the average loss\n",
        "        val_acc.append(val_correct/val_total)\n",
        "\n",
        "        print(\"Epoch {0}:\\ntraining accuracy: {1}\\ttraining loss: {2}\\tvalidation accuracy: {3}\\tvalidation loss:{4}\".format(epoch, train_acc[epoch], train_losses[epoch], val_acc[epoch], val_losses[epoch]))\n",
        "        print(\"Correct number of outputs in validation: {0}\\tTotal number of outputs in validation: {1}\\tTotal validation loss {2}\".format(val_correct, val_total, val_total_loss))\n",
        "        model_path = get_model_path(net.name, batch_size, learning_rate, epoch, exercise_code)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "    end_time = time.time()\n",
        "    print(\"Total time:  % 6.2f s  Time per Epoch: % 6.2f s \" % (\n",
        "    (end_time - start_time), ((end_time - start_time) / num_epochs)))\n",
        "\n",
        "    best_epoch, best_epoch_acc = find_the_best_model(val_acc)\n",
        "    print(\"The best epoch: {0}\\tAccuracy:{1}\".format(best_epoch, best_epoch_acc))\n",
        "\n",
        "    csv_path = get_csv_path(net.name, batch_size, learning_rate, exercise_code)\n",
        "    header = [\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Validation Loss\", \"Validation Accuracy\"]\n",
        "    save_to_csv(csv_path, epochs, train_losses, train_acc, val_losses, val_acc, header)\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.plot(epochs, train_losses, label=\"Train\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Accuracy Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Training\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Training_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Loss Curve\")\n",
        "    plt.plot(epochs, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Train Loss\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Loss\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Validation Accuracy Curve\")\n",
        "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Validation Accuracy\")\n",
        "    plt.savefig(get_fig_path(net.name, \"Val_Acc\", batch_size, learning_rate, exercise_code))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def test_model(net_type, parameters, use_cuda, model_path, data_loader, criterion):\n",
        "    state = torch.load(model_path)\n",
        "    net = net_type(parameters[0], parameters[1], parameters[2])\n",
        "    net.load_state_dict(state)\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        net.cuda()\n",
        "        print('CUDA is available!  Training on GPU ...')\n",
        "    else:\n",
        "        print('CUDA is not available.  Training on CPU ...')\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    for articles, labels in data_loader:\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            articles = articles.cuda()\n",
        "            labels = labels.cuda()\n",
        "        out = net(articles)\n",
        "        pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)\n",
        "        correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()\n",
        "        total = total + articles.shape[0]\n",
        "        total_loss = total_loss + (criterion(out, labels)).item() * articles.shape[0]\n",
        "    return correct, total, correct / total, total_loss / total"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G3SQ8YIm0lNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and test your model here"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XHaSVNYM0lNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "News_model = Transformer_news_classifier_2(50, 256, 7)\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  News_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')"
      ],
      "metadata": {
        "id": "e5qO3oIjFmFN",
        "outputId": "00883ecc-7e7e-4957-e823-ef8f0231a1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_net(News_model, 128, 0.01, 100, train_loader, val_loader, 'Aug_12_09_04_hidden_size_256')"
      ],
      "metadata": {
        "id": "Yov5VrVvJOWd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "42a34233-b85a-4465-8614-61b6b20487fa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 61, 50])\n",
            "torch.Size([128, 61, 50])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-64c1abde09f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNews_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Aug_12_09_04_hidden_size_256'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-b8667a858b98>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, batch_size, learning_rate, num_epochs, train_loader, val_loader, exercise_code)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0marticles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-7bdf046c5edf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                         \u001b[0mpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = (50, 256, 7) # (input size, hidden size, number of classes)\n",
        "model_path = get_model_path(\"LSTM_4\", 256, 0.01, 151, \"Aug_12_2_51_bidirectional_2_layers_hidden_size_256\")\n",
        "test_result = test_model(LSTM_news_classifier_4, parameters, True, model_path, test_loader, nn.MSELoss())\n",
        "print(\"Correct: {0}\\tTotal: {1}\\tAccuracy: {2}\\tLoss: {3}\".format(test_result[0], test_result[1], test_result[2], test_result[3]))"
      ],
      "metadata": {
        "id": "gEeaAPkuKYEL",
        "outputId": "8aa9a44c-7524-4ff5-edad-ab2e0160490b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Correct: 1323\tTotal: 1560\tAccuracy: 0.8480769230769231\tLoss: 0.03897613139870839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"Correct: 1323\tTotal: 1560\tAccuracy: 0.8480769230769231\tLoss: 0.03897613139870839\" >> /model/test_result.txt"
      ],
      "metadata": {
        "id": "7NcvTFK-3IH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /model /content/drive/MyDrive/ -r"
      ],
      "metadata": {
        "id": "7BTvmlw9MO6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "all_code.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
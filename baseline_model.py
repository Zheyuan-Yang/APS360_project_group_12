# -*- coding: utf-8 -*-
"""baseline model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VxBiLFThB97TXgpqXmeTrIvGLEHboB8b

# Data Preparation
"""

import numpy as np
import pandas as pd
import torch
import torchtext
from torch.utils.data import TensorDataset, DataLoader

# load data from csv file
fields = ['news_article', 'news_category']

train_data = pd.read_csv('/content/inshort_news_data-train.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)
val_data = pd.read_csv('/content/inshort_news_data-val.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)
test_data = pd.read_csv('/content/inshort_news_data-test.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)

print('Num training articles: ', len(train_data))
print('Num validation articles: ', len(val_data))
print('Num testing articles: ', len(test_data))

print(train_data)

# Creating training and testing data
X_train = train_data['news_article']
Y_train = train_data['news_category']

X_test = test_data['news_article']
Y_test = test_data['news_category']


X_val = val_data['news_article']
Y_val = val_data['news_category']

print (X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)

print(X_train)
print(Y_train)

"""# Prepare X_train and Y_train for package model"""

Y_train = pd.get_dummies(Y_train).to_numpy()
Y_val = pd.get_dummies(Y_val).to_numpy()
Y_test = pd.get_dummies(Y_test).to_numpy()

print(Y_train)

y_train, y_val, y_test = [],[],[]
for i in range(Y_train.shape[0]):
  for j in range(7):
    if Y_train[i][j]==1:
      y_train.append(j)

y_train = np.array(y_train)

for i in range(Y_val.shape[0]):
  for j in range(7):
    if Y_val[i][j]==1:
      y_val.append(j)

y_val = np.array(y_val)


for i in range(Y_test.shape[0]):
  for j in range(7):
    if Y_test[i][j]==1:
      y_test.append(j)

y_test = np.array(y_test)

print(y_train.shape, y_val.shape, y_test.shape)

X = X_train
y = y_train

from sklearn.model_selection import train_test_split
#split dataset into train and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

print(y_train.shape)

# Extracting features from text files
from sklearn.feature_extraction.text import CountVectorizer
count_vect = CountVectorizer()
X_train_counts = count_vect.fit_transform(X_train)

X_test_counts = count_vect.fit_transform(X_test)
X_test_counts.shape

# TF-IDF
from sklearn.feature_extraction.text import TfidfTransformer
tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)

X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)
X_test_tfidf.shape

"""# KNN, NB, Random Forest model training

## NB model
"""

from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB().fit(X_train_tfidf, y_train)

predicted = clf.predict(X_train_tfidf)
np.mean(predicted == y_train)

"""## random forest model"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

#rondom forest net
rf_net = RandomForestClassifier(n_estimators=100)
#apply data to model
rf_net.fit(X_train_tfidf, y_train)

predicted = rf_net.predict(X_train_tfidf)
np.mean(predicted == y_train)

"""## KNN model"""

# Create KNN classifier
knn = KNeighborsClassifier(n_neighbors = 3)
# apply data to model 
knn.fit(X_train_tfidf,y_train)

predicted = knn.predict(X_train_tfidf)
np.mean(predicted == y_train)

"""# ANN baseline model

## Data loader
"""

import numpy as np
import time
import torch
import os
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torchvision import datasets, models, transforms
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms

# load data from csv file
fields = ['news_article', 'news_category']

train_data = pd.read_csv('/content/inshort_news_data-train.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)
val_data = pd.read_csv('/content/inshort_news_data-val.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)
test_data = pd.read_csv('/content/inshort_news_data-test.csv', header=0, encoding='ISO-8859-1', usecols=fields, skip_blank_lines=True)

# Creating training and testing data
X_train = train_data['news_article']
Y_train = train_data['news_category']
"""
Y_train = np.zeros((X_train.shape[0],1))
for i in range((X_train.shape[0])):
  for j in range(7):
    if (train[j+1][i]==1):
      Y_train[i]=j
"""
X_test = test_data['news_article']
Y_test = test_data['news_category']
"""
Y_test = np.zeros((X_test.shape[0],1))
for i in range((X_test.shape[0])):
  for j in range(7):
    if (test[j+1][i]==1):
      Y_test[i]=j
"""
X_val = val_data['news_article']
Y_val = val_data['news_category']

print (X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape)

for i in range(X_train.shape[0]):
  X_train[i] = X_train[i].split()

for j in range(X_val.shape[0]):
  X_val[j] = X_val[j].split()

for k in range(X_test.shape[0]):
  X_test[k] = X_test[k].split()
    
Y_train = pd.get_dummies(Y_train).to_numpy()
Y_val = pd.get_dummies(Y_val).to_numpy()
Y_test = pd.get_dummies(Y_test).to_numpy()

# stopwords to eliminate useless words
stopwords = []
stop = open('/content/stopwords.txt', encoding="utf-8")
for line in stop:
  stopwords.append(line.strip())
stop.close()

# utilize Glove6B for embedding
glove = torchtext.vocab.GloVe(name='6B', dim=50)

# Filling the embedding matrix
embedding_matrix_train = np.zeros((X_train.shape[0], 61, 50))
embedding_matrix_val = np.zeros((X_val.shape[0], 61, 50))
embedding_matrix_test = np.zeros((X_test.shape[0], 61, 50))

for i in range(X_train.shape[0]):
  for j in range(len(X_train[i])):
    if not (X_train[i][j].lower() in stopwords):
      embedding_matrix_train[i][j] = glove[X_train[i][j].lower()]

for i in range(X_val.shape[0]):
  for j in range(len(X_val[i])):
    if not (X_val[i][j].lower() in stopwords):
      embedding_matrix_val[i][j] = glove[X_val[i][j].lower()]

for i in range(X_test.shape[0]):
  for j in range(len(X_test[i])):
    if not (X_test[i][j].lower() in stopwords):
      embedding_matrix_test[i][j] = glove[X_test[i][j].lower()]

X_train_t = torch.from_numpy(embedding_matrix_train).to(torch.float32)
Y_train_t = torch.from_numpy(Y_train).to(torch.float32)
X_val_t = torch.from_numpy(embedding_matrix_val).to(torch.float32)
Y_val_t = torch.from_numpy(Y_val).to(torch.float32)
X_test_t = torch.from_numpy(embedding_matrix_test).to(torch.float32)
Y_test_t = torch.from_numpy(Y_test).to(torch.float32)

train_dataset = TensorDataset(X_train_t, Y_train_t)
val_dataset = TensorDataset(X_val_t, Y_val_t)
test_dataset = TensorDataset(X_test_t, Y_test_t)

train_dataloader = DataLoader(train_dataset, batch_size=128)
val_dataloader = DataLoader(val_dataset, batch_size=128)
test_dataloader = DataLoader(test_dataset, batch_size=128)

X_train_t.shape

"""## ANN Class"""

class ANN(nn.Module):
    def __init__(self):
        super(ANN, self).__init__()
        self.layer1 = nn.Linear(50*61, 30)
        # layer 2 = nn.Linear (30, 15)
        self.layer2 = nn.Linear(30, 7)
    def forward(self, img):
        flattened = img.view(-1, 50*61)
        activation1 = self.layer1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.layer2(activation1)
        return activation2

"""## Training"""

import matplotlib.pyplot as plt # for plotting



def train_net(net, batch_size, learning_rate, num_epochs, momentum, train_loader, val_loader):
    assert num_epochs > 0, "num_epochs must be an integer that is greater than 0"
    assert learning_rate > 0, "learning_rate must be greater than 0"
    torch.manual_seed(1000)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(net.parameters(),
                                 lr=learning_rate,
                                 weight_decay=1e-5)
    epochs, train_losses, train_acc, val_losses, val_acc = [], [], [], [], []
    start_time = time.time()
    for epoch in range(num_epochs):
        epochs.append(epoch)
        total, correct = 0, 0
        total_loss = 0
        for articles, labels in train_loader:
            out = net(articles)
            loss = criterion(out, labels)
            total_loss = total_loss + loss.item() * articles.shape[0]
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)
            correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()
            total = total + articles.shape[0]
        train_acc.append(correct/total)
        train_losses.append(total_loss/total)

        val_correct = 0
        val_total_loss = 0
        val_total = 0
        for val_articles, val_labels in val_loader:
            # if use_cuda and torch.cuda.is_available():
                # val_imgs = val_imgs.cuda()
                # val_labels = val_labels.cuda()
            val_out = net(val_articles)
            # print(val_imgs)
            val_pred = torch.squeeze(val_out.max(1, keepdim=True)[1], 1)
            val_correct = val_correct + val_pred.eq(torch.argmax(val_labels, dim=1)).sum().item()
            val_total = val_total + val_articles.shape[0]
            val_total_loss = val_total_loss + (criterion(val_out, val_labels)).item() * val_articles.shape[0]
        val_losses.append(val_total_loss/val_total) # Append the average loss
        val_acc.append(val_correct/val_total)

        print("Epoch {0}:\ntraining accuracy: {1}\ttraining loss: {2}\tvalidation accuracy: {3}\tvalidation loss:{4}".format(epoch, train_acc[epoch], train_losses[epoch], val_acc[epoch], val_losses[epoch]))
        print("Correct number of outputs in validation: {0}\tTotal number of outputs in validation: {1}\tTotal validation loss {2}".format(val_correct, val_total, val_total_loss))
    end_time = time.time()
    print("Total time:  % 6.2f s  Time per Epoch: % 6.2f s " % (
    (end_time - start_time), ((end_time - start_time) / num_epochs)))

    # plotting
    plt.title("Training Loss Curve")
    plt.plot(epochs, train_losses, label="Train")
    plt.xlabel("Iterations")
    plt.ylabel("Train Loss")
    plt.show()

    plt.title("Training Accuracy Curve")
    plt.plot(epochs, train_acc, label="Training")
    plt.xlabel("Iterations")
    plt.ylabel("Training Accuracy")
    plt.show()


    plt.title("Validation Loss Curve")
    plt.plot(epochs, val_losses, label="Validation")
    plt.xlabel("Epochs")
    plt.ylabel("Train Loss")
    plt.show()

    plt.title("Validation Accuracy Curve")
    plt.plot(epochs, val_acc, label="Validation")
    plt.xlabel("Epochs")
    plt.ylabel("Validation Accuracy")
    plt.show()

net = ANN()

train_net(net, batch_size=128, learning_rate=0.001, num_epochs=10, momentum=0.9, train_loader=train_dataloader, val_loader=val_dataloader)

"""## Testing"""

def test_model(net, data_loader, criterion):
    correct = 0
    total_loss = 0
    total = 0
    for articles, labels in data_loader:
        out = net(articles)
        pred = torch.squeeze(out.max(1, keepdim=True)[1], 1)
        correct = correct + pred.eq(torch.argmax(labels, dim=1)).sum().item()
        total = total + articles.shape[0]
        total_loss = total_loss + (criterion(out, labels)).item() * articles.shape[0]
    return correct, total, correct / total, total_loss / total

test_result = test_model(net, test_dataloader, nn.MSELoss())
print("Correct: {0}\tTotal: {1}\tAccuracy: {2}\tLoss: {3}".format(test_result[0], test_result[1], test_result[2], test_result[3]))